# backend/main.py
import logging
import traceback
import os, hmac, hashlib, base64, json, time, asyncio
from urllib.parse import urlparse, quote_plus
from typing import Optional, Dict, List, Any

from fastapi import FastAPI, Depends, HTTPException, Request, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from providers import ProviderRegistry, ProviderOps
from fastapi.responses import JSONResponse, RedirectResponse, StreamingResponse
import io
from fastapi.exceptions import RequestValidationError

from sqlalchemy.orm import Session
from sqlalchemy import text, or_, and_

from ai_service import suggest_products_with_config
import models, schemas, crud
from database import Base, engine, SessionLocal
from pydantic import BaseModel, HttpUrl
from accesstrade_service import (
    fetch_products, map_at_product_to_offer, _check_url_alive, fetch_promotions,
    fetch_campaign_detail, fetch_commission_policies  # NEW
)

# FastAPI application instance
app = FastAPI()

# CORS (open by default; tighten in production)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Logger
logger = logging.getLogger("affiliate_api")
if not logger.handlers:
    logging.basicConfig(level=logging.INFO)

# --- DB init: create tables on import (no Alembic here) ---
Base.metadata.create_all(bind=engine)

# DB session dependency
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ---------------- Error handlers ----------------
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    logger.warning(
        "Validation error on %s %s: %s | body=%s",
        request.method, request.url.path, exc, getattr(exc, "body", None)
    )
    return JSONResponse(
        status_code=422,
        content={"detail": exc.errors(), "body": getattr(exc, "body", None)}
    )

@app.exception_handler(Exception)
async def all_exception_handler(request: Request, exc: Exception):
    tb = traceback.format_exc()
    return JSONResponse(status_code=500, content={"error": str(exc), "traceback": tb})

# ---------------- System ----------------
## NOTE: (removed) stray decorator left behind during refactor
@app.get(
    "/health",
    tags=["System üõ†Ô∏è"],
    summary="Ki·ªÉm tra s·ª©c kh·ªèe h·ªá th·ªëng",
    description="Th·ª±c hi·ªán truy v·∫•n SQL ƒë∆°n gi·∫£n ƒë·ªÉ ki·ªÉm tra k·∫øt n·ªëi DB v√† t√¨nh tr·∫°ng d·ªãch v·ª•."
)
def health(db: Session = Depends(get_db)):
    try:
        db.execute(text("SELECT 1"))
        return {"ok": True}
    except Exception as e:
        logger.exception("Health check failed")
        return {"ok": False, "error": str(e)}

# =====================================================================
#                       AFFILIATE ‚Äî SAFE SHORTLINK
# =====================================================================

# Secret k√Ω HMAC cho shortlink /r/{token}
AFF_SECRET = os.getenv("AFF_SECRET", "change-me")  # nh·ªõ ƒë·∫∑t trong docker-compose/.env khi ch·∫°y th·∫≠t

# Whitelist domain theo merchant ƒë·ªÉ ch·ªëng open-redirect
ALLOWED_DOMAINS = {
    "shopee": ["shopee.vn", "shopee.sg", "shopee.co.id", "shopee.co.th", "shopee.com.my", "shopee.ph"],
    "lazada": ["lazada.vn", "lazada.co.id", "lazada.co.th", "lazada.com.my", "lazada.sg", "lazada.com.ph"],
    "tiki":   ["tiki.vn"],
}

def _is_allowed_domain(merchant: str, url: str) -> bool:
    try:
        netloc = urlparse(url).netloc.lower()
        return any(netloc.endswith(dom) for dom in ALLOWED_DOMAINS.get(merchant, []))
    except Exception:
        return False

def _apply_template(template: str, target_url: str, params: Optional[Dict[str, str]]) -> str:
    # Encode link g·ªëc v√†o placeholder {target}; c√°c {param} kh√°c thay tr·ª±c ti·∫øp
    aff = template.replace("{target}", quote_plus(target_url))
    if params:
        for k, v in params.items():
            aff = aff.replace("{" + k + "}", str(v))
    return aff

def _make_token(affiliate_url: str, ts: Optional[int] = None) -> str:
    payload = {"u": affiliate_url, "ts": ts or int(time.time())}
    b64 = base64.urlsafe_b64encode(json.dumps(payload).encode()).decode().rstrip("=")
    sig = hmac.new(AFF_SECRET.encode(), b64.encode(), hashlib.sha256).hexdigest()
    return f"{b64}.{sig}"

def _parse_token(token: str) -> str:
    try:
        b64, sig = token.split(".", 1)
        expect = hmac.new(AFF_SECRET.encode(), b64.encode(), hashlib.sha256).hexdigest()
        if not hmac.compare_digest(expect, sig):
            raise ValueError("invalid signature")
        pad = "=" * (-len(b64) % 4)
        payload = json.loads(base64.urlsafe_b64decode(b64 + pad).decode())
        return payload["u"]
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Invalid token: {e}")

# ---------------- CRUD: Links ----------------
@app.get(
    "/links",
    tags=["Links üîó"],
    summary="Danh s√°ch link",
    description="L·∫•y danh s√°ch link ti·∫øp th·ªã t·ª´ DB. H·ªó tr·ª£ ph√¢n trang qua `skip`, `limit`.",
    response_model=list[schemas.AffiliateLinkOut]
)
def read_links(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    return crud.get_links(db, skip=skip, limit=limit)

@app.get(
    "/links/{link_id}",
    tags=["Links üîó"],
    summary="Chi ti·∫øt link",
    description="L·∫•y chi ti·∫øt m·ªôt link ti·∫øp th·ªã theo **ID**.",
    response_model=schemas.AffiliateLinkOut
)
def read_link(link_id: int, db: Session = Depends(get_db)):
    db_link = crud.get_link(db, link_id)
    if db_link is None:
        raise HTTPException(status_code=404, detail="Link not found")
    return db_link

@app.post(
    "/links",
    tags=["Links üîó"],
    summary="Th√™m link m·ªõi",
    description="T·∫°o m·ªõi m·ªôt link ti·∫øp th·ªã v√† l∆∞u v√†o DB.",
    response_model=schemas.AffiliateLinkOut
)
def create_link(link: schemas.AffiliateLinkCreate, db: Session = Depends(get_db)):
    logger.debug("Create link payload: %s", link.model_dump() if hasattr(link, "model_dump") else link.dict())
    return crud.create_link(db, link)

@app.put(
    "/links/{link_id}",
    tags=["Links üîó"],
    summary="C·∫≠p nh·∫≠t link",
    description="C·∫≠p nh·∫≠t th√¥ng tin m·ªôt link ti·∫øp th·ªã theo **ID**.",
    response_model=schemas.AffiliateLinkOut
)
def update_link(link_id: int, link: schemas.AffiliateLinkUpdate, db: Session = Depends(get_db)):
    db_link = crud.update_link(db, link_id, link)
    if db_link is None:
        raise HTTPException(status_code=404, detail="Link not found")
    return db_link

@app.delete(
    "/links/{link_id}",
    tags=["Links üîó"],
    summary="Xo√° link",
    description="Xo√° link ti·∫øp th·ªã theo **ID**."
)
def delete_link(link_id: int, db: Session = Depends(get_db)):
    db_link = crud.delete_link(db, link_id)
    if db_link is None:
        raise HTTPException(status_code=404, detail="Link not found")
    return {"ok": True, "message": "Link deleted"}

# ---------------- CRUD: API Configs ----------------

@app.get(
    "/api-configs",
    tags=["API Configs ‚öôÔ∏è"],
    summary="Danh s√°ch c·∫•u h√¨nh API",
    description="Li·ªát k√™ to√†n b·ªô c·∫•u h√¨nh nh√† cung c·∫•p AI/API.",
    response_model=list[schemas.APIConfigOut]
)
def read_api_configs(db: Session = Depends(get_db)):
    return crud.list_api_configs(db)

@app.post(
    "/api-configs/upsert",
    tags=["API Configs ‚öôÔ∏è"],
    summary="Upsert c·∫•u h√¨nh API",
    description="**T·∫°o m·ªõi ho·∫∑c c·∫≠p nh·∫≠t** c·∫•u h√¨nh d·ª±a tr√™n `name`. Thu·∫≠n ti·ªán ƒë·ªÉ c·∫≠p nh·∫≠t nhanh.",
    response_model=schemas.APIConfigOut
)
def upsert_api_config(config: schemas.APIConfigCreate, db: Session = Depends(get_db)):
    """T·∫°o m·ªõi ho·∫∑c c·∫≠p nh·∫≠t API config theo name."""
    return crud.upsert_api_config_by_name(db, config)

@app.put(
    "/api-configs/{config_id}",
    tags=["API Configs ‚öôÔ∏è"],
    summary="C·∫≠p nh·∫≠t c·∫•u h√¨nh API",
    description="C·∫≠p nh·∫≠t th√¥ng tin c·∫•u h√¨nh theo **ID**.",
    response_model=schemas.APIConfigOut
)
def update_api_config(config_id: int, config: schemas.APIConfigCreate, db: Session = Depends(get_db)):
    db_config = db.query(models.APIConfig).filter(models.APIConfig.id == config_id).first()
    if not db_config:
        raise HTTPException(status_code=404, detail="API config not found")
    db_config.name = config.name
    db_config.base_url = config.base_url
    db_config.api_key = config.api_key
    db_config.model = config.model
    db.commit()
    db.refresh(db_config)
    return db_config

@app.delete(
    "/api-configs/{config_id}",
    tags=["API Configs ‚öôÔ∏è"],
    summary="Xo√° c·∫•u h√¨nh API",
    description="Xo√° c·∫•u h√¨nh nh√† cung c·∫•p theo **ID**."
)
def delete_api_config_route(config_id: int, db: Session = Depends(get_db)):
    deleted = crud.delete_api_config(db, config_id)
    if not deleted:
        raise HTTPException(status_code=404, detail="API config not found")
    return {"ok": True, "deleted_id": config_id, "name": deleted.name}

# ---------------- AI: Suggest/Test ----------------
@app.post(
    "/ai/suggest",
    tags=["AI ü§ñ"],
    summary="AI g·ª£i √Ω theo s·∫£n ph·∫©m trong DB",
    description="Tr·∫£ l·ªùi/g·ª£i √Ω b·∫±ng AI d·ª±a tr√™n danh s√°ch s·∫£n ph·∫©m ƒë√£ ingest."
)
async def ai_suggest(
    query: str,
    provider: str = "groq",
    db: Session = Depends(get_db)
):
    # Gi·ªØ nguy√™n logic g·ªëc
    products = []
    for o in crud.list_offers(db, limit=50):
        desc = None
        if o.extra:
            try:
                desc = json.loads(o.extra).get("desc")
            except:
                pass
        products.append({
            "name": o.title,
            "url": o.url,
            "affiliate_url": o.affiliate_url or o.url,
            "desc": desc
        })
    if not products:
        raise HTTPException(status_code=404, detail="Ch∆∞a c√≥ s·∫£n ph·∫©m n√†o trong DB")
    response = await suggest_products_with_config(query, products, db, provider)
    return {"suggestion": response}

@app.post(
    "/ai/test",
    tags=["AI ü§ñ"],
    summary="Test AI nhanh",
    description="G·ªçi AI v·ªõi c√¢u h·ªèi m·∫´u & 10 s·∫£n ph·∫©m g·∫ßn nh·∫•t trong DB ƒë·ªÉ ki·ªÉm tra nhanh ch·∫•t l∆∞·ª£ng tr·∫£ l·ªùi."
)
async def ai_test(
    query: str = "Gi·ªõi thi·ªáu s·∫£n ph·∫©m t·ªët nh·∫•t tr√™n Shopee",
    provider: str = "groq",
    db: Session = Depends(get_db)
):
    # Gi·ªØ nguy√™n logic g·ªëc
    products = []
    for o in crud.list_offers(db, limit=50):
        desc = None
        if o.extra:
            try:
                desc = json.loads(o.extra).get("desc")
            except:
                pass
        products.append({
            "name": o.title,
            "url": o.url,
            "affiliate_url": o.affiliate_url or o.url,
            "desc": desc
        })
    if not products:
        return {"suggestion": "‚ö†Ô∏è Ch∆∞a c√≥ s·∫£n ph·∫©m n√†o trong DB ƒë·ªÉ g·ª£i √Ω."}
    response = await suggest_products_with_config(query, products, db, provider)
    return {"suggestion": response}

# =====================================================================
#                  NEW: Templates + Convert + Redirect
# =====================================================================

# Upsert template deeplink (m·ªói merchant/network m·ªôt m·∫´u)

@app.get(
    "/aff/templates",
    tags=["Affiliate üéØ"],
    summary="Danh s√°ch m·∫´u deeplink",
    description="Hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß c√°c m·∫´u deeplink hi·ªán c√≥ trong DB.",
    response_model=list[schemas.AffiliateTemplateOut]
)
def list_templates(db: Session = Depends(get_db)):
    return crud.list_affiliate_templates(db)

@app.post(
    "/aff/templates/upsert",
    tags=["Affiliate üéØ"],
    summary="Upsert m·∫´u deeplink",
    description="Th√™m/c·∫≠p nh·∫≠t m·∫´u deeplink cho t·ª´ng **merchant** v√† **network**.",
    response_model=schemas.AffiliateTemplateOut
)
def upsert_template(data: schemas.AffiliateTemplateCreate, db: Session = Depends(get_db)):
    tpl = crud.upsert_affiliate_template(db, data)
    return tpl

@app.put(
    "/aff/templates/{template_id}",
    tags=["Affiliate üéØ"],
    summary="C·∫≠p nh·∫≠t m·∫´u deeplink",
    description="S·ª≠a m·∫´u deeplink theo ID.",
    response_model=schemas.AffiliateTemplateOut
)
def update_template(template_id: int, data: schemas.AffiliateTemplateCreate, db: Session = Depends(get_db)):
    tpl = crud.update_affiliate_template(db, template_id, data)
    if not tpl:
        raise HTTPException(status_code=404, detail="Template not found")
    return tpl

@app.delete(
    "/aff/templates/{template_id}",
    tags=["Affiliate üéØ"],
    summary="Xo√° m·∫´u deeplink",
    description="Xo√° m·∫´u deeplink theo ID."
)
def delete_template(template_id: int, db: Session = Depends(get_db)):
    tpl = crud.delete_affiliate_template_by_id(db, template_id)
    if not tpl:
        raise HTTPException(status_code=404, detail="Template not found")
    return {"ok": True, "deleted_id": template_id}

# Y√™u c·∫ßu convert
class ConvertReq(BaseModel):
    merchant: str
    url: HttpUrl
    network: str = "accesstrade"
    params: Optional[Dict[str, str]] = None  # v√≠ d·ª• {"sub1": "my_subid"}

class ConvertRes(BaseModel):
    affiliate_url: str
    short_url: str

# Convert link g·ªëc -> deeplink + shortlink /r/{token}
@app.post(
    "/aff/convert",
    tags=["Affiliate üéØ"],
    summary="Chuy·ªÉn link g·ªëc ‚Üí deeplink + shortlink",
    description=(
        "Nh·∫≠n link g·ªëc + merchant ‚Üí tr·∫£ v·ªÅ **affiliate_url** (deeplink) v√† **short_url** d·∫°ng `/r/{token}`.\n"
        "H·ªó tr·ª£ merge `default_params` t·ª´ template + `params` ng∆∞·ªùi d√πng truy·ªÅn."
    ),
    response_model=ConvertRes
)
def aff_convert(req: ConvertReq, db: Session = Depends(get_db)):
    if not _is_allowed_domain(req.merchant, str(req.url)):
        raise HTTPException(status_code=400, detail=f"URL kh√¥ng thu·ªôc domain h·ª£p l·ªá c·ªßa {req.merchant}")

    tpl = crud.get_affiliate_template(db, req.merchant, req.network)
    if not tpl:
        raise HTTPException(status_code=404, detail=f"Ch∆∞a c·∫•u h√¨nh template cho merchant={req.merchant}, network={req.network}")

    merged: Dict[str, str] = {}
    if tpl.default_params:
        merged.update(tpl.default_params)
    if req.params:
        merged.update(req.params)

    affiliate_url = _apply_template(tpl.template, str(req.url), merged)
    token = _make_token(affiliate_url)
    short_url = f"/r/{token}"
    return ConvertRes(affiliate_url=affiliate_url, short_url=short_url)

# Redirect t·ª´ shortlink -> deeplink th·∫≠t
@app.get(
    "/r/{token}",
    tags=["Affiliate üéØ"],
    summary="Redirect shortlink",
    description="Gi·∫£i m√£ token v√† chuy·ªÉn h∆∞·ªõng 302 t·ªõi **affiliate_url** th·ª±c t·∫ø."
)
def redirect_short_link(token: str):
    affiliate_url = _parse_token(token)
    return RedirectResponse(url=affiliate_url, status_code=302)

# =====================================================================
#                  NEW (B∆∞·ªõc 3): Ingest/List t·ª´ Accesstrade
# =====================================================================

class IngestReq(BaseModel):
    provider: str = "accesstrade"                 # v√≠ d·ª•: "accesstrade", "adpia", ...
    path: str = "/v1/publishers/product_search"   # tu·ª≥ provider
    params: Dict[str, str] | None = None

class IngestAllDatafeedsReq(BaseModel):
    """
    Ingest to√†n b·ªô datafeeds trong m·ªôt l·∫ßn (t·ª± ph√¢n trang n·ªôi b·ªô).
    - params: b·ªô l·ªçc chuy·ªÉn th·∫≥ng ƒë·∫øn provider (Accesstrade) v√† m·ªôt s·ªë filter n·ªôi b·ªô:
        - merchant: l·ªçc theo merchant/campaign slug c·ªßa AT (vd: "tiki", "tiktokshop").
        - domain: l·ªçc theo domain s·∫£n ph·∫©m (vd: "tiki.vn").
        - campaign_id | camp_id: c·ªë ƒë·ªãnh ƒë√∫ng campaign_id c·∫ßn ingest (∆∞u ti√™n n·∫øu c√≥).
        - update_from/update_to, price_from/to, discount_*: chuy·ªÉn ti·∫øp xu·ªëng API AT n·∫øu h·ªó tr·ª£.
    - limit_per_page: k√≠ch th∆∞·ªõc trang khi g·ªçi ra Accesstrade (m·∫∑c ƒë·ªãnh 100)
    - max_pages: ch·∫∑n v√≤ng l·∫∑p v√¥ h·∫°n n·∫øu API tr·∫£ b·∫•t th∆∞·ªùng (m·∫∑c ƒë·ªãnh 2000 trang)
    - throttle_ms: ngh·ªâ gi·ªØa c√°c l·∫ßn g·ªçi ƒë·ªÉ t√¥n tr·ªçng rate-limit (m·∫∑c ƒë·ªãnh 0ms)
    - check_urls: n·∫øu True m·ªõi ki·ªÉm tra link s·ªëng (m·∫∑c ƒë·ªãnh False).
    """
    params: Dict[str, str] | None = None
    limit_per_page: int = 100
    max_pages: int = 2000
    throttle_ms: int = 0
    check_urls: bool = False
    verbose: bool = False
    
class CampaignsSyncReq(BaseModel):
    """
    ƒê·ªìng b·ªô campaigns t·ª´ Accesstrade (t·ªëi ∆∞u t·ªëc ƒë·ªô).
    - statuses: danh s√°ch tr·∫°ng th√°i c·∫ßn qu√©t, m·∫∑c ƒë·ªãnh ["running","paused"].
    - only_my: True -> ch·ªâ gi·ªØ approval in {"successful","pending"} (nhanh h∆°n, √≠t ghi DB).
    - enrich_user_status: l·∫•y user_status th·∫≠t t·ª´ campaign detail (ch·∫≠m). M·∫∑c ƒë·ªãnh False ƒë·ªÉ nhanh.
    - limit_per_page, page_concurrency, window_pages, throttle_ms: tinh ch·ªânh t·ªëc ƒë·ªô vs ƒë·ªô ·ªïn ƒë·ªãnh.
    - merchant: n·∫øu truy·ªÅn s·∫Ω l·ªçc theo merchant sau khi fetch.
    """
    statuses: List[str] | None = None
    only_my: bool = True
    enrich_user_status: bool = True
    limit_per_page: int = 50
    page_concurrency: int = 6
    window_pages: int = 10
    throttle_ms: int = 300
    merchant: str | None = None

class IngestV2PromotionsReq(BaseModel):
    """
    Ingest khuy·∫øn m√£i (offers_informations) theo merchant ƒë√£ duy·ªát.
    - merchant: n·∫øu truy·ªÅn, ch·ªâ ingest ƒë√∫ng merchant n√†y; n·∫øu b·ªè tr·ªëng s·∫Ω ch·∫°y cho t·∫•t c·∫£ merchant active.
    - create_offers: n·∫øu True, s·∫Ω map m·ªói promotion th√†nh 1 offer t·ªëi thi·ªÉu (title/url/affiliate_url/image).
    - check_urls: n·∫øu True m·ªõi ki·ªÉm tra link s·ªëng (m·∫∑c ƒë·ªãnh False).
    """
    merchant: str | None = None
    create_offers: bool = True
    check_urls: bool = False
    verbose: bool = False

class IngestV2TopProductsReq(BaseModel):
    """
    Ingest top_products (b√°n ch·∫°y) theo merchant & kho·∫£ng ng√†y.
    - date_from/date_to: 'YYYY-MM-DD' (t√πy Accesstrade h·ªó tr·ª£); n·∫øu b·ªè tr·ªëng c√≥ th·ªÉ l·∫•y m·∫∑c ƒë·ªãnh ph√≠a API.
    - limit_per_page: k√≠ch th∆∞·ªõc trang (<=100)
    - max_pages: s·ªë trang t·ªëi ƒëa s·∫Ω qu√©t
    - throttle_ms: ngh·ªâ gi·ªØa c√°c l·∫ßn g·ªçi
    - check_urls: n·∫øu True m·ªõi ki·ªÉm tra link s·ªëng (m·∫∑c ƒë·ªãnh False).
    """
    merchant: str
    date_from: str | None = None
    date_to: str | None = None
    check_urls: bool = False
    verbose: bool = False
    limit_per_page: int = 100
    max_pages: int = 200
    throttle_ms: int = 0
# ================================
# Unified provider-agnostic ingest (front-door)
class UnifiedCampaignsSyncReq(CampaignsSyncReq):
    provider: str = "accesstrade"

class UnifiedPromotionsReq(IngestV2PromotionsReq):
    provider: str = "accesstrade"

class UnifiedTopProductsReq(IngestV2TopProductsReq):
    provider: str = "accesstrade"

class UnifiedDatafeedsAllReq(IngestAllDatafeedsReq):
    provider: str = "accesstrade"

## Removed duplicated earlier unified endpoints (replaced by a single consolidated set below)

# ---------------- Provider registry wiring ----------------
_registry = ProviderRegistry()

# Build Accesstrade ops from existing handlers
async def _accesstrade_campaigns_sync(req: "CampaignsSyncReq", db: Session):
    return await ingest_v2_campaigns_sync(req, db)

async def _accesstrade_promotions(req: "IngestV2PromotionsReq", db: Session):
    return await ingest_v2_promotions(req, db)

async def _accesstrade_top_products(req: "IngestV2TopProductsReq", db: Session):
    return await ingest_v2_top_products(req, db)

async def _accesstrade_datafeeds_all(req: "IngestAllDatafeedsReq", db: Session):
    return await ingest_accesstrade_datafeeds_all(req, db)

# products op will be provided by a helper implemented below
async def _accesstrade_products(req: "IngestReq", db: Session):
    return await _ingest_products_accesstrade_impl(req, db)

_registry.register("accesstrade", ProviderOps(
    campaigns_sync=_accesstrade_campaigns_sync,
    promotions=_accesstrade_promotions,
    top_products=_accesstrade_top_products,
    datafeeds_all=_accesstrade_datafeeds_all,
    products=_accesstrade_products,
))

from sqlalchemy import func

@app.get("/campaigns/summary", tags=["Campaigns üì¢"])
def campaigns_summary(db: Session = Depends(get_db)):
    total = db.query(func.count(models.Campaign.campaign_id)).scalar() or 0

    by_status = {
        (k or "NULL"): v
        for (k, v) in db.query(models.Campaign.status, func.count())
                        .group_by(models.Campaign.status).all()
    }
    by_user_status = {
        (k or "NULL"): v
        for (k, v) in db.query(models.Campaign.user_registration_status, func.count())
                        .group_by(models.Campaign.user_registration_status).all()
    }

    running_approved_count = (
            db.query(func.count(models.Campaign.campaign_id))
            .filter(models.Campaign.status == "running")
            .filter(models.Campaign.user_registration_status.in_(["APPROVED", "SUCCESSFUL"]))
            .scalar() or 0
    )
    approved_merchants = sorted({
            m for (m,) in db.query(models.Campaign.merchant)
                            .filter(models.Campaign.status == "running")
                            .filter(models.Campaign.user_registration_status.in_(["APPROVED", "SUCCESSFUL"]))
                            .distinct().all()
            if m
    })

    return {
        "total": total,
        "by_status": by_status,
        "by_user_status": by_user_status,
        "running_approved_count": running_approved_count,
        "approved_merchants": approved_merchants
    }

@app.post("/maintenance/normalize-campaigns", tags=["Campaigns üì¢"], summary="Chu·∫©n ho√° d·ªØ li·ªáu campaign (v1 ‚Üí v2)")
def normalize_campaigns(db: Session = Depends(get_db)):
    """
    Di chuy·ªÉn c√°c gi√° tr·ªã 'successful/pending/unregistered' t·ª´ c·ªôt approval
    sang user_registration_status, r·ªìi set approval = NULL.
    """
    rows = db.query(models.Campaign).all()
    moved = 0
    for r in rows:
        val = (r.approval or "").strip().lower() if r.approval else ""
        if val in ("successful", "pending", "unregistered"):
            r.user_registration_status = "APPROVED" if val == "successful" else val.upper()
            r.approval = None
            db.add(r)
            moved += 1
    db.commit()
    return {"ok": True, "moved": moved}

@app.get("/campaigns", response_model=list[schemas.CampaignOut], tags=["Campaigns üì¢"])
def list_campaigns_api(
    status: str | None = None,
    approval: str | None = None,
    user_status: str | None = None,
    merchant: str | None = None,
    db: Session = Depends(get_db),
):
    q = db.query(models.Campaign)
    if status:
        q = q.filter(models.Campaign.status == status)
    # filter ch√≠nh x√°c theo t√†i li·ªáu: approval = unregistered/pending/successful
    if approval:
        q = q.filter(models.Campaign.approval == approval)
    # h·ªó tr·ª£ user_status: ∆∞u ti√™n c·ªôt user_registration_status; n·∫øu NULL m·ªõi fallback v·ªÅ approval map
    if user_status:
        us = user_status.strip().upper()
        fallback = {
            "APPROVED": "successful",
            "PENDING": "pending",
            "NOT_REGISTERED": "unregistered",
        }.get(us)
        if fallback:
            q = q.filter(
                or_(
                    models.Campaign.user_registration_status == us,
                    and_(models.Campaign.user_registration_status == None,
                         models.Campaign.approval == fallback)
                )
            )
        else:
            q = q.filter(models.Campaign.user_registration_status == us)
    if merchant:
        q = q.filter(models.Campaign.merchant == merchant)
    return q.order_by(models.Campaign.updated_at.desc()).all()

@app.get("/campaigns/approved-merchants", response_model=list[str], tags=["Campaigns üì¢"])
def list_approved_merchants_api(db: Session = Depends(get_db)):
    rows = (
        db.query(models.Campaign.merchant)
        .filter(models.Campaign.status == "running")
        .filter(or_(
            models.Campaign.user_registration_status == "APPROVED",
            models.Campaign.user_registration_status == "SUCCESSFUL",
        ))
        .distinct()
        .all()
    )
    merchants = sorted({m for (m,) in rows if m})
    return merchants

@app.get("/offers", response_model=list[schemas.ProductOfferOut], tags=["Offers üõí"])
def list_offers_api(
    merchant: str | None = None,
    skip: int = 0,
    limit: int = 50,
    db: Session = Depends(get_db)
):
    """
    üõí L·∫•y danh s√°ch s·∫£n ph·∫©m trong DB c√≥ ph√¢n trang  
    - `merchant`: l·ªçc theo t√™n merchant (vd: `shopee`, `lazada`, `tiki`)  
    - `skip`: s·ªë b·∫£n ghi b·ªè qua (offset)  
    - `limit`: s·ªë b·∫£n ghi t·ªëi ƒëa tr·∫£ v·ªÅ  
    """
    rows = crud.list_offers(db, merchant=merchant, skip=skip, limit=limit)

    out: list[dict] = []
    for o in rows:
        item = {
            "id": o.id,
            "title": o.title,
            "url": o.url,
            "affiliate_url": o.affiliate_url,
            "image_url": o.image_url,
            "merchant": o.merchant,
            "campaign_id": o.campaign_id,
            "price": o.price,
            "currency": o.currency,
            # Model kh√¥ng c√≥ 'status'; gi·ªØ key cho t∆∞∆°ng th√≠ch, map sang approval_status
            "status": getattr(o, "status", None) or o.approval_status,
            "approval_status": o.approval_status,
            "eligible_commission": o.eligible_commission,
            "source_type": o.source_type,
            "affiliate_link_available": o.affiliate_link_available,
            "product_id": o.product_id,
            "extra": o.extra,
            "updated_at": o.updated_at,
            "desc": None, "cate": None, "shop_name": None, "update_time_raw": None,
        }

        try:
            ex = json.loads(o.extra) if o.extra else {}
            item["desc"] = ex.get("desc")
            item["cate"] = ex.get("cate")
            item["shop_name"] = ex.get("shop_name")
            item["update_time_raw"] = ex.get("update_time_raw") or ex.get("update_time")
        except Exception:
            pass
        out.append(item)

    return out

@app.post(
    "/ingest/policy",
    tags=["Offers üõí"],
    summary="C·∫•u h√¨nh policy ingest",
    description="B·∫≠t/t·∫Øt ch·∫ø ƒë·ªô ch·ªâ ingest s·∫£n ph·∫©m c√≥ commission policy."
)
def set_ingest_policy(only_with_commission: bool = False, db: Session = Depends(get_db)):
    model_str = f"only_with_commission={'true' if only_with_commission else 'false'}"
    cfg = crud.upsert_api_config_by_name(db, schemas.APIConfigCreate(
        name="ingest_policy",
        base_url="-",
        api_key="-",
        model=model_str,
    ))
    return {"ok": True, "ingest_policy": model_str, "config_id": cfg.id}

@app.post(
    "/ingest/policy/check-urls",
    tags=["Offers üõí"],
    summary="B·∫≠t/t·∫Øt ki·ªÉm tra link khi IMPORT EXCEL",
    description="Ch·ªâ ·∫£nh h∆∞·ªüng import Excel. API ingest (V1/V2) lu√¥n m·∫∑c ƒë·ªãnh KH√îNG check link."
)
def set_ingest_policy_check_urls(enable: bool = False, db: Session = Depends(get_db)):
    # d√πng store flags trong api_configs.name='ingest_policy'
    crud.set_policy_flag(db, "check_urls", enable)
    flags = crud.get_policy_flags(db)
    return {"ok": True, "flags": flags}

@app.post(
    "/ingest/products",
    tags=["Offers üõí"],
    summary="Ingest s·∫£n ph·∫©m t·ª´ nhi·ªÅu provider",
    description=(
        "Nh·∫≠p s·∫£n ph·∫©m v√†o DB t·ª´ nhi·ªÅu provider (v√≠ d·ª•: Accesstrade). "
        "Hi·ªán h·ªó tr·ª£ `provider=accesstrade`. C√°c provider kh√°c c√≥ th·ªÉ b·ªï sung sau."
    )
)
async def ingest_products(
    req: IngestReq,
    db: Session = Depends(get_db),
):
    provider = (req.provider or "accesstrade").lower()
    ops = _registry.get(provider)
    if not ops:
        raise HTTPException(status_code=400, detail=f"Provider '{provider}' hi·ªán ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£")
    return await ops.products(req, db)

# Internal helper: Accesstrade implementation for products ingest
async def _ingest_products_accesstrade_impl(req: IngestReq, db: Session):
    from accesstrade_service import (
        fetch_active_campaigns, fetch_campaign_detail, fetch_products,
        fetch_promotions, fetch_commission_policies, map_at_product_to_offer, _check_url_alive,
    )
    active_campaigns = await fetch_active_campaigns(db)
    logger.info("Fetched %d active campaigns", len(active_campaigns))
    merchant_campaign_map = {v: k for k, v in active_campaigns.items()}

    items = await fetch_products(db, req.path, req.params or {})
    if not items:
        return {"ok": True, "imported": 0}

    imported = 0
    def _vlog(reason: str, extra: dict | None = None):
        try:
            from accesstrade_service import _log_jsonl as _rawlog
            payload = {"endpoint": "manual_ingest", "reason": reason}
            if extra:
                payload.update(extra)
            _rawlog("ingest_skips.jsonl", payload)
        except Exception:
            pass

    for it in items:
        policies = []  # ensure defined for each iteration
        camp_id = str(it.get("campaign_id") or it.get("campaign_id_str") or "").strip()
        merchant = str(it.get("merchant") or it.get("campaign") or "").lower().strip()
        _alias = {"lazadacps": "lazada", "tikivn": "tiki"}
        merchant_norm = _alias.get(merchant, merchant.split(".")[0] if "." in merchant else merchant)

        def _resolve_campaign_id_by_suffix(m_name: str) -> tuple[str | None, str]:
            if m_name in merchant_campaign_map:
                return merchant_campaign_map[m_name], "exact"
            for m_key, cid in merchant_campaign_map.items():
                if m_key.endswith(m_name) or f"_{m_name}" in m_key:
                    return cid, f"suffix({m_key})"
            for m_key, cid in merchant_campaign_map.items():
                if m_name in m_key:
                    return cid, f"contains({m_key})"
            return None, ""

        if not camp_id:
            camp_id, how = _resolve_campaign_id_by_suffix(merchant_norm)
            if camp_id:
                logger.debug("Fallback campaign_id=%s via %s cho merchant=%s (norm=%s) [manual ingest]",
                             camp_id, how, merchant, merchant_norm)
            else:
                _vlog("no_campaign_match", {"merchant": merchant, "merchant_norm": merchant_norm})

        if not camp_id or camp_id not in active_campaigns:
            logger.info("Skip product v√¨ campaign_id=%s kh√¥ng active [manual ingest] (merchant=%s)", camp_id, merchant_norm)
            _vlog("campaign_not_active", {"campaign_id": camp_id, "merchant": merchant_norm})
            continue

        try:
            _row = crud.get_campaign_by_cid(db, camp_id)
            if not _row or (_row.user_registration_status or "").upper() != "APPROVED":
                logger.info("Skip product v√¨ campaign_id=%s ch∆∞a APPROVED [manual ingest]", camp_id)
                _vlog("campaign_not_approved", {"campaign_id": camp_id})
                continue
        except Exception:
            continue

        promotions_data = await fetch_promotions(db, merchant_norm) if merchant_norm else []
        if promotions_data:
            for prom in promotions_data:
                try:
                    crud.upsert_promotion(db, schemas.PromotionCreate(
                        campaign_id=camp_id,
                        name=prom.get("name"),
                        content=prom.get("content") or prom.get("description"),
                        start_time=prom.get("start_time"),
                        end_time=prom.get("end_time"),
                        coupon=prom.get("coupon"),
                        link=prom.get("link"),
                    ))
                except Exception as e:
                    logger.debug("Skip promotion upsert: %s", e)

        try:
            camp = await fetch_campaign_detail(db, camp_id)
            if camp:
                status_val = camp.get("status")
                approval_val = camp.get("approval")
                _user_raw = (
                    camp.get("user_registration_status")
                    or camp.get("publisher_status")
                    or camp.get("user_status")
                )
                def _map_status(v):
                    s = str(v).strip() if v is not None else None
                    if s == "1": return "running"
                    if s == "0": return "paused"
                    return s
                crud.upsert_campaign(db, schemas.CampaignCreate(
                    campaign_id=str(camp.get("campaign_id") or camp_id),
                    merchant=str(camp.get("merchant") or merchant_norm or "").lower() or None,
                    name=camp.get("name"),
                    status=_map_status(status_val),
                    approval=(str(approval_val) if approval_val is not None else None),
                    start_time=camp.get("start_time"),
                    end_time=camp.get("end_time"),
                    user_registration_status=(_user_raw if _user_raw not in (None, "", []) else None),
                ))
        except Exception as e:
            logger.debug("Skip campaign upsert: %s", e)

        try:
            policies = await fetch_commission_policies(db, camp_id)
            for rec in (policies or []):
                crud.upsert_commission_policy(db, schemas.CommissionPolicyCreate(
                    campaign_id=camp_id,
                    reward_type=rec.get("reward_type") or rec.get("type"),
                    sales_ratio=rec.get("sales_ratio") or rec.get("ratio"),
                    sales_price=rec.get("sales_price"),
                    target_month=rec.get("target_month"),
                ))
        except Exception as e:
            logger.debug("Skip commission upsert: %s", e)

        data = map_at_product_to_offer(it, commission=policies, promotion=promotions_data)
        if not data.get("url") or not data.get("source_id"):
            continue

        data["campaign_id"] = camp_id
        data["source_type"] = "manual"
        _camp_row = crud.get_campaign_by_cid(db, camp_id)
        if _camp_row:
            us = (_camp_row.user_registration_status or "").upper()
            data["approval_status"] = (
                "successful" if us == "APPROVED" else
                "pending" if us == "PENDING" else
                "unregistered" if us == "NOT_REGISTERED" else None
            )
            data["eligible_commission"] = (
                (_camp_row.status == "running") and (us in ("APPROVED", "SUCCESSFUL"))
            )

        if not await _check_url_alive(str(data.get("url") or "")):
            logger.info("Skip dead product [manual ingest]: title='%s'", data.get("title"))
            _vlog("dead_url", {"url": data.get("url")})
            continue

        crud.upsert_offer_by_source(db, schemas.ProductOfferCreate(**data))
        imported += 1

    return {"ok": True, "imported": imported}

async def ingest_accesstrade_datafeeds_all(
    req: IngestAllDatafeedsReq,
    db: Session = Depends(get_db),
):

    # D√πng lu√¥n session `db` t·ª´ Depends; kh√¥ng m·ªü/ƒë√≥ng session m·ªõi t·∫°i ƒë√¢y
    from accesstrade_service import fetch_campaigns_full_all, fetch_campaign_detail
    items = await fetch_campaigns_full_all(
        db,
        status="running",
        limit_per_page=req.limit_per_page or 100,
        max_pages=req.max_pages or 200,
        throttle_ms=req.throttle_ms or 0
    )
    imported = 0
    for camp in (items or []):
        try:
            camp_id = str(camp.get("campaign_id") or camp.get("id") or "").strip()
            merchant = str(camp.get("merchant") or camp.get("name") or "").lower().strip()
            status_val = camp.get("status")
            approval_val = camp.get("approval")

            # map status "1/0" -> "running/paused" n·∫øu API tr·∫£ d·∫°ng s·ªë
            def _map_status(v):
                s = str(v).strip() if v is not None else None
                if s == "1": return "running"
                if s == "0": return "paused"
                return s

            # T√°ch approval (ki·ªÉu duy·ªát campaign) ‚Üî user_status (tr·∫°ng th√°i ƒëƒÉng k√Ω c·ªßa ri√™ng m√¨nh)
            def _split_approval_or_user(v):
                if v is None:
                    return (None, None)
                s = str(v).strip().lower()
                if s in ("successful", "pending", "unregistered"):
                    # ƒê√¢y th·ª±c ch·∫•t l√† tr·∫°ng th√°i ƒëƒÉng k√Ω c·ªßa b·∫°n
                    user = "APPROVED" if s == "successful" else s.upper()
                    return (None, user)
                return (str(v), None)

            approval_for_campaign, user_status = _split_approval_or_user(approval_val)

            # NEW: n·∫øu API kh√¥ng cung c·∫•p user_status, d√πng gi√° tr·ªã c≈© trong DB ƒë·ªÉ tr√°nh m·∫•t record
            existing = crud.get_campaign_by_cid(db, camp_id)
            eff_user = user_status or (existing.user_registration_status if existing else None)

            # L·ªçc: ch·ªâ gi·ªØ APPROVED/PENDING
            if eff_user not in ("APPROVED", "PENDING"):
                continue
            # Kh√¥ng enrich ·ªü job ƒë·ªãnh k·ª≥ ƒë·ªÉ nhanh (c√≥ th·ªÉ b·∫≠t ·ªü API /ingest/v2/campaigns/sync)

            payload = schemas.CampaignCreate(
                campaign_id=camp_id,
                merchant=merchant or None,
                name=camp.get("name"),
                status=_map_status(status_val),
                approval=approval_for_campaign,                 # KH√îNG c√≤n ghi 'successful/pending/unregistered' ·ªü ƒë√¢y
                start_time=camp.get("start_time"),
                end_time=camp.get("end_time"),
                user_registration_status=user_status,           # NOT_REGISTERED/PENDING/APPROVED ho·∫∑c None
            )

            crud.upsert_campaign(db, payload)
            imported += 1
        except Exception as e:
            logger.debug("Skip campaign upsert: %s", e)

    logger.info("Scheduled campaigns sync done: %s", imported)

    from accesstrade_service import (
        fetch_products, fetch_active_campaigns, fetch_promotions,
        fetch_commission_policies, fetch_campaign_detail,
        map_at_product_to_offer, _check_url_alive
    )

    # 0) L·∫•y danh s√°ch campaign ƒëang ch·∫°y ƒë·ªÉ l·ªçc
    active_campaigns = await fetch_active_campaigns(db)  # dict {campaign_id: merchant}
    if not active_campaigns:
        # Fallback: l·∫•y t·ª´ DB n·∫øu API kh√¥ng tr·∫£ (·ªïn ƒë·ªãnh cho smoke test)
        active_campaigns = {
            c.campaign_id: c.merchant
            for c in db.query(models.Campaign)
                        .filter(models.Campaign.status == "running")
                        .filter(models.Campaign.user_registration_status.in_(["APPROVED","SUCCESSFUL"]))
                        .all()
            if c.campaign_id and c.merchant
        }
    merchant_campaign_map = {v: k for k, v in active_campaigns.items()}  # {merchant: campaign_id}

    # Map merchant -> approved campaign_id (running + user APPROVED/SUCCESSFUL) for fallback rebinding
    approved_cid_by_merchant: dict[str, str] = {}
    try:
        for cid, m in active_campaigns.items():
            _row = crud.get_campaign_by_cid(db, cid)
            if _row and (_row.user_registration_status or "").upper() in ("APPROVED", "SUCCESSFUL"):
                approved_cid_by_merchant[(m or "").lower()] = cid
    except Exception:
        pass

    # ch√≠nh s√°ch ingest (API b·ªè qua policy; policy ch·ªâ √°p d·ª•ng cho import Excel)
    only_with_commission = False

    # 2) Cache promotions theo merchant ƒë·ªÉ tr√°nh g·ªçi tr√πng
    promotion_cache: dict[str, list[dict]] = {}

    # NEW: Cache commission theo campaign_id ƒë·ªÉ tr√°nh spam API (fix NameError)
    cache_commissions: dict[str, list[dict]] = {}

    # 3) Tham s·ªë g·ªçi API datafeeds + b·ªô l·ªçc ph√≠a server
    base_params = dict(req.params or {})
    base_params.pop("page", None)   # client kh√¥ng c·∫ßn truy·ªÅn
    base_params.pop("limit", None)  # client kh√¥ng c·∫ßn truy·ªÅn

    # Chu·∫©n ho√° alias filters
    filter_merchant = (base_params.get("merchant") or base_params.get("campaign") or base_params.get("merchant_slug"))
    if isinstance(filter_merchant, str):
        filter_merchant = filter_merchant.strip().lower()
    filter_cid = (base_params.get("campaign_id") or base_params.get("camp_id"))
    if isinstance(filter_cid, str):
        filter_cid = filter_cid.strip()

    imported = 0
    total_pages = 0

    # X√¢y danh s√°ch merchants c·∫ßn ch·∫°y: ∆∞u ti√™n t·ª´ active_campaigns (ƒëang ch·∫°y) ‚à© DB (APPROVED)
    approved_merchants: set[str] = set()
    try:
        for cid, m in active_campaigns.items():
            _row = crud.get_campaign_by_cid(db, cid)
            if _row and (_row.user_registration_status or "").upper() in ("APPROVED", "SUCCESSFUL"):
                approved_merchants.add((m or "").lower())
    except Exception:
        pass
    if not approved_merchants:
        # Fallback: l·∫•y t·ª´ DB
        approved_merchants = {
            (c.merchant or "").lower()
            for c in db.query(models.Campaign)
                        .filter(models.Campaign.status == "running")
                        .filter(models.Campaign.user_registration_status.in_(["APPROVED","SUCCESSFUL"]))
                        .all()
            if c.merchant
        }

    # √Åp d·ª•ng filter merchant/campaign_id n·∫øu c√≥
    forced_cid_by_merchant: dict[str, str] = {}
    if filter_cid:
        # N·∫øu campaign_id c√≥ trong active list, gi·ªõi h·∫°n merchant t∆∞∆°ng ·ª©ng
        cid = str(filter_cid)
        m = active_campaigns.get(cid)
        if m:
            m_norm = (m or "").lower()
            approved_merchants = {m_norm} if m_norm in approved_merchants else set()
            forced_cid_by_merchant[m_norm] = cid
        else:
            # Kh√¥ng t√¨m th·∫•y campaign_id ƒëang ch·∫°y ‚Üí kh√¥ng ingest g√¨
            approved_merchants = set()

    if filter_merchant:
        m_norm = filter_merchant
        # alias n·ªôi b·ªô
        _alias = {"lazadacps": "lazada", "tikivn": "tiki"}
        m_norm = _alias.get(m_norm, m_norm)
        if approved_merchants:
            approved_merchants = {m for m in approved_merchants if (m == m_norm or m.endswith(m_norm) or (m_norm in m))}
        else:
            # n·∫øu tr∆∞·ªõc ƒë√≥ r·ªóng (v√≠ d·ª• ƒë√£ l·ªçc theo campaign_id kh√¥ng kh·ªõp) th√¨ gi·ªØ r·ªóng
            pass

    # verbose helper
    def _vlog(reason: str, extra: dict | None = None):
        try:
            from accesstrade_service import _log_jsonl as _rawlog
            payload = {"endpoint": "datafeeds_all", "reason": reason}
            if extra:
                payload.update(extra)
            _rawlog("ingest_skips.jsonl", payload)
        except Exception:
            pass

    # L·∫∑p t·ª´ng merchant ƒë√£ APPROVED v√† g·ªçi /v1/datafeeds v·ªõi b·ªô l·ªçc merchant
    for m in sorted(approved_merchants):
        _alias = {"lazadacps": "lazada", "tikivn": "tiki"}
        merchant_fetch = _alias.get(m, m)

        # X√°c ƒë·ªãnh campaign_id t∆∞∆°ng ·ª©ng merchant ƒëang fetch (∆∞u ti√™n exact, sau ƒë√≥ suffix/contains)
        cid_for_fetch = None
        # ∆Øu ti√™n forced campaign id n·∫øu ƒë√£ x√°c ƒë·ªãnh
        if m in forced_cid_by_merchant:
            cid_for_fetch = forced_cid_by_merchant[m]
        for cid, mm in active_campaigns.items():
            if (mm or "").lower() == merchant_fetch or (mm or "").lower() == m:
                cid_for_fetch = cid
                break
        if not cid_for_fetch:
            for cid, mm in active_campaigns.items():
                mm_l = (mm or "").lower()
                if mm_l.endswith(merchant_fetch) or f"_{merchant_fetch}" in mm_l or (merchant_fetch in mm_l):
                    cid_for_fetch = cid
                    break
        if not cid_for_fetch and merchant_fetch != m:
            for cid, mm in active_campaigns.items():
                mm_l = (mm or "").lower()
                if mm_l.endswith(m) or f"_{m}" in mm_l or (m in mm_l):
                    cid_for_fetch = cid
                    break

        page = 1
        while page <= max(1, req.max_pages):
            params = dict(base_params)
            params["page"] = str(page)
            params["limit"] = str(req.limit_per_page)
            params["merchant"] = merchant_fetch

            items = await fetch_products(db, "/v1/datafeeds", params)
            if not items:
                # Kh√¥ng c√≥ d·ªØ li·ªáu cho merchant/page n√†y ‚Üí d·ª´ng merchant
                break

            # X·ª≠ l√Ω t·ª´ng item
            for it in items:
                # G·∫Øn merchant theo v√≤ng l·∫∑p ngo√†i v√† force-bind campaign_id theo merchant ƒëang fetch
                merchant_norm = m
                camp_id = cid_for_fetch

                # B·ªè qua n·∫øu campaign kh√¥ng active
                if not camp_id or camp_id not in active_campaigns:
                    if req.verbose:
                        _vlog("campaign_not_active", {"campaign_id": camp_id, "merchant": merchant_norm, "page": page})
                    continue

                # Y√äU C·∫¶U: user APPROVED
                try:
                    _row = crud.get_campaign_by_cid(db, camp_id)
                    us = (_row.user_registration_status or "").upper() if _row else ""
                    if (not _row) or (us not in ("APPROVED", "SUCCESSFUL")):
                        # Fallback: n·∫øu merchant c√≥ campaign kh√°c ƒë√£ APPROVED, d√πng campaign ƒë√≥
                        alt_cid = approved_cid_by_merchant.get(merchant_norm)
                        if alt_cid:
                            if req.verbose:
                                _vlog("rebind_campaign_id", {"from": camp_id, "to": alt_cid, "merchant": merchant_norm, "page": page})
                            camp_id = alt_cid
                        else:
                            if req.verbose:
                                _vlog("campaign_not_approved", {"campaign_id": camp_id, "merchant": merchant_norm, "page": page})
                            continue
                except Exception:
                    continue

                # L·∫•y commission theo camp_id (cache)
                policies = cache_commissions.get(camp_id)
                if policies is None:
                    try:
                        policies = await fetch_commission_policies(db, camp_id)
                        cache_commissions[camp_id] = policies or []
                        for p in (policies or []):
                            crud.upsert_commission_policy(db, schemas.CommissionPolicyCreate(
                                campaign_id=str(camp_id),
                                reward_type=p.get("reward_type") or p.get("type"),
                                sales_ratio=p.get("sales_ratio") or p.get("ratio"),
                                sales_price=p.get("sales_price"),
                                target_month=p.get("target_month"),
                            ))
                    except Exception:
                        policies = []
                        logger.debug("Skip commission upsert")

                if only_with_commission:
                    eligible_by_status = False
                    try:
                        _camp_row = crud.get_campaign_by_cid(db, camp_id)
                        if _camp_row:
                            _us = (_camp_row.user_registration_status or "").upper()
                            eligible_by_status = (_camp_row.status == "running") and (_us == "APPROVED")
                    except Exception:
                        eligible_by_status = False

                    has_commission = bool(policies) or eligible_by_status
                    if not has_commission:
                        if req.verbose:
                            _vlog("no_commission", {"campaign_id": camp_id, "merchant": merchant_norm, "page": page})
                        continue

                # Promotions: l·∫•y theo merchant, c√≥ cache + upsert DB
                if merchant_norm not in promotion_cache:
                    promotion_cache[merchant_norm] = await fetch_promotions(db, merchant_norm) or []
                pr_list = promotion_cache.get(merchant_norm, [])
                if pr_list:
                    for prom in pr_list:
                        try:
                            crud.upsert_promotion(db, schemas.PromotionCreate(
                                campaign_id=camp_id,
                                name=prom.get("name"),
                                content=prom.get("content") or prom.get("description"),
                                start_time=prom.get("start_time"),
                                end_time=prom.get("end_time"),
                                coupon=prom.get("coupon"),
                                link=prom.get("link"),
                            ))
                        except Exception as e:
                            logger.debug("Skip promotion upsert: %s", e)

                # Campaign detail: ƒë·ªìng nh·∫•t upsert
                try:
                    camp = await fetch_campaign_detail(db, camp_id)
                    if camp:
                        status_val = camp.get("status")
                        approval_val = camp.get("approval")

                        def _map_status(v):
                            s = str(v).strip() if v is not None else None
                            if s == "1": return "running"
                            if s == "0": return "paused"
                            return s

                        _user_raw = (
                            camp.get("user_registration_status")
                            or camp.get("publisher_status")
                            or camp.get("user_status")
                        )
                        crud.upsert_campaign(db, schemas.CampaignCreate(
                            campaign_id=str(camp.get("campaign_id") or camp_id),
                            merchant=str(camp.get("merchant") or merchant_norm or "").lower() or None,
                            name=camp.get("name"),
                            status=_map_status(status_val),
                            approval=(str(approval_val) if approval_val is not None else None),
                            start_time=camp.get("start_time"),
                            end_time=camp.get("end_time"),
                            user_registration_status=(_user_raw if _user_raw not in (None, "", []) else None),
                        ))
                except Exception as e:
                    logger.debug("Skip campaign upsert: %s", e)

                # Chu·∫©n ho√° record ‚Üí ProductOfferCreate
                data = map_at_product_to_offer(it, commission=policies, promotion=pr_list)
                if not data or not data.get("url"):
                    continue
                data["campaign_id"] = camp_id

                # NEW: g·∫Øn lo·∫°i ngu·ªìn + tr·∫°ng th√°i ph√™ duy·ªát & eligibility
                data["source_type"] = "datafeeds"
                _camp_row = crud.get_campaign_by_cid(db, camp_id)
                if _camp_row:
                    us = (_camp_row.user_registration_status or "").upper()
                    data["approval_status"] = (
                        "successful" if us == "APPROVED" else
                        "pending" if us == "PENDING" else
                        "unregistered" if us == "NOT_REGISTERED" else None
                    )
                    data["eligible_commission"] = (
                        (_camp_row.status == "running") and (us in ("APPROVED", "SUCCESSFUL"))
                    )

                # Link g·ªëc: ch·ªâ ki·ªÉm tra khi b·∫≠t c·ªù (ƒë·ªÉ tr√°nh b·ªè s√≥t do ch·∫∑n bot/timeout trong m√¥i tr∆∞·ªùng container)
                if req.check_urls:
                    if not await _check_url_alive(data["url"]):
                        if req.verbose:
                            _vlog("dead_url", {"url": data.get("url"), "merchant": merchant_norm, "page": page})
                        continue

                crud.upsert_offer_by_source(db, schemas.ProductOfferCreate(**data))
                imported += 1

            # Sau khi x·ª≠ l√Ω xong 1 trang cho merchant hi·ªán t·∫°i
            total_pages += 1
            # D·ª´ng n·∫øu trang hi·ªán t·∫°i √≠t h∆°n limit ‚Üí coi nh∆∞ trang cu·ªëi
            if len(items) < (req.limit_per_page or 100):
                break

            # Trang ti·∫øp theo
            page += 1
            sleep_ms = getattr(req, "throttle_ms", 0) or 0
            if sleep_ms:
                await asyncio.sleep(sleep_ms / 1000.0)

    return {"ok": True, "imported": imported, "pages": total_pages}

async def ingest_v2_campaigns_sync(
    req: CampaignsSyncReq,
    db: Session = Depends(get_db),
):
    from accesstrade_service import fetch_campaigns_full_all, fetch_campaign_detail

    # --- gom d·ªØ li·ªáu theo nhi·ªÅu tr·∫°ng th√°i (running/paused/...) n·∫øu ƒë∆∞·ª£c truy·ªÅn ---
    statuses = (req.statuses or ["running"])  # m·∫∑c ƒë·ªãnh ch·ªâ 'running' ƒë·ªÉ nhanh; b·∫°n c√≥ th·ªÉ g·ª≠i ["running","paused"]
    unique = {}
    for st in statuses:
        try:
            items = await fetch_campaigns_full_all(
                db,
                status=st,
                limit_per_page=req.limit_per_page or 50,
                max_pages=1000,
                throttle_ms=req.throttle_ms or 0,
                page_concurrency=req.page_concurrency or 6,
                window_pages=req.window_pages or 10,
            )
            for it in (items or []):
                cid = str(it.get("campaign_id") or it.get("id") or "").strip()
                if cid:
                    unique[cid] = it
        except Exception as e:
            logger.error("ingest_v2_campaigns_sync: fetch failed (%s): %s", st, e)

    imported = 0

    def _map_status(v):
        s = str(v).strip() if v is not None else None
        if s == "1": return "running"
        if s == "0": return "paused"
        return s

    def _split_approval_or_user(v):
        """
        N·∫øu AT tr·∫£ 'approval' ‚àà {successful,pending,unregistered} th√¨ ƒë√¢y th·ª±c ch·∫•t l√† user_status.
        Tr·∫£ v·ªÅ tuple: (approval_for_campaign, user_status_for_me)
        """
        if v is None:
            return (None, None)
        s = str(v).strip().lower()
        if s in ("successful", "pending", "unregistered"):
            # map v·ªÅ NOT_REGISTERED/PENDING/APPROVED
            user = "APPROVED" if s == "successful" else s.upper()
            return (None, user)
        # c√≤n l·∫°i ƒë·ªÉ nguy√™n cho ki·ªÉu duy·ªát (auto/manual/‚Ä¶)
        return (str(v), None)

    for camp in unique.values():
        try:
            camp_id = str(camp.get("campaign_id") or camp.get("id") or "").strip()
            merchant = str(camp.get("merchant") or camp.get("name") or "").lower().strip()
            if req.merchant and merchant != req.merchant.strip().lower():
                continue

            status_val = _map_status(camp.get("status"))
            approval_val, user_status = _split_approval_or_user(camp.get("approval"))

            # enrich user_status t·ª´ detail n·∫øu b·∫≠t c·ªù (ch√≠nh x√°c h∆°n)
            if req.enrich_user_status or (req.only_my and not user_status):
                try:
                    det = await fetch_campaign_detail(db, camp_id)
                    if det:
                        _user_raw = (
                            det.get("user_registration_status")
                            or det.get("publisher_status")
                            or det.get("user_status")
                        )
                        # Fallback: ƒë√¥i khi detail ch·ªâ tr·∫£ 'approval' = successful/pending/unregistered
                        if not _user_raw:
                            appr_det = det.get("approval")
                            if isinstance(appr_det, str) and appr_det.lower() in ("successful","pending","unregistered"):
                                _user_raw = "APPROVED" if appr_det.lower() == "successful" else appr_det.upper()
                        if _user_raw not in (None, "", []):
                            user_status = str(_user_raw).strip().upper()
                except Exception:
                    pass

            # L·ªçc only_my: ch·ªâ gi·ªØ APPROVED/PENDING.
            # N·∫øu ƒë√£ b·∫≠t enrich_user_status nh∆∞ng v·∫´n KH√îNG l·∫•y ƒë∆∞·ª£c user_status (API kh√¥ng tr·∫£),
            # cho ph√©p import ƒë·ªÉ l∆∞u l·∫°i tr∆∞·ªõc (tr√°nh imported=0 ·ªü l·∫ßn ƒë·∫ßu).
            if req.only_my:
                existing = crud.get_campaign_by_cid(db, camp_id)
                eff_user = user_status or (existing.user_registration_status if existing else None)
                if eff_user not in ("APPROVED", "PENDING"):
                    if req.enrich_user_status and eff_user is None:
                        logger.debug("only_my=true: allow %s (%s) d√π user_status ch∆∞a r√µ (first-run).", camp_id, merchant)
                    else:
                        logger.debug("only_my=true: skip %s (%s) v√¨ user_status=%s", camp_id, merchant, eff_user)
                        continue

            payload = schemas.CampaignCreate(
                campaign_id=camp_id,
                merchant=merchant or None,
                name=camp.get("name"),
                status=status_val,
                approval=approval_val,                  # KH√îNG c√≤n ghi 'successful' ·ªü ƒë√¢y n·ªØa
                start_time=camp.get("start_time"),
                end_time=camp.get("end_time"),
                user_registration_status=user_status,   # NOT_REGISTERED / PENDING / APPROVED / None
            )
            crud.upsert_campaign(db, payload)
            imported += 1
        except Exception as e:
            logger.debug("Skip campaign upsert: %s", e)

    return {"ok": True, "imported": imported}

# (Removed) Aliases for Accesstrade routes ‚Äî use unified endpoints instead

async def ingest_v2_promotions(
    req: IngestV2PromotionsReq,
    db: Session = Depends(get_db),
):
    from accesstrade_service import fetch_promotions, fetch_active_campaigns, _check_url_alive
    imported_promos = 0
    imported_offers = 0

    # 0) X√°c ƒë·ªãnh merchant c·∫ßn ch·∫°y: 1 merchant ho·∫∑c t·∫•t c·∫£ merchant ƒëang active
    active = await fetch_active_campaigns(db)  # {campaign_id: merchant}
    merchants = set(active.values())
    if not merchants:
        # Fallback: t·ª´ DB
        merchants = {
            (c.merchant or "").lower()
            for c in db.query(models.Campaign)
                        .filter(models.Campaign.status == "running")
                        .filter(models.Campaign.user_registration_status.in_(["APPROVED","SUCCESSFUL"]))
                        .all()
            if c.merchant
        }
    if req.merchant:
        merchants = {req.merchant.strip().lower()}

    # 1) V√≤ng l·∫∑p t·ª´ng merchant
    for m in sorted(merchants):
        _alias = {"lazadacps": "lazada", "tikivn": "tiki"}
        m_fetch = _alias.get(m, m)
        promos = await fetch_promotions(db, m_fetch) or []
        # upsert b·∫£ng promotions
        for p in promos:
            try:
                # map campaign_id t·ª´ merchant
                # ∆∞u ti√™n exact, n·∫øu kh√¥ng c√≥ th√¨ b·ªè tr·ªëng
                campaign_id = None
                # ∆Øu ti√™n exact theo m ho·∫∑c m_fetch
                for cid, mm in active.items():
                    mm_l = (mm or "").lower()
                    if mm_l == m or mm_l == m_fetch:
                        campaign_id = cid
                        break
                # N·∫øu ch∆∞a kh·ªõp, th·ª≠ suffix/contains (ƒë·ª° l·ªách alias)
                if not campaign_id:
                    for cid, mm in active.items():
                        mm_l = (mm or "").lower()
                        if mm_l.endswith(m) or f"_{m}" in mm_l or (m in mm_l):
                            campaign_id = cid
                            break
                if not campaign_id and m_fetch != m:
                    for cid, mm in active.items():
                        mm_l = (mm or "").lower()
                        if mm_l.endswith(m_fetch) or f"_{m_fetch}" in mm_l or (m_fetch in mm_l):
                            campaign_id = cid
                            break

                crud.upsert_promotion(db, schemas.PromotionCreate(
                    campaign_id=campaign_id or "",
                    name=p.get("name"),
                    content=p.get("content") or p.get("description"),
                    start_time=p.get("start_time"),
                    end_time=p.get("end_time"),
                    coupon=p.get("coupon"),
                    link=p.get("link"),
                ))
                imported_promos += 1

                if req.create_offers:
                    # map promotion -> offer t·ªëi thi·ªÉu
                    title = p.get("name") or "Khuy·∫øn m√£i"
                    link = p.get("link") or p.get("url")
                    aff = p.get("aff_link")
                    img = p.get("image") or p.get("thumb") or p.get("banner")

                    # CHO PH√âP T·∫†O OFFER KHI CH·ªà C√ì aff_link
                    if not link and not aff:
                        logger.debug("[PROMO] skip: no link/aff for %s (merchant=%s)", title, m)
                        continue

                    url_to_check = link or aff

                    # (policy) ch·ªâ check khi b·∫≠t c·ªù
                    alive = True if not req.check_urls else await _check_url_alive(str(url_to_check or ""))
                    if not alive:
                        logger.debug("[PROMO] skip: dead url %s", url_to_check)
                        continue

                    # source_id c·ªë ƒë·ªãnh theo link/aff_link ƒë·ªÉ idempotent
                    sid_base = (link or aff or "").encode("utf-8")
                    sid = hashlib.md5(sid_base).hexdigest()
                    extra = {
                        "source_type": "promotions",
                        "raw": p,
                    }
                    # Ch·ªâ t·∫°o offer n·∫øu campaign ƒë√£ duy·ªát (SUCCESSFUL/APPROVED)
                    try:
                        _row = crud.get_campaign_by_cid(db, campaign_id) if campaign_id else None
                        _user = (_row.user_registration_status or "").upper() if _row else ""
                        if not _row or _user not in ("APPROVED", "SUCCESSFUL"):
                            continue
                    except Exception:
                        continue

                    payload = schemas.ProductOfferCreate(
                        source="accesstrade",
                        source_id=f"promo:{m}:{sid}",
                        merchant=m,
                        title=title,
                        url=link,
                        affiliate_url=aff,
                        image_url=img,
                        price=None,
                        currency="VND",
                        campaign_id=campaign_id,
                        source_type="promotions",
                        # eligible_commission = campaign ƒëang ch·∫°y & user APPROVED/SUCCESSFUL (d√πng _row ƒë√£ truy v·∫•n tr∆∞·ªõc ƒë√≥)
                        eligible_commission=bool(
                            _row
                            and _row.status == "running"
                            and (_row.user_registration_status or "").upper() in ("APPROVED", "SUCCESSFUL")
                        ),
                        affiliate_link_available=bool(aff),
                        extra=json.dumps(extra, ensure_ascii=False),
                    )
                    crud.upsert_offer_by_source(db, payload)
                    imported_offers += 1
            except Exception as e:
                logger.debug("Skip promotion/offer upsert: %s", e)

    return {"ok": True, "promotions": imported_promos, "offers_from_promotions": imported_offers}

"""Legacy provider-specific routes have been removed. Use unified endpoints."""

async def ingest_v2_top_products(
    req: IngestV2TopProductsReq,
    db: Session = Depends(get_db),
):
    from accesstrade_service import fetch_top_products, fetch_active_campaigns, _check_url_alive

    # 0) map merchant -> campaign_id ƒë·ªÉ g·∫Øn campaign_id cho offer
    active = await fetch_active_campaigns(db)  # {campaign_id: merchant}
    if not active:
        active = {
            c.campaign_id: c.merchant
            for c in db.query(models.Campaign)
                        .filter(models.Campaign.status == "running")
                        .filter(models.Campaign.user_registration_status.in_(["APPROVED","SUCCESSFUL"]))
                        .all()
            if c.campaign_id and c.merchant
        }
    m_req = (req.merchant or "").lower()
    _alias = {"lazadacps": "lazada", "tikivn": "tiki"}
    m_fetch = _alias.get(m_req, m_req)

    campaign_id = None
    for cid, mm in active.items():
        mm_l = (mm or "").lower()
        if mm_l == m_req or mm_l == m_fetch:
            campaign_id = cid
            break
    if not campaign_id:
        for cid, mm in active.items():
            mm_l = (mm or "").lower()
            if mm_l.endswith(m_req) or f"_{m_req}" in mm_l or (m_req in mm_l):
                campaign_id = cid
                break
    if not campaign_id and m_fetch != m_req:
        for cid, mm in active.items():
            mm_l = (mm or "").lower()
            if mm_l.endswith(m_fetch) or f"_{m_fetch}" in mm_l or (m_fetch in mm_l):
                campaign_id = cid
                break

    # DEFAULT date range: 7 ng√†y g·∫ßn nh·∫•t n·∫øu kh√¥ng truy·ªÅn
    if not req.date_from or not req.date_to:
        from datetime import datetime, timedelta, UTC
        _to = datetime.now(UTC).date()
        _from = _to - timedelta(days=7)
        date_from_use = req.date_from or _from.strftime("%Y-%m-%d")
        date_to_use = req.date_to or _to.strftime("%Y-%m-%d")
    else:
        date_from_use = req.date_from
        date_to_use = req.date_to

    page = 1
    imported = 0
    while page <= max(1, req.max_pages):
        items = await fetch_top_products(
            db,
            merchant=m_fetch,  # d√πng alias ƒë·ªÉ g·ªçi API ·ªïn ƒë·ªãnh
            date_from=date_from_use,
            date_to=date_to_use,
            page=page,
            limit=req.limit_per_page
        )
        if not items:
            break

        for it in items:
            try:
                title = it.get("name") or "S·∫£n ph·∫©m"
                link = it.get("link") or it.get("url")
                aff = it.get("aff_link")
                img = it.get("image") or it.get("thumb")
                price = it.get("price")
                product_id = it.get("product_id") or it.get("id")

                if not link and not aff:
                    logger.debug("[TOP] skip: no link/aff for %s", title)
                    continue
                # ∆Øu ti√™n link g·ªëc cho tr∆∞·ªùng url (affiliate_url s·∫Ω gi·ªØ aff)
                url_to_check = link or aff

                # (policy) ch·ªâ check khi b·∫≠t c·ªù
                alive = True if not req.check_urls else await _check_url_alive(str(url_to_check or ""))
                if not alive:
                    logger.debug("[TOP] skip: dead url %s", url_to_check)
                    continue

                # idempotent theo product_id n·∫øu c√≥, n·∫øu kh√¥ng theo link
                base_key = str(product_id or url_to_check)
                sid = hashlib.md5(base_key.encode("utf-8")).hexdigest()

                extra = {
                    "source_type": "top_products",
                    "raw": it,
                }
                # Ch·ªâ t·∫°o offer n·∫øu campaign APPROVED (API b·ªè qua policy nh∆∞ng v·∫´n y√™u c·∫ßu APPROVED)
                try:
                    _row = crud.get_campaign_by_cid(db, campaign_id) if campaign_id else None
                    _user = (_row.user_registration_status or "").upper() if _row else ""
                    if not _row or _user not in ("APPROVED", "SUCCESSFUL"):
                        continue
                except Exception:
                    continue

                payload = schemas.ProductOfferCreate(
                    source="accesstrade",
                    source_id=f"top:{req.merchant}:{sid}",
                    merchant=req.merchant,
                    title=title,
                    url=link or aff,
                    affiliate_url=aff,
                    image_url=img,
                    price=price,
                    currency="VND",
                    campaign_id=campaign_id,
                    source_type="top_products",
                    # eligible_commission = campaign ƒëang ch·∫°y & user APPROVED/SUCCESSFUL
                    eligible_commission=bool(
                        _row
                        and _row.status == "running"
                        and (_row.user_registration_status or "").upper() in ("APPROVED", "SUCCESSFUL")
                    ),
                    affiliate_link_available=bool(aff),
                    product_id=str(product_id) if product_id is not None else None,
                    extra=json.dumps(extra, ensure_ascii=False),
                )

                crud.upsert_offer_by_source(db, payload)
                imported += 1
            except Exception as e:
                logger.debug("Skip top_product upsert: %s", e)

        page += 1
        sleep_ms = getattr(req, "throttle_ms", 0) or 0
        if sleep_ms:
            await asyncio.sleep(sleep_ms / 1000.0)

    return {"ok": True, "imported": imported, "merchant": req.merchant}

# =============================================
# Unified provider-agnostic ingest endpoints üåê
# =============================================

class ProviderReq(BaseModel):
    provider: str = "accesstrade"

class CampaignsSyncUnifiedReq(ProviderReq, CampaignsSyncReq):
    pass

class PromotionsUnifiedReq(ProviderReq, IngestV2PromotionsReq):
    pass

class TopProductsUnifiedReq(ProviderReq, IngestV2TopProductsReq):
    pass

class DatafeedsAllUnifiedReq(ProviderReq, IngestAllDatafeedsReq):
    pass

@app.post(
    "/ingest/campaigns/sync",
    tags=["Ingest üåê"],
    summary="ƒê·ªìng b·ªô campaigns (provider-agnostic)",
    description="H·ªó tr·ª£ nhi·ªÅu provider qua tham s·ªë `provider`. Hi·ªán h·ªó tr·ª£: accesstrade."
)
async def ingest_campaigns_sync_unified(req: CampaignsSyncUnifiedReq, db: Session = Depends(get_db)):
    prov = (req.provider or "accesstrade").lower()
    if prov == "accesstrade":
        inner = CampaignsSyncReq(**req.model_dump(exclude={"provider"}))
        return await ingest_v2_campaigns_sync(inner, db)
    raise HTTPException(status_code=400, detail=f"Provider '{prov}' hi·ªán ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£")

@app.post(
    "/ingest/promotions",
    tags=["Ingest üåê"],
    summary="Ingest promotions (provider-agnostic)",
    description="H·ªó tr·ª£ nhi·ªÅu provider qua tham s·ªë `provider`. Hi·ªán h·ªó tr·ª£: accesstrade."
)
async def ingest_promotions_unified(req: PromotionsUnifiedReq, db: Session = Depends(get_db)):
    prov = (req.provider or "accesstrade").lower()
    if prov == "accesstrade":
        inner = IngestV2PromotionsReq(**req.model_dump(exclude={"provider"}))
        return await ingest_v2_promotions(inner, db)
    raise HTTPException(status_code=400, detail=f"Provider '{prov}' hi·ªán ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£")

@app.post(
    "/ingest/top-products",
    tags=["Ingest üåê"],
    summary="Ingest top products (provider-agnostic)",
    description="H·ªó tr·ª£ nhi·ªÅu provider qua tham s·ªë `provider`. Hi·ªán h·ªó tr·ª£: accesstrade."
)
async def ingest_top_products_unified(req: TopProductsUnifiedReq, db: Session = Depends(get_db)):
    prov = (req.provider or "accesstrade").lower()
    if prov == "accesstrade":
        inner = IngestV2TopProductsReq(**req.model_dump(exclude={"provider"}))
        return await ingest_v2_top_products(inner, db)
    raise HTTPException(status_code=400, detail=f"Provider '{prov}' hi·ªán ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£")

@app.post(
    "/ingest/datafeeds/all",
    tags=["Ingest üåê"],
    summary="Ingest datafeeds to√†n b·ªô (provider-agnostic)",
    description="H·ªó tr·ª£ nhi·ªÅu provider qua tham s·ªë `provider`. Hi·ªán h·ªó tr·ª£: accesstrade."
)
async def ingest_datafeeds_all_unified(req: DatafeedsAllUnifiedReq, db: Session = Depends(get_db)):
    prov = (req.provider or "accesstrade").lower()
    if prov == "accesstrade":
        inner = IngestAllDatafeedsReq(**req.model_dump(exclude={"provider"}))
        return await ingest_accesstrade_datafeeds_all(inner, db)
    raise HTTPException(status_code=400, detail=f"Provider '{prov}' hi·ªán ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£")

"""Legacy provider-specific routes have been removed. Use unified endpoints."""

"""Legacy provider-specific routes have been removed. Use unified endpoints."""

# ================================
# NEW: One-shot ingest ALL sources for APPROVED merchants
# ================================
## Removed deprecated endpoint: POST /ingest/v2/offers/all-approved (per requirements)

@app.put(
    "/offers/{offer_id}",
    tags=["Offers üõí"],
    summary="C·∫≠p nh·∫≠t th√¥ng tin s·∫£n ph·∫©m",
    description="S·ª≠a th√¥ng tin 1 s·∫£n ph·∫©m trong DB theo ID.",
    response_model=schemas.ProductOfferOut
)
def update_offer_api(offer_id: int, data: schemas.ProductOfferUpdate, db: Session = Depends(get_db)):
    obj = crud.update_offer(db, offer_id, data)
    if not obj:
        raise HTTPException(status_code=404, detail="Offer not found")
    return obj

@app.delete(
    "/offers/{offer_id}",
    tags=["Offers üõí"],
    summary="Xo√° 1 s·∫£n ph·∫©m",
    description="Xo√° m·ªôt s·∫£n ph·∫©m trong DB theo ID."
)
def delete_offer_api(offer_id: int, db: Session = Depends(get_db)):
    obj = crud.delete_offer(db, offer_id)
    if not obj:
        raise HTTPException(status_code=404, detail="Offer not found")
    return {"ok": True, "deleted_id": offer_id}

# --- API cleanup: x√≥a s·∫£n ph·∫©m c√≥ link ch·∫øt ---
@app.delete(
    "/offers/cleanup/dead",
    tags=["Offers üõí"],
    summary="D·ªçn link ch·∫øt (cleanup)",
    description="Qu√©t to√†n b·ªô s·∫£n ph·∫©m trong DB, ki·ªÉm tra link s·ªëng/ch·∫øt v√† **xo√° t·∫•t c·∫£** link ch·∫øt."
)
async def cleanup_dead_offers(db: Session = Depends(get_db)):
    offers = crud.list_offers(db, limit=1000)
    removed = 0
    alive_count = 0
    total = len(offers)
    for idx, o in enumerate(offers, start=1):
        if idx % 50 == 0 or idx == total:
            logger.info("Cleanup progress: %d/%d", idx, total)
        alive = await _check_url_alive(o.url)  # ch·ªâ d√πng link g·ªëc ƒë·ªÉ tr√°nh click ·∫£o
        if not alive:
            logger.info("Removing dead product via API: id=%s, title='%s'", o.id, o.title)
            db.delete(o)
            removed += 1
        else:
            alive_count += 1
    db.commit()
    logger.info("API cleanup done: %s dead / %s alive / %s scanned", removed, alive_count, total)
    return {"dead": removed, "alive": alive_count, "scanned": total}

@app.post(
    "/scheduler/linkcheck/rotate",
    tags=["Maintenance üßπ"],
    summary="Ki·ªÉm tra link s·ªëng theo l√°t c·∫Øt 10% v√† xoay v√≤ng",
    description=(
        "M·ªói l·∫ßn ch·∫°y s·∫Ω ki·ªÉm tra ~10% s·∫£n ph·∫©m theo ƒëi·ªÅu ki·ªán id % 10 = cursor. "
        "Sau khi ch·∫°y xong, cursor t·ª± tƒÉng (modulo 10). "
        "Tu·ª≥ ch·ªçn xo√° link ch·∫øt."
    )
)
async def scheduler_linkcheck_rotate(
    delete_dead: bool = False,
    db: Session = Depends(get_db),
):
    from accesstrade_service import _check_url_alive
    flags = crud.get_policy_flags(db)
    cursor = int(flags.get("linkcheck_cursor", 0)) % 10

    from models import ProductOffer
    slice_q = db.query(ProductOffer).filter(text("id % 10 = :cur")).params(cur=cursor)
    offers = slice_q.all()

    total = len(offers)
    removed = 0
    alive_count = 0
    for idx, o in enumerate(offers, start=1):
        if idx % 50 == 0 or idx == total:
            logger.info("[ROTATE] progress: %d/%d (cursor=%d)", idx, total, cursor)
        alive = await _check_url_alive(o.url)
        if alive:
            alive_count += 1
        else:
            if delete_dead:
                db.delete(o)
                removed += 1
    db.commit()

    next_cursor = (cursor + 1) % 10
    crud.set_policy_flag(db, "linkcheck_cursor", next_cursor)

    return {
        "cursor_used": cursor,
        "next_cursor": next_cursor,
        "scanned": total,
        "alive": alive_count,
        "deleted": removed,
    }

# --- API test nhanh: check 1 s·∫£n ph·∫©m trong DB ---
from datetime import datetime, UTC

@app.get(
    "/offers/check/{offer_id}",
    tags=["Offers üõí"],
    summary="Ki·ªÉm tra 1 s·∫£n ph·∫©m (alive/dead)",
    description="Ki·ªÉm tra nhanh tr·∫°ng th√°i link c·ªßa m·ªôt s·∫£n ph·∫©m trong DB theo ID."
)
async def check_offer_status(offer_id: int, db: Session = Depends(get_db)):
    offer = db.query(models.ProductOffer).filter(models.ProductOffer.id == offer_id).first()
    if not offer:
        raise HTTPException(status_code=404, detail="Offer not found")
    alive = await _check_url_alive(offer.url)  # ch·ªâ check link g·ªëc ƒë·ªÉ tr√°nh click ·∫£o
    return {
        "id": offer.id,
        "title": offer.title,
        "url": offer.url,
        "affiliate_url": offer.affiliate_url,
        "alive": alive,
    "checked_at": datetime.now(UTC).isoformat()
    }

"""Legacy v2 routes have been removed. Use unified endpoints."""

@app.delete(
    "/offers",
    tags=["Offers üõí"],
    summary="Xo√° to√†n b·ªô s·∫£n ph·∫©m",
    description="**C·∫£nh b√°o:** Xo√° t·∫•t c·∫£ s·∫£n ph·∫©m trong DB."
)
def delete_all_offers_api(db: Session = Depends(get_db)):
    count = crud.delete_all_offers(db)
    return {"ok": True, "deleted": count}

# --- Import s·∫£n ph·∫©m t·ª´ Excel ---
import pandas as pd
@app.post(
    "/offers/import-excel",
    tags=["Offers üõí"],
    summary="Import s·∫£n ph·∫©m t·ª´ Excel",
    description="Upload file Excel (.xlsx) ch·ª©a danh s√°ch s·∫£n ph·∫©m ƒë·ªÉ import v√†o DB."
)
async def import_offers_excel(file: UploadFile = File(...), db: Session = Depends(get_db)):
    if not file.filename.endswith(".xlsx"):
        raise HTTPException(status_code=400, detail="Ch·ªâ h·ªó tr·ª£ file .xlsx")

    try:
        # Read specifically the 'Products' sheet (if present). Fall back to first sheet.
        try:
            df = pd.read_excel(file.file, sheet_name="Products")
        except Exception:
            # fallback to first sheet
            file.file.seek(0)
            df = pd.read_excel(file.file)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"L·ªói ƒë·ªçc file Excel: {e}")

    # B·∫ÆT BU·ªòC: File Excel ph·∫£i c√≥ 2 h√†ng ti√™u ƒë·ªÅ
    # - H√†ng 1: ti√™u ƒë·ªÅ k·ªπ thu·∫≠t (t√™n c·ªôt g·ªëc) ‚Üí ƒë∆∞·ª£c pandas d√πng l√†m df.columns
    # - H√†ng 2: ti√™u ƒë·ªÅ ti·∫øng Vi·ªát (human-readable) ‚Üí l√† d√≤ng ƒë·∫ßu ti√™n c·ªßa df v√† s·∫Ω b·ªã b·ªè qua khi import
    # N·∫øu kh√¥ng c√≥ h√†ng 2 n√†y, tr·∫£ l·ªói 400 ƒë·ªÉ ƒë·∫£m b·∫£o th·ªëng nh·∫•t ƒë·ªãnh d·∫°ng trong d·ª± √°n
    # Map d·ªãch d√πng ƒë·ªÉ ki·ªÉm tra (h√†ng 2). ƒê√°nh d·∫•u (*) cho c·ªôt b·∫Øt bu·ªôc.
    trans_products = {
        "id": "M√£ ID", "source": "Ngu·ªìn", "source_id": "M√£ ngu·ªìn (*)", "source_type": "Lo·∫°i ngu·ªìn",
        "merchant": "Nh√† b√°n (*)",
        "title": "T√™n s·∫£n ph·∫©m (*)", "url": "Link g·ªëc", "affiliate_url": "Link ti·∫øp th·ªã",
        "image_url": "·∫¢nh s·∫£n ph·∫©m", "price": "Gi√°", "currency": "Ti·ªÅn t·ªá",
        "campaign_id": "Chi·∫øn d·ªãch", "product_id": "M√£ s·∫£n ph·∫©m ngu·ªìn", "affiliate_link_available": "C√≥ affiliate?",
        "domain": "T√™n mi·ªÅn", "sku": "SKU", "discount": "Gi√° KM", "discount_amount": "M·ª©c gi·∫£m",
        "discount_rate": "T·ª∑ l·ªá gi·∫£m (%)", "status_discount": "C√≥ khuy·∫øn m√£i?",
        "updated_at": "Ng√†y c·∫≠p nh·∫≠t", "desc": "M√¥ t·∫£ chi ti·∫øt",
        "cate": "Danh m·ª•c", "shop_name": "T√™n c·ª≠a h√†ng", "update_time_raw": "Th·ªùi gian c·∫≠p nh·∫≠t t·ª´ ngu·ªìn",
    }
    if df.empty:
        raise HTTPException(status_code=400, detail="File Excel tr·ªëng ho·∫∑c kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng (thi·∫øu d·ªØ li·ªáu)")
    # Ki·ªÉm tra d√≤ng ƒë·∫ßu ti√™n ph·∫£i l√† ti√™u ƒë·ªÅ ti·∫øng Vi·ªát (ch·∫•p nh·∫≠n c√≥/kh√¥ng d·∫•u (*))
    first = df.iloc[0]
    matches = 0
    total_keys = 0
    for k, v in trans_products.items():
        if k in df.columns:
            total_keys += 1
            try:
                def _norm_header(s: str) -> str:
                    s = str(s or "").strip()
                    # B·ªè "(*)" n·∫øu c√≥ ƒë·ªÉ t∆∞∆°ng th√≠ch ng∆∞·ª£c
                    return s.replace("(*)", "").replace("( * )", "").replace("(*) ", "").strip()
                if _norm_header(str(first[k])) == _norm_header(str(v)):
                    matches += 1
            except Exception:
                pass
    # Y√™u c·∫ßu: ph·∫£i kh·ªõp √≠t nh·∫•t 1/3 s·ªë c·ªôt hi·ªán di·ªán (t·ªëi thi·ªÉu 3 c·ªôt) ƒë·ªÉ coi l√† header ti·∫øng Vi·ªát h·ª£p l·ªá
    threshold = max(3, total_keys // 3)
    if not (total_keys and matches >= threshold):
        raise HTTPException(
            status_code=400,
            detail=(
                "File Excel thi·∫øu h√†ng ti√™u ƒë·ªÅ ti·∫øng Vi·ªát (h√†ng 2). "
                "M·ªçi file ph·∫£i c√≥ 2 h√†ng ti√™u ƒë·ªÅ: h√†ng 1 l√† t√™n c·ªôt k·ªπ thu·∫≠t, h√†ng 2 l√† t√™n c·ªôt ti·∫øng Vi·ªát."
            ),
        )
    # B·ªè qua h√†ng ti√™u ƒë·ªÅ ti·∫øng Vi·ªát ƒë·ªÉ ti·∫øn h√†nh import d·ªØ li·ªáu
    df = df.iloc[1:].reset_index(drop=True)
    # Ch·ªâ import Excel m·ªõi √°p d·ª•ng policy; m·∫∑c ƒë·ªãnh False n·∫øu ch∆∞a set
    flags = crud.get_policy_flags(db)
    only_with_commission = bool(flags.get("only_with_commission"))
    check_urls_excel = bool(flags.get("check_urls"))
    from accesstrade_service import _check_url_alive

    imported = 0
    skipped_required = 0
    required_errors: list[dict] = []
    
    def _opt_str(v):
        try:
            import pandas as _pd
            if v is None or (isinstance(v, float) and _pd.isna(v)) or (hasattr(_pd, "isna") and _pd.isna(v)):
                return None
        except Exception:
            if v is None:
                return None
        s = str(v)
        s = s.strip()
        return s if s != "" else None
    for _, row in df.iterrows():
        # Map columns expected in Products sheet coming from API datafeeds
        # Coerce and sanitize typical Excel NaN/empty values
        _price_val = row.get("price")
        try:
            if _price_val in (None, "") or (hasattr(pd, "isna") and pd.isna(_price_val)):
                _price_val = None
            else:
                _price_val = float(_price_val)
        except Exception:
            _price_val = None

        base = {
            "source": "excel",
            "source_type": "excel",
            "source_id": _opt_str(row.get("source_id") or row.get("product_id") or row.get("id") or "") or "",
            "merchant": (_opt_str(row.get("merchant") or row.get("campaign")) or "").lower(),
            "title": _opt_str(row.get("title") or row.get("name") or "") or "",
            "url": _opt_str(row.get("url") or row.get("landing_url") or "") or "",
            "affiliate_url": _opt_str(row.get("affiliate_url") or row.get("aff_link")),
            "image_url": _opt_str(row.get("image_url") or row.get("image") or row.get("thumbnail")),
            "price": _price_val,
            "currency": _opt_str(row.get("currency")) or "VND",
        }

        # REQUIRED validation: merchant, title, price, and at least one of url/affiliate_url
        missing = []
        if not base["merchant"]:
            missing.append("merchant")
        if not base["title"]:
            missing.append("title")
        if base.get("price") in (None,):
            missing.append("price")
        if not (base["url"] or base["affiliate_url"]):
            missing.append("url|affiliate_url")
        if missing:
            skipped_required += 1
            required_errors.append({"row": int(_)+2, "missing": missing})
            continue

        # Auto-generate source_id if missing: prefer URL, then affiliate_url, else hash of title+merchant
        if not base["source_id"]:
            import hashlib
            sid_src = base.get("url") or base.get("affiliate_url")
            if sid_src:
                base["source_id"] = hashlib.md5(str(sid_src).encode("utf-8")).hexdigest()
            else:
                seed = f"{base.get('title')}-{base.get('merchant')}"
                base["source_id"] = hashlib.md5(seed.encode("utf-8")).hexdigest()

        # Ghi campaign_id n·∫øu c√≥ trong file Excel
        campaign_id = row.get("campaign_id")
        if pd.notna(campaign_id):
            base["campaign_id"] = str(campaign_id).strip()

        # Gom promotion (if Products sheet contains promotion fields)
        promotion = {
            "name": row.get("promotion_name") or row.get("name"),
            "content": row.get("promotion_content") or row.get("content") or row.get("description"),
            "start_time": row.get("promotion_start_time") or row.get("start_time"),
            "end_time": row.get("promotion_end_time") or row.get("end_time"),
            "coupon": row.get("promotion_coupon") or row.get("coupon"),
            "link": row.get("promotion_link") or row.get("link"),
        }
        promotion = {k: v for k, v in promotion.items() if pd.notna(v)}

        # Gom commission (n·∫øu Products sheet c√≥ c√°c c·ªôt n√†y)
        commission = {
            "sales_ratio": row.get("sales_ratio") or row.get("commission_sales_ratio"),
            "sales_price": row.get("sales_price") or row.get("commission_sales_price"),
            "reward_type": row.get("reward_type") or row.get("commission_reward_type"),
            "target_month": row.get("target_month") or row.get("commission_target_month"),
        }
        commission = {k: v for k, v in commission.items() if pd.notna(v)}

        # G·ªôp v√†o extra (kh√¥ng c√≤n xu·∫•t extra_raw trong Excel, nh∆∞ng DB v·∫´n gi·ªØ extra n·∫øu c√≥)
        extra = {}
        if promotion:
            extra["promotion"] = promotion
        if commission:
            extra["commission"] = commission
        base["extra"] = json.dumps(extra, ensure_ascii=False)
        
        if only_with_commission:
            # X√°c ƒë·ªãnh ƒë·ªß ƒëi·ªÅu ki·ªán: c√≥ c·ªôt eligible_commission=True ho·∫∑c c√≥ √≠t nh·∫•t m·ªôt tr∆∞·ªùng commission h·ª£p l·ªá
            eligible_flag = False
            try:
                eligible_flag = bool(str(row.get("eligible_commission") or "").strip().lower() in ("true","1","yes"))
            except Exception:
                eligible_flag = False

            has_comm = False
            try:
                _comm = commission if isinstance(commission, dict) else {}
                for _k in ("sales_ratio","sales_price","reward_type","target_month"):
                    v = _comm.get(_k)
                    if v not in (None, "", float("nan")):
                        has_comm = True
                        break
            except Exception:
                has_comm = False

            if not (eligible_flag or has_comm):
                continue

        # Auto-convert url -> affiliate_url if missing and a template is available
        if (not base.get("affiliate_url")) and base.get("url") and base.get("merchant"):
            try:
                tpl = crud.get_affiliate_template(db, base["merchant"], "accesstrade")
                if tpl:
                    merged_params: dict[str, str] = {}
                    if tpl.default_params:
                        merged_params.update(tpl.default_params)
                    # apply template: replace {target} and any params
                    aff = tpl.template.replace("{target}", quote_plus(base["url"]))
                    for k, v in merged_params.items():
                        aff = aff.replace("{"+k+"}", str(v))
                    base["affiliate_url"] = aff
            except Exception:
                pass

        # Set affiliate_link_available by presence of affiliate_url
        base["affiliate_link_available"] = bool(base.get("affiliate_url"))

        data = schemas.ProductOfferCreate(**base)

        if not data.url or not data.source_id:
            continue

        # N·∫øu b·∫≠t check link cho Excel th√¨ ch·ªâ ghi khi url s·ªëng
        if check_urls_excel:
            try:
                if not await _check_url_alive(data.url or ""):
                    continue
            except Exception:
                continue

        crud.upsert_offer_by_source(db, data)
        imported += 1

    if required_errors:
        # Tr·∫£ th√¥ng tin th·ªëng k√™ ƒë·ªÉ ng∆∞·ªùi d√πng bi·∫øt l√Ω do b·ªè qua
        return {
            "ok": True,
            "imported": imported,
            "skipped_required": skipped_required,
            "errors": required_errors[:50]  # tr√°nh tr·∫£ qu√° d√†i
        }
    return {"ok": True, "imported": imported}

# --- Export s·∫£n ph·∫©m t·ª´ DB ra file Excel ---
@app.get(
    "/offers/export-excel",
    tags=["Offers üõí"],
    summary="Xu·∫•t Excel chuy√™n bi·ªát (Products/Campaigns/Commissions/Promotions)",
    description=(
        "Xu·∫•t Excel g·ªìm 4 sheet ƒë·ªôc l·∫≠p. Products ch·ªâ g·ªìm s·∫£n ph·∫©m t·ª´ API (datafeeds/top_products) v√† c√≥ c·ªôt source_type; "
        "Campaigns ch·ªâ c√°c campaign ƒë√£ APPROVED/SUCCESSFUL; Commissions/PROMotions ƒë·ªôc l·∫≠p, kh√¥ng ph·ª• thu·ªôc s·∫£n ph·∫©m."
    )
)
def export_offers_excel(
    merchant: str | None = None,
    title: str | None = None,
    skip: int = 0,
    limit: int = 0,  # n·∫øu =0 th√¨ xu·∫•t to√†n b·ªô
    db: Session = Depends(get_db)
):
    import os, json
    import pandas as pd
    from collections import defaultdict

    # 1) Products: ch·ªâ l·∫•y offers t·ª´ ngu·ªìn API (datafeeds/top_products)
    q_offers = db.query(models.ProductOffer).filter(
        models.ProductOffer.source_type.in_(["datafeeds", "top_products", "promotions", "manual", "excel"])  # m·ªü r·ªông theo y√™u c·∫ßu
    )
    if merchant:
        q_offers = q_offers.filter(models.ProductOffer.merchant == merchant.lower())
    if title:
        q_offers = q_offers.filter(models.ProductOffer.title.ilike(f"%{title.lower()}%"))
    if skip:
        q_offers = q_offers.offset(skip)
    if limit:
        q_offers = q_offers.limit(limit)
    offers = q_offers.all()

    # 2) Campaigns: ƒë·ªôc l·∫≠p, ch·ªâ APPROVED/SUCCESSFUL
    campaigns_all = db.query(models.Campaign).filter(
        (models.Campaign.user_registration_status.in_(["APPROVED", "SUCCESSFUL"]))
    ).all()
    campaign_map = {c.campaign_id: c for c in campaigns_all}

    # 3) Commissions: ƒë·ªôc l·∫≠p, l·∫•y t·ª´ b·∫£ng CommissionPolicy
    commissions_all = db.query(models.CommissionPolicy).all()

    # 4) Promotions: ƒë·ªôc l·∫≠p, l·∫•y t·ª´ b·∫£ng Promotion (k√®m merchant t·ª´ campaign n·∫øu c√≥)
    promotions_all = db.query(models.Promotion).all()

    # 5) ƒê·ªçc JSONL logs ƒë·ªÉ enrich Campaign fields (gi·ªëng tr∆∞·ªõc ƒë√¢y)
    LOG_DIR = os.getenv("API_LOG_DIR", "./logs")
    def _read_jsonl(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        yield json.loads(line)
                    except Exception:
                        pass
        except FileNotFoundError:
            return

    CAMP_LAST = {}
    for rec in _read_jsonl(os.path.join(LOG_DIR, "campaign_detail.jsonl")) or []:
        cid = str(rec.get("campaign_id") or "")
        if cid:
            CAMP_LAST[cid] = rec

    def _campaign_field_from_log(cid: str, field_name: str):
        rec = CAMP_LAST.get(str(cid) if cid is not None else "")
        if not rec:
            return "API_MISSING"
        if field_name == "end_time" and rec.get("has_end_time") is False:
            return "API_EMPTY"
        if field_name == "user_registration_status" and rec.get("has_user_status") is False:
            return "API_EMPTY"
        if rec.get("empty") is True:
            return "API_EMPTY"
        raw = rec.get("raw")
        if isinstance(raw, dict):
            data = None
            d = raw.get("data")
            if isinstance(d, dict):
                data = d
            elif isinstance(d, list) and d:
                data = d[0]
            if isinstance(data, dict):
                if field_name == "user_registration_status":
                    for k in ("user_registration_status", "publisher_status", "user_status"):
                        v = data.get(k, None)
                        if v not in (None, "", []):
                            return v
                    return "API_EMPTY"
                v = data.get(field_name, None)
                return v if v not in (None, "", []) else "API_EMPTY"
        return "API_MISSING"

    # ---------------------------
    # Build Products rows
    # ---------------------------
    df_products_rows = []
    for o in offers:
        extra = {}
        if o.extra:
            try:
                extra = json.loads(o.extra)
            except Exception:
                extra = {}
        df_products_rows.append({
            "id": o.id,
            "source": o.source,
            "source_id": o.source_id,
            "source_type": o.source_type,
            "merchant": o.merchant,
            "title": o.title,
            "url": o.url,
            "affiliate_url": o.affiliate_url,
            "image_url": o.image_url,
            "price": o.price,
            "currency": o.currency,
            "campaign_id": o.campaign_id,
            "product_id": json.dumps(extra.get("product_id")) if False else (extra.get("product_id") or getattr(o, "product_id", None)),
            "affiliate_link_available": extra.get("affiliate_link_available"),
            "domain": extra.get("domain"),
            "sku": extra.get("sku"),
            "discount": extra.get("discount"),
            "discount_amount": extra.get("discount_amount"),
            "discount_rate": extra.get("discount_rate"),
            "status_discount": extra.get("status_discount"),
            "updated_at": o.updated_at.isoformat() if o.updated_at else None,
            "desc": extra.get("desc"),
            "cate": extra.get("cate"),
            "shop_name": extra.get("shop_name"),
            "update_time_raw": extra.get("update_time_raw") or extra.get("update_time"),
        })

    # ---------------------------
    # Build Campaigns rows (independent)
    # ---------------------------
    df_campaigns_rows = []
    for c in campaigns_all:
        cid = c.campaign_id
        df_campaigns_rows.append({
            "campaign_id": c.campaign_id,
            "merchant": c.merchant,
            "campaign_name": c.name,
            "approval_type": c.approval,
            "user_status": c.user_registration_status,
            "status": c.status or _campaign_field_from_log(cid, "status"),
            "start_time": c.start_time,
            "end_time": c.end_time if c.end_time else _campaign_field_from_log(cid, "end_time"),
            "category": _campaign_field_from_log(cid, "category"),
            "conversion_policy": _campaign_field_from_log(cid, "conversion_policy"),
            "cookie_duration": _campaign_field_from_log(cid, "cookie_duration"),
            "cookie_policy": _campaign_field_from_log(cid, "cookie_policy"),
            "description": _campaign_field_from_log(cid, "description"),
            "scope": _campaign_field_from_log(cid, "scope"),
            "sub_category": _campaign_field_from_log(cid, "sub_category"),
            "type": _campaign_field_from_log(cid, "type"),
            "campaign_url": _campaign_field_from_log(cid, "url"),
        })

    # ---------------------------
    # Build Commissions rows (independent)
    # ---------------------------
    df_commissions_rows = []
    for cp in commissions_all:
        df_commissions_rows.append({
            "campaign_id": cp.campaign_id,
            "reward_type": cp.reward_type,
            "sales_ratio": cp.sales_ratio,
            "sales_price": cp.sales_price,
            "target_month": cp.target_month,
        })

    # ---------------------------
    # Build Promotions rows (independent + merchant)
    # ---------------------------
    df_promotions_rows = []
    for pr in promotions_all:
        m = None
        if pr.campaign_id and pr.campaign_id in campaign_map:
            m = campaign_map[pr.campaign_id].merchant
        df_promotions_rows.append({
            "campaign_id": pr.campaign_id,
            "merchant": m,
            "name": pr.name,
            "content": pr.content,
            "start_time": pr.start_time,
            "end_time": pr.end_time,
            "coupon": pr.coupon,
            "link": pr.link,
        })

    # DataFrames
    df_products = pd.DataFrame(df_products_rows)
    df_campaigns = pd.DataFrame(df_campaigns_rows)
    df_commissions = pd.DataFrame(df_commissions_rows)
    df_promotions = pd.DataFrame(df_promotions_rows)

    # Header translations (Vietnamese) ‚Äî add (*) markers for required in Products
    trans_products = {
        "id": "M√£ ID", "source": "Ngu·ªìn", "source_id": "M√£ ngu·ªìn", "source_type": "Lo·∫°i ngu·ªìn",
        "merchant": "Nh√† b√°n (*)", "title": "T√™n s·∫£n ph·∫©m (*)", "url": "Link g·ªëc", "affiliate_url": "Link ti·∫øp th·ªã",
        "image_url": "·∫¢nh s·∫£n ph·∫©m", "price": "Gi√° (*)", "currency": "Ti·ªÅn t·ªá",
        "campaign_id": "Chi·∫øn d·ªãch", "product_id": "M√£ s·∫£n ph·∫©m ngu·ªìn", "affiliate_link_available": "C√≥ affiliate?",
        "domain": "T√™n mi·ªÅn", "sku": "SKU", "discount": "Gi√° KM", "discount_amount": "M·ª©c gi·∫£m",
        "discount_rate": "T·ª∑ l·ªá gi·∫£m (%)", "status_discount": "C√≥ khuy·∫øn m√£i?",
        "updated_at": "Ng√†y c·∫≠p nh·∫≠t", "desc": "M√¥ t·∫£ chi ti·∫øt",
        "cate": "Danh m·ª•c", "shop_name": "T√™n c·ª≠a h√†ng", "update_time_raw": "Th·ªùi gian c·∫≠p nh·∫≠t t·ª´ ngu·ªìn",
    }
    trans_campaigns = {
        "campaign_id": "M√£ chi·∫øn d·ªãch", "merchant": "Nh√† b√°n", "campaign_name": "T√™n chi·∫øn d·ªãch",
        "approval_type": "Approval", "user_status": "Tr·∫°ng th√°i c·ªßa t√¥i", "status": "T√¨nh tr·∫°ng",
        "start_time": "B·∫Øt ƒë·∫ßu", "end_time": "K·∫øt th√∫c",
        "category": "Danh m·ª•c ch√≠nh", "conversion_policy": "Ch√≠nh s√°ch chuy·ªÉn ƒë·ªïi",
        "cookie_duration": "Hi·ªáu l·ª±c cookie (gi√¢y)", "cookie_policy": "Ch√≠nh s√°ch cookie",
        "description": "M√¥ t·∫£", "scope": "Ph·∫°m vi", "sub_category": "Danh m·ª•c ph·ª•",
        "type": "Lo·∫°i", "campaign_url": "URL chi·∫øn d·ªãch",
    }
    trans_commissions = {
        "campaign_id": "M√£ chi·∫øn d·ªãch", "reward_type": "Ki·ªÉu th∆∞·ªüng", "sales_ratio": "T·ª∑ l·ªá (%)",
        "sales_price": "Hoa h·ªìng c·ªë ƒë·ªãnh", "target_month": "Th√°ng √°p d·ª•ng",
    }
    trans_promotions = {
        "campaign_id": "M√£ chi·∫øn d·ªãch", "merchant": "Nh√† b√°n", "name": "T√™n khuy·∫øn m√£i", "content": "N·ªôi dung",
        "start_time": "B·∫Øt ƒë·∫ßu KM", "end_time": "K·∫øt th√∫c KM", "coupon": "M√£ gi·∫£m", "link": "Link khuy·∫øn m√£i",
    }

    def _with_header(df, trans):
        # Lu√¥n t·∫°o m·ªôt h√†ng ti√™u ƒë·ªÅ TV l√†m h√†ng ƒë·∫ßu ti√™n
        # N·∫øu df ƒëang r·ªóng, t·∫°o h√†ng ƒë·∫ßu v·ªõi to√†n b·ªô c·ªôt theo trans
        if df.empty:
            header = {c: trans.get(c, c) for c in trans.keys()}
            return pd.DataFrame([header])
        header = {c: trans.get(c, c) for c in df.columns}
        return pd.concat([pd.DataFrame([header]), df], ignore_index=True)

    df_products = _with_header(df_products, trans_products)
    df_campaigns = _with_header(df_campaigns, trans_campaigns)
    df_commissions = _with_header(df_commissions, trans_commissions)
    df_promotions = _with_header(df_promotions, trans_promotions)

    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        # N·∫øu DataFrame r·ªóng, v·∫´n c·∫ßn t·∫°o c·ªôt theo trans ƒë·ªÉ sheet c√≥ header
        def _ensure_cols(df, trans_map):
            cols = list(trans_map.keys())
            if df.empty:
                return pd.DataFrame(columns=cols)
            # Reorder/align columns to match trans_map keys; include missing columns as empty
            for c in cols:
                if c not in df.columns:
                    df[c] = None
            return df[cols]

        df_products = _ensure_cols(df_products, trans_products)
        df_campaigns = _ensure_cols(df_campaigns, trans_campaigns)
        df_commissions = _ensure_cols(df_commissions, trans_commissions)
        df_promotions = _ensure_cols(df_promotions, trans_promotions)

        df_products.to_excel(writer, sheet_name="Products", index=False)
        df_campaigns.to_excel(writer, sheet_name="Campaigns", index=False)
        df_commissions.to_excel(writer, sheet_name="Commissions", index=False)
        df_promotions.to_excel(writer, sheet_name="Promotions", index=False)

        # Style the Vietnamese header row (row index 1) as bold + italic
        workbook = writer.book
        fmt_vi_header = workbook.add_format({"bold": True, "italic": True})
        for sheet_name in ("Products", "Campaigns", "Commissions", "Promotions"):
            ws = writer.sheets.get(sheet_name)
            if ws is not None:
                try:
                    ws.set_row(1, None, fmt_vi_header)
                except Exception:
                    pass
    output.seek(0)

    filename = f"offers_export_{int(time.time())}.xlsx"
    headers = {"Content-Disposition": f"attachment; filename={filename}"}
    return StreamingResponse(
        output,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers=headers
    )

@app.get(
    "/offers/export-template",
    tags=["Offers üõí"],
    summary="T·∫£i template Excel (4 sheet)",
    description="T·∫£i file m·∫´u c√≥ s·∫µn 4 sheet v·ªõi header 2 h√†ng; ƒë√°nh d·∫•u (*) ·ªü c√°c c·ªôt b·∫Øt bu·ªôc c·ªßa Products."
)
def export_excel_template():
    import pandas as pd
    # T·∫°o DataFrames r·ªóng v·ªõi ƒë√∫ng c·ªôt v√† ch√®n h√†ng ti√™u ƒë·ªÅ TV
    trans_products = {
        "id": "M√£ ID", "source": "Ngu·ªìn", "source_id": "M√£ ngu·ªìn", "source_type": "Lo·∫°i ngu·ªìn",
        "merchant": "Nh√† b√°n (*)", "title": "T√™n s·∫£n ph·∫©m (*)", "url": "Link g·ªëc", "affiliate_url": "Link ti·∫øp th·ªã",
        "image_url": "·∫¢nh s·∫£n ph·∫©m", "price": "Gi√° (*)", "currency": "Ti·ªÅn t·ªá",
        "campaign_id": "Chi·∫øn d·ªãch", "product_id": "M√£ s·∫£n ph·∫©m ngu·ªìn", "affiliate_link_available": "C√≥ affiliate?",
        "domain": "T√™n mi·ªÅn", "sku": "SKU", "discount": "Gi√° KM", "discount_amount": "M·ª©c gi·∫£m",
        "discount_rate": "T·ª∑ l·ªá gi·∫£m (%)", "status_discount": "C√≥ khuy·∫øn m√£i?",
        "updated_at": "Ng√†y c·∫≠p nh·∫≠t", "desc": "M√¥ t·∫£ chi ti·∫øt",
        "cate": "Danh m·ª•c", "shop_name": "T√™n c·ª≠a h√†ng", "update_time_raw": "Th·ªùi gian c·∫≠p nh·∫≠t t·ª´ ngu·ªìn",
    }
    trans_campaigns = {
        "campaign_id": "M√£ chi·∫øn d·ªãch", "merchant": "Nh√† b√°n", "campaign_name": "T√™n chi·∫øn d·ªãch",
        "approval_type": "Approval", "user_status": "Tr·∫°ng th√°i c·ªßa t√¥i", "status": "T√¨nh tr·∫°ng",
        "start_time": "B·∫Øt ƒë·∫ßu", "end_time": "K·∫øt th√∫c",
        "category": "Danh m·ª•c ch√≠nh", "conversion_policy": "Ch√≠nh s√°ch chuy·ªÉn ƒë·ªïi",
        "cookie_duration": "Hi·ªáu l·ª±c cookie (gi√¢y)", "cookie_policy": "Ch√≠nh s√°ch cookie",
        "description": "M√¥ t·∫£", "scope": "Ph·∫°m vi", "sub_category": "Danh m·ª•c ph·ª•",
        "type": "Lo·∫°i", "campaign_url": "URL chi·∫øn d·ªãch",
    }
    trans_commissions = {
        "campaign_id": "M√£ chi·∫øn d·ªãch", "reward_type": "Ki·ªÉu th∆∞·ªüng", "sales_ratio": "T·ª∑ l·ªá (%)",
        "sales_price": "Hoa h·ªìng c·ªë ƒë·ªãnh", "target_month": "Th√°ng √°p d·ª•ng",
    }
    trans_promotions = {
        "campaign_id": "M√£ chi·∫øn d·ªãch", "merchant": "Nh√† b√°n", "name": "T√™n khuy·∫øn m√£i", "content": "N·ªôi dung",
        "start_time": "B·∫Øt ƒë·∫ßu KM", "end_time": "K·∫øt th√∫c KM", "coupon": "M√£ gi·∫£m", "link": "Link khuy·∫øn m√£i",
    }

    def _df_with_header(cols_map):
        df = pd.DataFrame(columns=list(cols_map.keys()))
        header = {c: cols_map.get(c, c) for c in df.columns}
        return pd.concat([pd.DataFrame([header]), df], ignore_index=True)

    df_products = _df_with_header(trans_products)
    df_campaigns = _df_with_header(trans_campaigns)
    df_commissions = _df_with_header(trans_commissions)
    df_promotions = _df_with_header(trans_promotions)

    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df_products.to_excel(writer, sheet_name="Products", index=False)
        df_campaigns.to_excel(writer, sheet_name="Campaigns", index=False)
        df_commissions.to_excel(writer, sheet_name="Commissions", index=False)
        df_promotions.to_excel(writer, sheet_name="Promotions", index=False)

        # Style the Vietnamese header row (row index 1) as bold + italic
        workbook = writer.book
        fmt_vi_header = workbook.add_format({"bold": True, "italic": True})
        for sheet_name in ("Products", "Campaigns", "Commissions", "Promotions"):
            ws = writer.sheets.get(sheet_name)
            if ws is not None:
                try:
                    ws.set_row(1, None, fmt_vi_header)
                except Exception:
                    pass
    output.seek(0)

    filename = f"offers_template_{int(time.time())}.xlsx"
    headers = {"Content-Disposition": f"attachment; filename={filename}"}
    return StreamingResponse(
        output,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers=headers
    )
@app.get(
    "/alerts/campaigns-registration",
    tags=["Campaigns üì¢"],
    summary="C·∫£nh b√°o ƒëƒÉng k√Ω chi·∫øn d·ªãch",
    description="Li·ªát k√™ c√°c campaign ƒëang ch·∫°y v√† ƒë√£ c√≥ s·∫£n ph·∫©m trong DB, nh∆∞ng user ch∆∞a ·ªü tr·∫°ng th√°i APPROVED (ch∆∞a ƒëƒÉng k√Ω ho·∫∑c ƒëang ch·ªù duy·ªát)."
)
def campaigns_registration_alerts(db: Session = Depends(get_db)):
    return crud.campaigns_need_registration_alerts(db)
