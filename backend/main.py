import logging
import traceback
import os, hmac, hashlib, base64, json, time, asyncio
from urllib.parse import urlparse, quote_plus
from typing import Optional, Dict, List, Any, Literal

from fastapi import FastAPI, Depends, HTTPException, Request, UploadFile, File, Body, Query
from fastapi.middleware.cors import CORSMiddleware
from providers import ProviderRegistry, ProviderOps
from fastapi.responses import JSONResponse, RedirectResponse, StreamingResponse
from fastapi.responses import HTMLResponse
import io
from fastapi.exceptions import RequestValidationError

from sqlalchemy.orm import Session
from sqlalchemy import text, or_, and_, func

from ai_service import suggest_products_with_config
import models, schemas, crud
from database import Base, engine, SessionLocal, apply_simple_migrations
from pydantic import BaseModel, HttpUrl, Field
from accesstrade_service import (
    fetch_products, map_at_product_to_offer, _check_url_alive, fetch_promotions,
    fetch_campaign_detail, fetch_commission_policies  # NEW
)

# FastAPI application instance with organized Swagger tags and VN docs
tags_metadata = [
    {"name": "System üõ†Ô∏è", "description": "C√°c API ki·ªÉm tra s·ª©c kh·ªèe h·ªá th·ªëng v√† v·∫≠n h√†nh."},
    {"name": "Links üîó", "description": "Qu·∫£n l√Ω link ti·∫øp th·ªã (CRUD)."},
    {"name": "API Configs ‚öôÔ∏è", "description": "C·∫•u h√¨nh nh√† cung c·∫•p AI/API (v√≠ d·ª•: Accesstrade, m√¥ h√¨nh AI)."},
    {"name": "Settings ‚öôÔ∏è", "description": "C√†i ƒë·∫∑t/policy h·ªá th·ªëng: c·∫•u h√¨nh ingest, b·∫≠t/t·∫Øt ki·ªÉm tra link khi import Excel."},
    {"name": "Affiliate üéØ", "description": "M·∫´u deeplink, chuy·ªÉn ƒë·ªïi link g·ªëc ‚Üí deeplink, shortlink an to√†n."},
    {"name": "Campaigns üì¢", "description": "Chi·∫øn d·ªãch: danh s√°ch, summary, merchants ƒë√£ duy·ªát."},
    {"name": "Offers üõí", "description": "S·∫£n ph·∫©m/offer: li·ªát k√™, c·∫≠p nh·∫≠t, xo√°, import Excel, ki·ªÉm tra link s·ªëng."},
    {"name": "Ingest üåê", "description": "ƒê·ªìng b·ªô d·ªØ li·ªáu t·ª´ nh√† cung c·∫•p (Accesstrade): campaigns, datafeeds, promotions, top products."},
    {"name": "AI ü§ñ", "description": "C√°c t√≠nh nƒÉng AI: g·ª£i √Ω s·∫£n ph·∫©m v√† ki·ªÉm tra nhanh."},
]

app = FastAPI(
    title="AI Affiliate API",
    description=(
        "B·ªô API qu·∫£n l√Ω affiliate: chi·∫øn d·ªãch, s·∫£n ph·∫©m, deeplink v√† ingest t·ª´ Accesstrade.\n\n"
        "H∆∞·ªõng d·∫´n chung:\n"
        "- C√°c nh√≥m API ƒë∆∞·ª£c s·∫Øp x·∫øp theo ch·ª©c nƒÉng ƒë·ªÉ d·ªÖ t√¨m.\n"
        "- C√°c v√≠ d·ª• ƒëi k√®m (Example) b·∫±ng ti·∫øng Vi·ªát ngay trong schema request.\n"
        "- Khi c·∫ßn demo nhanh, b·∫≠t bi·∫øn m√¥i tr∆∞·ªùng AT_MOCK=1 ƒë·ªÉ d√πng d·ªØ li·ªáu gi·∫£ l·∫≠p.\n"
    ),
    version="0.1.0",
    openapi_tags=tags_metadata,
    swagger_ui_parameters={
        "docExpansion": "list",                # m·ªü r·ªông theo danh s√°ch, g·ªçn h∆°n
        "defaultModelsExpandDepth": -1,         # thu g·ªçn m·ª•c Schemas m·∫∑c ƒë·ªãnh
        "defaultModelExpandDepth": 0,           # kh√¥ng auto m·ªü t·ª´ng schema
        "displayRequestDuration": True,
    },
)

# CORS (open by default; tighten in production)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Logger
logger = logging.getLogger("affiliate_api")
if not logger.handlers:
    logging.basicConfig(level=logging.INFO)

# --- DB init: create tables and apply lightweight migrations (no Alembic here) ---
Base.metadata.create_all(bind=engine)
# Ensure older Postgres DBs get new columns added idempotently
try:
    apply_simple_migrations(engine)
except Exception:
    # Non-fatal: continue startup even if migration helper fails
    logger = logging.getLogger("affiliate_api")
    logger.warning("apply_simple_migrations failed during startup", exc_info=True)

# Thi·∫øt l·∫≠p m·∫∑c ƒë·ªãnh cho policy link-check n·∫øu ch∆∞a c√≥ trong DB
def _ensure_default_policy_flags():
    db = SessionLocal()
    try:
        cfg = crud.get_api_config(db, "ingest_policy")
        s = (cfg.model or "") if cfg else ""
        # Ch·ªâ ƒë·∫∑t n·∫øu CH∆ØA c√≥ trong chu·ªói model
        if "linkcheck_mod=" not in (s or ""):
            crud.set_policy_flag(db, "linkcheck_mod", 24)
        if "linkcheck_limit=" not in (s or ""):
            crud.set_policy_flag(db, "linkcheck_limit", 1000)
    except Exception:
        pass
    finally:
        db.close()

_ensure_default_policy_flags()

# DB session dependency
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ---------------- Error handlers ----------------
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    logger.warning(
        "Validation error on %s %s: %s | body=%s",
        request.method, request.url.path, exc, getattr(exc, "body", None)
    )
    return JSONResponse(
        status_code=422,
        content={"detail": exc.errors(), "body": getattr(exc, "body", None)}
    )

@app.exception_handler(Exception)
async def all_exception_handler(request: Request, exc: Exception):
    tb = traceback.format_exc()
    return JSONResponse(status_code=500, content={"error": str(exc), "traceback": tb})

# ---------------- System ----------------
## NOTE: (removed) stray decorator left behind during refactor
@app.get(
    "/health",
    tags=["System üõ†Ô∏è"],
    summary="Ki·ªÉm tra s·ª©c kh·ªèe h·ªá th·ªëng",
    description=(
        "Tr·∫£ v·ªÅ ok=true n·∫øu k·∫øt n·ªëi DB ho·∫°t ƒë·ªông.\n\n"
        "V√≠ d·ª•: g·ªçi GET /health ‚Üí {\"ok\": true}"
    )
)
def health(db: Session = Depends(get_db)):
    try:
        db.execute(text("SELECT 1"))
        return {"ok": True}
    except Exception as e:
        logger.exception("Health check failed")
        return {"ok": False, "error": str(e)}

# =====================================================================
#                       AFFILIATE ‚Äî SAFE SHORTLINK
# =====================================================================

# Secret k√Ω HMAC cho shortlink /r/{token}
AFF_SECRET = os.getenv("AFF_SECRET", "change-me")  # nh·ªõ ƒë·∫∑t trong docker-compose/.env khi ch·∫°y th·∫≠t

# Whitelist domain theo merchant ƒë·ªÉ ch·ªëng open-redirect
ALLOWED_DOMAINS = {
    "shopee": ["shopee.vn", "shopee.sg", "shopee.co.id", "shopee.co.th", "shopee.com.my", "shopee.ph"],
    "lazada": ["lazada.vn", "lazada.co.id", "lazada.co.th", "lazada.com.my", "lazada.sg", "lazada.com.ph"],
    "tiki":   ["tiki.vn"],
}

def _is_allowed_domain(merchant: str, url: str) -> bool:
    try:
        netloc = urlparse(url).netloc.lower()
        return any(netloc.endswith(dom) for dom in ALLOWED_DOMAINS.get(merchant, []))
    except Exception:
        return False

def _apply_template(template: str, target_url: str, params: Optional[Dict[str, str]]) -> str:
    # Encode link g·ªëc v√†o placeholder {target}; c√°c {param} kh√°c thay tr·ª±c ti·∫øp
    aff = template.replace("{target}", quote_plus(target_url))
    if params:
        for k, v in params.items():
            aff = aff.replace("{" + k + "}", str(v))
    return aff

def _make_token(affiliate_url: str, ts: Optional[int] = None) -> str:
    payload = {"u": affiliate_url, "ts": ts or int(time.time())}
    b64 = base64.urlsafe_b64encode(json.dumps(payload).encode()).decode().rstrip("=")
    sig = hmac.new(AFF_SECRET.encode(), b64.encode(), hashlib.sha256).hexdigest()
    return f"{b64}.{sig}"

def _parse_token(token: str) -> str:
    try:
        b64, sig = token.split(".", 1)
        expect = hmac.new(AFF_SECRET.encode(), b64.encode(), hashlib.sha256).hexdigest()
        if not hmac.compare_digest(expect, sig):
            raise ValueError("invalid signature")
        pad = "=" * (-len(b64) % 4)
        payload = json.loads(base64.urlsafe_b64decode(b64 + pad).decode())
        return payload["u"]
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Invalid token: {e}")

# ---------------- CRUD: Links ----------------
@app.get(
    "/links",
    tags=["Links üîó"],
    summary="Danh s√°ch link",
    description="L·∫•y danh s√°ch link ti·∫øp th·ªã t·ª´ DB. H·ªó tr·ª£ ph√¢n trang qua `skip`, `limit`.",
    response_model=list[schemas.AffiliateLinkOut]
)
def read_links(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    return crud.get_links(db, skip=skip, limit=limit)

@app.get(
    "/links/{link_id}",
    tags=["Links üîó"],
    summary="Chi ti·∫øt link",
    description="L·∫•y chi ti·∫øt m·ªôt link ti·∫øp th·ªã theo **ID**.",
    response_model=schemas.AffiliateLinkOut
)
def read_link(link_id: int, db: Session = Depends(get_db)):
    db_link = crud.get_link(db, link_id)
    if db_link is None:
        raise HTTPException(status_code=404, detail="Link not found")
    return db_link

@app.post(
    "/links",
    tags=["Links üîó"],
    summary="Th√™m link m·ªõi",
    description=(
        "T·∫°o m·ªõi m·ªôt link ti·∫øp th·ªã v√† l∆∞u v√†o DB.\n\n"
        "- B·∫Øt bu·ªôc: name, url, affiliate_url.\n"
        "- Tu·ª≥ ch·ªçn: (kh√¥ng c√≥).\n\n"
        "V√≠ d·ª• body JSON:\n"
        "{\n  \"name\": \"Link Shopee ƒëi·ªán tho·∫°i\",\n  \"url\": \"https://shopee.vn/product/123\",\n  \"affiliate_url\": \"https://go.example/?url=https%3A%2F%2Fshopee.vn%2Fproduct%2F123\"\n}"
    ),
    response_model=schemas.AffiliateLinkOut
)
def create_link(
    link: schemas.AffiliateLinkCreate = Body(
        ...,
        examples={
            "default": {
                "summary": "Link Shopee",
                "value": {
                    "name": "Link Shopee ƒëi·ªán tho·∫°i",
                    "url": "https://shopee.vn/product/123",
                    "affiliate_url": "https://go.example/?url=https%3A%2F%2Fshopee.vn%2Fproduct%2F123"
                }
            }
        }
    ),
    db: Session = Depends(get_db)
):
    logger.debug("Create link payload: %s", link.model_dump() if hasattr(link, "model_dump") else link.dict())
    return crud.create_link(db, link)

@app.put(
    "/links/{link_id}",
    tags=["Links üîó"],
    summary="C·∫≠p nh·∫≠t link",
    description=(
        "C·∫≠p nh·∫≠t th√¥ng tin m·ªôt link ti·∫øp th·ªã theo **ID**.\n\n"
        "- B·∫Øt bu·ªôc: name, url, affiliate_url (hi·ªán schema y√™u c·∫ßu ƒë·ªß 3 tr∆∞·ªùng).\n"
        "- Tu·ª≥ ch·ªçn: (kh√¥ng c√≥).\n\n"
        "V√≠ d·ª• body JSON:\n"
        "{\n  \"name\": \"Link Shopee A\",\n  \"url\": \"https://shopee.vn/product/123\",\n  \"affiliate_url\": \"https://go.example/?url=...\"\n}"
    ),
    response_model=schemas.AffiliateLinkOut
)
def update_link(
    link_id: int,
    link: schemas.AffiliateLinkUpdate = Body(
        ...,
        examples={
            "default": {
                "summary": "C·∫≠p nh·∫≠t ƒë·ªß tr∆∞·ªùng",
                "value": {
                    "name": "Link Shopee A",
                    "url": "https://shopee.vn/product/123",
                    "affiliate_url": "https://go.example/?url=..."
                }
            }
        }
    ),
    db: Session = Depends(get_db)
):
    db_link = crud.update_link(db, link_id, link)
    if db_link is None:
        raise HTTPException(status_code=404, detail="Link not found")
    return db_link

@app.delete(
    "/links/{link_id}",
    tags=["Links üîó"],
    summary="Xo√° link",
    description="Xo√° link ti·∫øp th·ªã theo **ID**."
)
def delete_link(link_id: int, db: Session = Depends(get_db)):
    db_link = crud.delete_link(db, link_id)
    if db_link is None:
        raise HTTPException(status_code=404, detail="Link not found")
    return {"ok": True, "message": "Link deleted"}

# ---------------- CRUD: API Configs ----------------

@app.get(
    "/api-configs",
    tags=["API Configs ‚öôÔ∏è"],
    summary="Danh s√°ch c·∫•u h√¨nh API",
    description="Li·ªát k√™ to√†n b·ªô c·∫•u h√¨nh nh√† cung c·∫•p AI/API.",
    response_model=list[schemas.APIConfigOut]
)
def read_api_configs(db: Session = Depends(get_db)):
    return crud.list_api_configs(db)

@app.post(
    "/api-configs/upsert",
    tags=["API Configs ‚öôÔ∏è"],
    summary="Upsert c·∫•u h√¨nh API",
    description=(
        "**T·∫°o m·ªõi ho·∫∑c c·∫≠p nh·∫≠t** c·∫•u h√¨nh d·ª±a tr√™n `name`. Thu·∫≠n ti·ªán ƒë·ªÉ c·∫≠p nh·∫≠t nhanh.\n\n"
        "- B·∫Øt bu·ªôc: name, base_url, api_key.\n"
        "- Tu·ª≥ ch·ªçn: model (chu·ªói l∆∞u tr·ªØ flags/tu·ª≥ bi·∫øn).\n\n"
        "V√≠ d·ª• body JSON:\n"
        "{\n  \"name\": \"accesstrade\",\n  \"base_url\": \"https://api.accesstrade.vn\",\n  \"api_key\": \"AT-XXXX\",\n  \"model\": \"only_with_commission=true\"\n}"
    ),
    response_model=schemas.APIConfigOut
)
def upsert_api_config(
    config: schemas.APIConfigCreate = Body(
        ...,
        examples={
            "default": {
                "summary": "Accesstrade",
                "value": {
                    "name": "accesstrade",
                    "base_url": "https://api.accesstrade.vn",
                    "api_key": "AT-XXXX",
                    "model": "only_with_commission=true"
                }
            }
        }
    ),
    db: Session = Depends(get_db)
):
    """T·∫°o m·ªõi ho·∫∑c c·∫≠p nh·∫≠t API config theo name."""
    return crud.upsert_api_config_by_name(db, config)

@app.put(
    "/api-configs/{config_id}",
    tags=["API Configs ‚öôÔ∏è"],
    summary="C·∫≠p nh·∫≠t c·∫•u h√¨nh API",
    description=(
        "C·∫≠p nh·∫≠t th√¥ng tin c·∫•u h√¨nh theo **ID**.\n\n"
        "- B·∫Øt bu·ªôc: name, base_url, api_key.\n"
        "- Tu·ª≥ ch·ªçn: model.\n\n"
        "V√≠ d·ª• body JSON:\n"
        "{\n  \"name\": \"accesstrade\",\n  \"base_url\": \"https://api.accesstrade.vn\",\n  \"api_key\": \"AT-XXXX\",\n  \"model\": \"check_urls=true\"\n}"
    ),
    response_model=schemas.APIConfigOut
)
def update_api_config(
    config_id: int,
    config: schemas.APIConfigCreate = Body(
        ...,
        examples={
            "default": {
                "summary": "C·∫≠p nh·∫≠t kho√°",
                "value": {
                    "name": "accesstrade",
                    "base_url": "https://api.accesstrade.vn",
                    "api_key": "AT-NEW-KEY",
                    "model": "check_urls=true"
                }
            }
        }
    ),
    db: Session = Depends(get_db)
):
    db_config = db.query(models.APIConfig).filter(models.APIConfig.id == config_id).first()
    if not db_config:
        raise HTTPException(status_code=404, detail="API config not found")
    db_config.name = config.name
    db_config.base_url = config.base_url
    db_config.api_key = config.api_key
    db_config.model = config.model
    db.commit()
    db.refresh(db_config)
    return db_config

@app.delete(
    "/api-configs/{config_id}",
    tags=["API Configs ‚öôÔ∏è"],
    summary="Xo√° c·∫•u h√¨nh API",
    description="Xo√° c·∫•u h√¨nh nh√† cung c·∫•p theo **ID**."
)
def delete_api_config_route(config_id: int, db: Session = Depends(get_db)):
    deleted = crud.delete_api_config(db, config_id)
    if not deleted:
        raise HTTPException(status_code=404, detail="API config not found")
    return {"ok": True, "deleted_id": config_id, "name": deleted.name}

# ---------------- AI: Suggest/Test ----------------
@app.post(
    "/ai/suggest",
    tags=["AI ü§ñ"],
    summary="AI g·ª£i √Ω theo s·∫£n ph·∫©m trong DB",
    description="Tr·∫£ l·ªùi/g·ª£i √Ω b·∫±ng AI d·ª±a tr√™n danh s√°ch s·∫£n ph·∫©m ƒë√£ ingest."
)
async def ai_suggest(
    query: str,
    provider: str = "groq",
    db: Session = Depends(get_db)
):
    # Gi·ªØ nguy√™n logic g·ªëc
    products = []
    for o in crud.list_offers(db, limit=50):
        desc = None
        if o.extra:
            try:
                desc = json.loads(o.extra).get("desc")
            except:
                pass
        products.append({
            "name": o.title,
            "url": o.url,
            "affiliate_url": o.affiliate_url or o.url,
            "desc": desc
        })
    if not products:
        raise HTTPException(status_code=404, detail="Ch∆∞a c√≥ s·∫£n ph·∫©m n√†o trong DB")
    response = await suggest_products_with_config(query, products, db, provider)
    return {"suggestion": response}

@app.post(
    "/ai/test",
    tags=["AI ü§ñ"],
    summary="Test AI nhanh",
    description="G·ªçi AI v·ªõi c√¢u h·ªèi m·∫´u & 10 s·∫£n ph·∫©m g·∫ßn nh·∫•t trong DB ƒë·ªÉ ki·ªÉm tra nhanh ch·∫•t l∆∞·ª£ng tr·∫£ l·ªùi."
)
async def ai_test(
    query: str = "Gi·ªõi thi·ªáu s·∫£n ph·∫©m t·ªët nh·∫•t tr√™n Shopee",
    provider: str = "groq",
    db: Session = Depends(get_db)
):
    # Gi·ªØ nguy√™n logic g·ªëc
    products = []
    for o in crud.list_offers(db, limit=50):
        desc = None
        if o.extra:
            try:
                desc = json.loads(o.extra).get("desc")
            except:
                pass
        products.append({
            "name": o.title,
            "url": o.url,
            "affiliate_url": o.affiliate_url or o.url,
            "desc": desc
        })
    if not products:
        return {"suggestion": "‚ö†Ô∏è Ch∆∞a c√≥ s·∫£n ph·∫©m n√†o trong DB ƒë·ªÉ g·ª£i √Ω."}
    response = await suggest_products_with_config(query, products, db, provider)
    return {"suggestion": response}

# =====================================================================
#                  NEW: Templates + Convert + Redirect
# =====================================================================

# Upsert template deeplink (m·ªói merchant/network m·ªôt m·∫´u)

@app.get(
    "/aff/templates",
    tags=["Affiliate üéØ"],
    summary="Danh s√°ch m·∫´u deeplink",
    description=(
        "Hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß c√°c m·∫´u deeplink hi·ªán c√≥ trong DB.\n\n"
        "G·ª£i √Ω: c·∫•u h√¨nh m·ªôt m·∫´u cho m·ªói c·∫∑p (merchant, network)."
    ),
    response_model=list[schemas.AffiliateTemplateOut]
)
def list_templates(db: Session = Depends(get_db)):
    return crud.list_affiliate_templates(db)

@app.post(
    "/aff/templates/upsert",
    tags=["Affiliate üéØ"],
    summary="Upsert m·∫´u deeplink",
    description=(
        "Th√™m/c·∫≠p nh·∫≠t m·∫´u deeplink cho t·ª´ng merchant/network.\n\n"
        "- B·∫Øt bu·ªôc: merchant, network, template.\n"
        "- Tu·ª≥ ch·ªçn: default_params (object), enabled (bool, m·∫∑c ƒë·ªãnh true).\n\n"
        "V√≠ d·ª• body JSON:\n"
        "{\n  \"merchant\": \"shopee\",\n  \"network\": \"accesstrade\",\n  \"template\": \"https://go.example/?url={target}&sub1={sub1}\",\n  \"default_params\": {\"sub1\": \"my_subid\"}\n}"
    ),
    response_model=schemas.AffiliateTemplateOut
)
def upsert_template(
    data: schemas.AffiliateTemplateCreate = Body(
        ...,
        examples={
            "default": {
                "summary": "M·∫´u Shopee",
                "value": {
                    "merchant": "shopee",
                    "network": "accesstrade",
                    "template": "https://go.example/?url={target}&sub1={sub1}",
                    "default_params": {"sub1": "my_subid"}
                }
            }
        }
    ),
    db: Session = Depends(get_db)
):
    tpl = crud.upsert_affiliate_template(db, data)
    return tpl

@app.put(
    "/aff/templates/{template_id}",
    tags=["Affiliate üéØ"],
    summary="C·∫≠p nh·∫≠t m·∫´u deeplink",
    description=(
        "S·ª≠a m·∫´u deeplink theo ID.\n\n"
        "- B·∫Øt bu·ªôc: merchant, network, template.\n"
        "- Tu·ª≥ ch·ªçn: default_params, enabled.\n\n"
        "V√≠ d·ª• body JSON:\n"
        "{\n  \"merchant\": \"lazada\",\n  \"network\": \"accesstrade\",\n  \"template\": \"https://go.example/?url={target}&sub1={sub1}\",\n  \"default_params\": {\"sub1\": \"ads2025\"},\n  \"enabled\": true\n}"
    ),
    response_model=schemas.AffiliateTemplateOut
)
def update_template(
    template_id: int,
    data: schemas.AffiliateTemplateCreate = Body(
        ...,
        examples={
            "default": {
                "summary": "S·ª≠a m·∫´u Lazada",
                "value": {
                    "merchant": "lazada",
                    "network": "accesstrade",
                    "template": "https://go.example/?url={target}&sub1={sub1}",
                    "default_params": {"sub1": "ads2025"},
                    "enabled": True
                }
            }
        }
    ),
    db: Session = Depends(get_db)
):
    tpl = crud.update_affiliate_template(db, template_id, data)
    if not tpl:
        raise HTTPException(status_code=404, detail="Template not found")
    return tpl

@app.delete(
    "/aff/templates/{template_id}",
    tags=["Affiliate üéØ"],
    summary="Xo√° m·∫´u deeplink",
    description="Xo√° m·∫´u deeplink theo ID."
)
def delete_template(template_id: int, db: Session = Depends(get_db)):
    tpl = crud.delete_affiliate_template_by_id(db, template_id)
    if not tpl:
        raise HTTPException(status_code=404, detail="Template not found")
    return {"ok": True, "deleted_id": template_id}

# Y√™u c·∫ßu convert
class ConvertReq(BaseModel):
    merchant: str
    url: HttpUrl
    network: str = "accesstrade"
    params: Optional[Dict[str, str]] = None  # v√≠ d·ª• {"sub1": "my_subid"}

    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "merchant": "shopee",
                    "url": "https://shopee.vn/product/12345",
                    "network": "accesstrade",
                    "params": {"sub1": "campaign_fb", "utm_source": "fbad"}
                }
            ]
        }
    }

class ConvertRes(BaseModel):
    affiliate_url: str
    short_url: str

# Convert link g·ªëc -> deeplink + shortlink /r/{token}
@app.post(
    "/aff/convert",
    tags=["Affiliate üéØ"],
    summary="Chuy·ªÉn link g·ªëc ‚Üí deeplink + shortlink",
    description=(
        "Nh·∫≠n link g·ªëc + merchant ‚Üí tr·∫£ v·ªÅ affiliate_url (deeplink) v√† short_url d·∫°ng /r/{token}.\n\n"
        "- B·∫Øt bu·ªôc: merchant, url.\n"
        "- Tu·ª≥ ch·ªçn: params (object), network (m·∫∑c ƒë·ªãnh \"accesstrade\").\n\n"
        "L∆∞u √Ω: URL ph·∫£i thu·ªôc domain h·ª£p l·ªá c·ªßa merchant (v√≠ d·ª• shopee.vn).\n\n"
        "V√≠ d·ª• body JSON:\n"
        "{\n  \"merchant\": \"shopee\",\n  \"url\": \"https://shopee.vn/product/123\",\n  \"params\": {\"sub1\": \"abc\"}\n}"
    ),
    response_model=ConvertRes
)
def aff_convert(
    req: ConvertReq = Body(
        ...,
        examples={
            "default": {
                "summary": "Convert Shopee",
                "value": {
                    "merchant": "shopee",
                    "url": "https://shopee.vn/product/123",
                    "params": {"sub1": "abc"}
                }
            }
        }
    ),
    db: Session = Depends(get_db)
):
    if not _is_allowed_domain(req.merchant, str(req.url)):
        raise HTTPException(status_code=400, detail=f"URL kh√¥ng thu·ªôc domain h·ª£p l·ªá c·ªßa {req.merchant}")

    tpl = crud.get_affiliate_template(db, req.merchant, req.network)
    if not tpl:
        raise HTTPException(status_code=404, detail=f"Ch∆∞a c·∫•u h√¨nh template cho merchant={req.merchant}, network={req.network}")

    merged: Dict[str, str] = {}
    if tpl.default_params:
        merged.update(tpl.default_params)
    if req.params:
        merged.update(req.params)

    affiliate_url = _apply_template(tpl.template, str(req.url), merged)
    token = _make_token(affiliate_url)
    short_url = f"/r/{token}"
    return ConvertRes(affiliate_url=affiliate_url, short_url=short_url)

# Redirect t·ª´ shortlink -> deeplink th·∫≠t
@app.get(
    "/r/{token}",
    tags=["Affiliate üéØ"],
    summary="Redirect shortlink",
    description="Gi·∫£i m√£ token v√† chuy·ªÉn h∆∞·ªõng 302 t·ªõi **affiliate_url** th·ª±c t·∫ø."
)
def redirect_short_link(token: str):
    affiliate_url = _parse_token(token)
    return RedirectResponse(url=affiliate_url, status_code=302)

# =====================================================================
#                  NEW (B∆∞·ªõc 3): Ingest/List t·ª´ Accesstrade
# =====================================================================

class IngestReq(BaseModel):
    provider: str = "accesstrade"                 # v√≠ d·ª•: "accesstrade", "adpia", ...
    path: str = "/v1/publishers/product_search"   # tu·ª≥ provider
    params: Dict[str, str] | None = None
    # Tu·ª≥ ch·ªçn chung (kh√¥ng b·∫Øt bu·ªôc, c√≥ th·ªÉ b·ªã b·ªè qua tu·ª≥ provider)
    check_urls: bool = False
    verbose: bool = False
    throttle_ms: int = 50

    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "provider": "accesstrade",
                    "path": "/v1/datafeeds",
                    "params": {"merchant": "tikivn", "page": "1", "limit": "50"},
                    "check_urls": False,
                    "verbose": False,
                    "throttle_ms": 50
                }
            ]
        }
    }

class IngestAllDatafeedsReq(BaseModel):
    """
    Ingest to√†n b·ªô datafeeds trong m·ªôt l·∫ßn (t·ª± ph√¢n trang n·ªôi b·ªô).
    - params: b·ªô l·ªçc chuy·ªÉn th·∫≥ng ƒë·∫øn provider (Accesstrade) v√† m·ªôt s·ªë filter n·ªôi b·ªô:
        - merchant: l·ªçc theo merchant/campaign slug c·ªßa AT (vd: "tiki", "tiktokshop").
        - domain: l·ªçc theo domain s·∫£n ph·∫©m (vd: "tiki.vn").
        - campaign_id | camp_id: c·ªë ƒë·ªãnh ƒë√∫ng campaign_id c·∫ßn ingest (∆∞u ti√™n n·∫øu c√≥).
        - update_from/update_to, price_from/to, discount_*: chuy·ªÉn ti·∫øp xu·ªëng API AT n·∫øu h·ªó tr·ª£.
    - limit_per_page: k√≠ch th∆∞·ªõc trang khi g·ªçi ra Accesstrade (m·∫∑c ƒë·ªãnh 100)
    - max_pages: ch·∫∑n v√≤ng l·∫∑p v√¥ h·∫°n n·∫øu API tr·∫£ b·∫•t th∆∞·ªùng (m·∫∑c ƒë·ªãnh 2000 trang)
    - throttle_ms: ngh·ªâ gi·ªØa c√°c l·∫ßn g·ªçi ƒë·ªÉ t√¥n tr·ªçng rate-limit (m·∫∑c ƒë·ªãnh 50ms)
    - check_urls: n·∫øu True m·ªõi ki·ªÉm tra link s·ªëng (m·∫∑c ƒë·ªãnh False).
    """
    params: Dict[str, str] | None = None
    limit_per_page: int = 100
    max_pages: int = 2000
    throttle_ms: int = 50
    check_urls: bool = False
    verbose: bool = False
    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "params": {"merchant": "tikivn"},
                    "limit_per_page": 100,
                    "max_pages": 1,
                    "throttle_ms": 50,
                    "check_urls": False,
                    "verbose": False
                }
            ]
        }
    }
    
class CampaignsSyncReq(BaseModel):
    """
    ƒê·ªìng b·ªô campaigns t·ª´ Accesstrade (t·ªëi ∆∞u t·ªëc ƒë·ªô).
    - statuses: danh s√°ch tr·∫°ng th√°i c·∫ßn qu√©t, m·∫∑c ƒë·ªãnh ["running","paused"].
    - only_my: True -> ch·ªâ gi·ªØ approval in {"successful","pending"} (nhanh h∆°n, √≠t ghi DB).
    - enrich_user_status: l·∫•y user_status th·∫≠t t·ª´ campaign detail (ch·∫≠m). M·∫∑c ƒë·ªãnh False ƒë·ªÉ nhanh.
    - limit_per_page, page_concurrency, window_pages, throttle_ms: tinh ch·ªânh t·ªëc ƒë·ªô vs ƒë·ªô ·ªïn ƒë·ªãnh.
    - merchant: n·∫øu truy·ªÅn s·∫Ω l·ªçc theo merchant sau khi fetch.
    """
    statuses: List[str] = Field(default_factory=lambda: ["running", "paused"])
    only_my: bool = True
    enrich_user_status: bool = True
    limit_per_page: int = 50
    page_concurrency: int = 6
    window_pages: int = 10
    throttle_ms: int = 50
    merchant: str | None = None
    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "statuses": ["running", "paused"],
                    "only_my": True,
                    "enrich_user_status": False,
                    "limit_per_page": 50,
                    "page_concurrency": 6,
                    "window_pages": 10,
                    "throttle_ms": 50
                }
            ]
        }
    }

class IngestV2PromotionsReq(BaseModel):
    """
    Ingest khuy·∫øn m√£i (offers_informations) theo merchant ƒë√£ duy·ªát.
    - merchant: n·∫øu truy·ªÅn, ch·ªâ ingest ƒë√∫ng merchant n√†y; n·∫øu b·ªè tr·ªëng s·∫Ω ch·∫°y cho t·∫•t c·∫£ merchant active.
    - L∆∞u √Ω: KH√îNG t·∫°o ProductOffer t·ª´ Promotions.
    """
    merchant: str | None = None
    verbose: bool = False
    throttle_ms: int = 50
    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "merchant": "tikivn",
                    "verbose": False,
                    "throttle_ms": 50
                }
            ]
        }
    }

class IngestV2TopProductsReq(BaseModel):
    """
    Ingest top_products (b√°n ch·∫°y) theo merchant & kho·∫£ng ng√†y.
    - date_from/date_to: 'YYYY-MM-DD' (t√πy Accesstrade h·ªó tr·ª£); n·∫øu b·ªè tr·ªëng c√≥ th·ªÉ l·∫•y m·∫∑c ƒë·ªãnh ph√≠a API.
    - limit_per_page: k√≠ch th∆∞·ªõc trang (<=100)
    - max_pages: s·ªë trang t·ªëi ƒëa s·∫Ω qu√©t
    - throttle_ms: ngh·ªâ gi·ªØa c√°c l·∫ßn g·ªçi
    - check_urls: n·∫øu True m·ªõi ki·ªÉm tra link s·ªëng (m·∫∑c ƒë·ªãnh False).
    """
    merchant: str | None = None
    date_from: str | None = None
    date_to: str | None = None
    check_urls: bool = False
    verbose: bool = False
    limit_per_page: int = 100
    max_pages: int = 200
    throttle_ms: int = 50
    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "merchant": "tikivn",
                    "date_from": "2025-09-15",
                    "date_to": "2025-09-22",
                    "limit_per_page": 50,
                    "max_pages": 1,
                    "check_urls": False,
                    "verbose": False,
                    "throttle_ms": 50
                }
            ]
        }
    }
## (old) Removed duplicated unified request classes ‚Äî s·ª≠ d·ª•ng nh√≥m *Unified* ph√≠a d∆∞·ªõi

# ---------------- Provider registry wiring ----------------
_registry = ProviderRegistry()

# Build Accesstrade ops from existing handlers
async def _accesstrade_campaigns_sync(req: "CampaignsSyncReq", db: Session):
    return await ingest_v2_campaigns_sync(req, db)

async def _accesstrade_promotions(req: "IngestV2PromotionsReq", db: Session):
    return await ingest_v2_promotions(req, db)

async def _accesstrade_top_products(req: "IngestV2TopProductsReq", db: Session):
    return await ingest_v2_top_products(req, db)

async def _accesstrade_datafeeds_all(req: "IngestAllDatafeedsReq", db: Session):
    return await ingest_accesstrade_datafeeds_all(req, db)

# products op will be provided by a helper implemented below
async def _accesstrade_products(req: "IngestReq", db: Session):
    return await _ingest_products_accesstrade_impl(req, db)

_registry.register("accesstrade", ProviderOps(
    campaigns_sync=_accesstrade_campaigns_sync,
    promotions=_accesstrade_promotions,
    top_products=_accesstrade_top_products,
    datafeeds_all=_accesstrade_datafeeds_all,
    products=_accesstrade_products,
))

from sqlalchemy import func

@app.get("/campaigns/summary", tags=["Campaigns üì¢"]) 
def campaigns_summary(db: Session = Depends(get_db)):
    """Summary theo chu·∫©n m·ªõi: ch·ªâ d·ª±a tr√™n user_registration_status."""
    rows = db.query(
        models.Campaign.status,
        models.Campaign.user_registration_status,
        models.Campaign.merchant,
    ).all()

    total = len(rows)

    def _norm_user(us: str | None) -> str | None:
        if not us:
            return None
        u = str(us).strip().upper()
        # ch·∫•p nh·∫≠n SUCCESSFUL nh∆∞ APPROVED ƒë·ªÉ t∆∞∆°ng th√≠ch ngu·ªìn d·ªØ li·ªáu
        if u == "SUCCESSFUL":
            return "APPROVED"
        return u

    by_status: dict[str, int] = {}
    by_user_status: dict[str, int] = {}
    running_approved_count = 0
    approved_merchants_set: set[str] = set()

    for status, us, merchant in rows:
        st_key = status or "NULL"
        by_status[st_key] = by_status.get(st_key, 0) + 1

        eff_user = _norm_user(us)
        us_key = eff_user or "NULL"
        by_user_status[us_key] = by_user_status.get(us_key, 0) + 1

        if (status == "running") and (eff_user == "APPROVED"):
            running_approved_count += 1
            if merchant:
                approved_merchants_set.add(merchant)

    approved_merchants = sorted(approved_merchants_set)

    return {
        "total": total,
        "by_status": by_status,
        "by_user_status": by_user_status,
        "running_approved_count": running_approved_count,
        "approved_merchants": approved_merchants,
    }

@app.post(
    "/campaigns/backfill-user-status",
    tags=["Campaigns üì¢"],
    summary="Backfill user_registration_status cho campaigns b·ªã NULL/empty",
    description=(
        "D√≤ c√°c campaign c√≥ user_registration_status NULL/empty, g·ªçi campaign detail ƒë·ªÉ l·∫•y tr·∫°ng th√°i,\n"
        "chu·∫©n ho√° (SUCCESSFUL‚ÜíAPPROVED) v√† upsert l·∫°i. Tr·∫£ v·ªÅ th·ªëng k√™ tr∆∞·ªõc/sau v√† s·ªë l∆∞·ª£ng c·∫≠p nh·∫≠t.\n\n"
        "L∆∞u √Ω: D√πng AT_MOCK=1 ƒë·ªÉ ch·∫°y ·ªü ch·∫ø ƒë·ªô mock n·∫øu ch∆∞a c·∫•u h√¨nh Accesstrade."
    )
)
async def backfill_user_status(limit: int = 200, db: Session = Depends(get_db)):
    # Helper: normalize user status
    def _norm(us: str | None) -> str | None:
        if not us:
            return None
        s = str(us).strip().upper()
        if not s:
            return None
        if s == "SUCCESSFUL":
            return "APPROVED"
        return s

    def _summary() -> dict:
        rows = db.query(models.Campaign.status, models.Campaign.user_registration_status).all()
        total = len(rows)
        by_status: dict[str,int] = {}
        by_user: dict[str,int] = {}
        for st, us in rows:
            st_key = st or "NULL"
            by_status[st_key] = by_status.get(st_key, 0) + 1
            eff = _norm(us) or "NULL"
            by_user[eff] = by_user.get(eff, 0) + 1
        return {"total": total, "by_status": by_status, "by_user_status": by_user}

    before = _summary()

    targets = (
        db.query(models.Campaign)
        .filter(or_(models.Campaign.user_registration_status.is_(None), func.trim(models.Campaign.user_registration_status) == ""))
        .limit(limit)
        .all()
    )
    fixed = 0
    for c in targets:
        try:
            det = await fetch_campaign_detail(db, c.campaign_id)
            if not det:
                continue
            user_raw = (
                det.get("user_registration_status")
                or det.get("publisher_status")
                or det.get("user_status")
            )
            if not user_raw:
                appr = det.get("approval")
                if isinstance(appr, str) and appr.lower() in ("successful", "pending", "unregistered"):
                    user_raw = "APPROVED" if appr.lower() == "successful" else appr.upper()
            eff = _norm(user_raw)
            if not eff:
                continue
            crud.upsert_campaign(db, schemas.CampaignCreate(
                campaign_id=str(c.campaign_id),
                user_registration_status=eff,
            ))
            fixed += 1
        except Exception:
            continue

    after = _summary()
    return {"fixed": fixed, "before": before, "after": after}

# Legacy maintenance endpoints removed; project uses the new standard exclusively.

@app.get("/campaigns", response_model=list[schemas.CampaignOut], tags=["Campaigns üì¢"])
def list_campaigns_api(
    status: str | None = None,
    approval: str | None = None,
    user_status: str | None = None,
    merchant: str | None = None,
    db: Session = Depends(get_db),
):
    q = db.query(models.Campaign)
    if status:
        q = q.filter(models.Campaign.status == status)
    # approval gi·ªù ch·ªâ mang nghƒ©a ki·ªÉu duy·ªát campaign; kh√¥ng d√πng cho user status filter n·ªØa
    if approval:
        q = q.filter(models.Campaign.approval == approval)
    # Filter user_status theo chu·∫©n m·ªõi tr·ª±c ti·∫øp
    if user_status:
        us = user_status.strip().upper()
        if us == "SUCCESSFUL":
            us = "APPROVED"
        q = q.filter(func.upper(func.trim(models.Campaign.user_registration_status)) == us)
    if merchant:
        q = q.filter(models.Campaign.merchant == merchant)
    return q.order_by(models.Campaign.updated_at.desc()).all()

@app.get("/campaigns/approved-merchants", response_model=list[str], tags=["Campaigns üì¢"])
def list_approved_merchants_api(db: Session = Depends(get_db)):
    rows = (
        db.query(models.Campaign.merchant)
        .filter(models.Campaign.status == "running")
        .filter(func.upper(func.trim(models.Campaign.user_registration_status)).in_(["APPROVED", "SUCCESSFUL"]))
        .distinct()
        .all()
    )
    merchants = sorted({m for (m,) in rows if m})
    return merchants

@app.get("/offers", response_model=list[schemas.ProductOfferOut], tags=["Offers üõí"])
def list_offers_api(
    merchant: str | None = None,
    skip: int = 0,
    limit: int = 50,
    category: Literal["offers", "top-products"] = Query(
        "offers",
        description="Nh√≥m d·ªØ li·ªáu: offers | top-products"
    ),
    db: Session = Depends(get_db)
):
    """
    üõí L·∫•y danh s√°ch s·∫£n ph·∫©m trong DB c√≥ ph√¢n trang  
    - `merchant`: l·ªçc theo t√™n merchant (vd: `shopee`, `lazada`, `tiki`)  
    - `skip`: s·ªë b·∫£n ghi b·ªè qua (offset)  
    - `limit`: s·ªë b·∫£n ghi t·ªëi ƒëa tr·∫£ v·ªÅ  
    - `category`: 'offers' (m·∫∑c ƒë·ªãnh) ho·∫∑c 'top-products'.
    """
    cat = (category or "offers").strip().lower()
    if cat not in ("offers", "top-products"):
        raise HTTPException(status_code=400, detail="category kh√¥ng h·ª£p l·ªá; ch·ªâ h·ªó tr·ª£: offers | top-products")

    if cat == "top-products":
        rows = crud.list_offers(db, merchant=merchant, skip=skip, limit=limit, source_type="top_products")
    else:
        # 'offers' m·∫∑c ƒë·ªãnh: lo·∫°i tr·ª´ c√°c nh√≥m kh√¥ng ph·∫£i catalog ch√≠nh
        rows = crud.list_offers(db, merchant=merchant, skip=skip, limit=limit, exclude_source_types=["top_products", "promotions"])

    out: list[dict] = []
    for o in rows:
        item = {
            "id": o.id,
            "title": o.title,
            "url": o.url,
            "affiliate_url": o.affiliate_url,
            "image_url": o.image_url,
            "merchant": o.merchant,
            "campaign_id": o.campaign_id,
            "price": o.price,
            "currency": o.currency,
            # Model kh√¥ng c√≥ 'status'; gi·ªØ key cho t∆∞∆°ng th√≠ch, map sang approval_status
            "status": getattr(o, "status", None) or o.approval_status,
            "approval_status": o.approval_status,
            "eligible_commission": o.eligible_commission,
            "source_type": o.source_type,
            "affiliate_link_available": o.affiliate_link_available,
            "product_id": o.product_id,
            "extra": o.extra,
            "updated_at": o.updated_at,
            "desc": None, "cate": None, "shop_name": None, "update_time_raw": None,
        }

        try:
            ex = json.loads(o.extra) if o.extra else {}
            item["desc"] = ex.get("desc")
            item["cate"] = ex.get("cate")
            item["shop_name"] = ex.get("shop_name")
            item["update_time_raw"] = ex.get("update_time_raw") or ex.get("update_time")
        except Exception:
            pass
        out.append(item)

    return out

@app.post(
    "/ingest/policy",
    tags=["Settings ‚öôÔ∏è"],
    summary="C·∫•u h√¨nh policy ingest",
    description=(
        "B·∫≠t/t·∫Øt ch·∫ø ƒë·ªô ch·ªâ ingest s·∫£n ph·∫©m c√≥ commission policy.\n"
        "B·∫Øt bu·ªôc: (kh√¥ng c√≥) ‚Äî d√πng query only_with_commission=true/false.\n"
        "V√≠ d·ª•: /ingest/policy?only_with_commission=true"
    )
)
def set_ingest_policy(only_with_commission: bool = False, db: Session = Depends(get_db)):
    model_str = f"only_with_commission={'true' if only_with_commission else 'false'}"
    cfg = crud.upsert_api_config_by_name(db, schemas.APIConfigCreate(
        name="ingest_policy",
        base_url="-",
        api_key="-",
        model=model_str,
    ))
    return {"ok": True, "ingest_policy": model_str, "config_id": cfg.id}

@app.post(
    "/ingest/policy/check-urls",
    tags=["Settings ‚öôÔ∏è"],
    summary="B·∫≠t/t·∫Øt ki·ªÉm tra link khi IMPORT EXCEL",
    description=(
        "Ch·ªâ ·∫£nh h∆∞·ªüng import Excel. API ingest (V1/V2) lu√¥n m·∫∑c ƒë·ªãnh KH√îNG check link.\n"
        "B·∫Øt bu·ªôc: (kh√¥ng c√≥) ‚Äî d√πng query enable=true/false.\n"
        "V√≠ d·ª•: /ingest/policy/check-urls?enable=true"
    )
)
def set_ingest_policy_check_urls(enable: bool = False, db: Session = Depends(get_db)):
    # d√πng store flags trong api_configs.name='ingest_policy'
    crud.set_policy_flag(db, "check_urls", enable)
    flags = crud.get_policy_flags(db)
    return {"ok": True, "flags": flags}

@app.post(
    "/ingest/products",
    tags=["Ingest üåê"],
    summary="Ingest s·∫£n ph·∫©m t·ª´ nhi·ªÅu provider",
    description=(
        "Nh·∫≠p s·∫£n ph·∫©m v√†o DB t·ª´ c√°c provider. Hi·ªán h·ªó tr·ª£ Accesstrade.\n\n"
        "- B·∫Øt bu·ªôc: (kh√¥ng c√≥ ‚Äî provider m·∫∑c ƒë·ªãnh \"accesstrade\", path m·∫∑c ƒë·ªãnh \"/v1/publishers/product_search\").\n"
        "- Tu·ª≥ ch·ªçn: path, params (chuy·ªÉn xu·ªëng API c·ªßa provider).\n\n"
        "V√≠ d·ª• body JSON:\n"
        "{\n  \"provider\": \"accesstrade\",\n  \"path\": \"/v1/datafeeds\",\n  \"params\": {\"merchant\": \"tikivn\", \"page\": \"1\", \"limit\": \"50\"}\n}"
    )
)
async def ingest_products(
    req: IngestReq = Body(
        ...,
        examples={
            "default": {
                "summary": "Datafeeds theo merchant",
                "value": {
                    "provider": "accesstrade",
                    "path": "/v1/datafeeds",
                    "params": {"merchant": "tikivn", "page": "1", "limit": "50"}
                }
            }
        }
    ),
    db: Session = Depends(get_db),
):
    provider = (req.provider or "accesstrade").lower()
    ops = _registry.get(provider)
    if not ops:
        raise HTTPException(status_code=400, detail=f"Provider '{provider}' hi·ªán ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£")
    return await ops.products(req, db)

# Internal helper: Accesstrade implementation for products ingest
async def _ingest_products_accesstrade_impl(req: IngestReq, db: Session):
    from accesstrade_service import (
        fetch_active_campaigns, fetch_campaign_detail, fetch_products,
        fetch_promotions, fetch_commission_policies, map_at_product_to_offer, _check_url_alive,
    )
    active_campaigns = await fetch_active_campaigns(db)
    logger.info("Fetched %d active campaigns", len(active_campaigns))
    merchant_campaign_map = {v: k for k, v in active_campaigns.items()}

    items = await fetch_products(db, req.path, req.params or {})
    if not items:
        return {"ok": True, "imported": 0}

    imported = 0
    def _vlog(reason: str, extra: dict | None = None):
        try:
            from accesstrade_service import _log_jsonl as _rawlog
            payload = {"endpoint": "manual_ingest", "reason": reason}
            if extra:
                payload.update(extra)
            _rawlog("ingest_skips.jsonl", payload)
        except Exception:
            pass

    for it in items:
        policies = []  # ensure defined for each iteration
        camp_id = str(it.get("campaign_id") or it.get("campaign_id_str") or "").strip()
        merchant = str(it.get("merchant") or it.get("campaign") or "").lower().strip()
        _alias = {"lazadacps": "lazada", "tikivn": "tiki"}
        merchant_norm = _alias.get(merchant, merchant.split(".")[0] if "." in merchant else merchant)

        def _resolve_campaign_id_by_suffix(m_name: str) -> tuple[str | None, str]:
            if m_name in merchant_campaign_map:
                return merchant_campaign_map[m_name], "exact"
            for m_key, cid in merchant_campaign_map.items():
                if m_key.endswith(m_name) or f"_{m_name}" in m_key:
                    return cid, f"suffix({m_key})"
            for m_key, cid in merchant_campaign_map.items():
                if m_name in m_key:
                    return cid, f"contains({m_key})"
            return None, ""

        if not camp_id:
            camp_id, how = _resolve_campaign_id_by_suffix(merchant_norm)
            if camp_id:
                logger.debug("Fallback campaign_id=%s via %s cho merchant=%s (norm=%s) [manual ingest]",
                             camp_id, how, merchant, merchant_norm)
            else:
                _vlog("no_campaign_match", {"merchant": merchant, "merchant_norm": merchant_norm})

        if not camp_id or camp_id not in active_campaigns:
            logger.info("Skip product v√¨ campaign_id=%s kh√¥ng active [manual ingest] (merchant=%s)", camp_id, merchant_norm)
            _vlog("campaign_not_active", {"campaign_id": camp_id, "merchant": merchant_norm})
            continue

        try:
            _row = crud.get_campaign_by_cid(db, camp_id)
            _us = (_row.user_registration_status or "").upper() if _row else ""
            if _us == "SUCCESSFUL":
                _us = "APPROVED"
            if not _row or _us != "APPROVED":
                logger.info("Skip product v√¨ campaign_id=%s ch∆∞a APPROVED [manual ingest]", camp_id)
                _vlog("campaign_not_approved", {"campaign_id": camp_id})
                continue
        except Exception:
            continue

        promotions_data = await fetch_promotions(db, merchant_norm) if merchant_norm else []
        if promotions_data:
            for prom in promotions_data:
                try:
                    crud.upsert_promotion(db, schemas.PromotionCreate(
                        campaign_id=camp_id,
                        name=prom.get("name"),
                        content=prom.get("content") or prom.get("description"),
                        start_time=prom.get("start_time"),
                        end_time=prom.get("end_time"),
                        coupon=prom.get("coupon"),
                        link=prom.get("link"),
                    ))
                except Exception as e:
                    logger.debug("Skip promotion upsert: %s", e)

        try:
            camp = await fetch_campaign_detail(db, camp_id)
            if camp:
                status_val = camp.get("status")
                approval_val = camp.get("approval")
                _user_raw = (
                    camp.get("user_registration_status")
                    or camp.get("publisher_status")
                    or camp.get("user_status")
                )
                def _map_status(v):
                    s = str(v).strip() if v is not None else None
                    if s == "1": return "running"
                    if s == "0": return "paused"
                    return s
                crud.upsert_campaign(db, schemas.CampaignCreate(
                    campaign_id=str(camp.get("campaign_id") or camp_id),
                    merchant=str(camp.get("merchant") or merchant_norm or "").lower() or None,
                    name=camp.get("name"),
                    status=_map_status(status_val),
                    approval=(str(approval_val) if approval_val is not None else None),
                    start_time=camp.get("start_time"),
                    end_time=camp.get("end_time"),
                    user_registration_status=(_user_raw if _user_raw not in (None, "", []) else None),
                ))
        except Exception as e:
            logger.debug("Skip campaign upsert: %s", e)

        try:
            policies = await fetch_commission_policies(db, camp_id)
            for rec in (policies or []):
                crud.upsert_commission_policy(db, schemas.CommissionPolicyCreate(
                    campaign_id=camp_id,
                    reward_type=rec.get("reward_type") or rec.get("type"),
                    sales_ratio=rec.get("sales_ratio") or rec.get("ratio"),
                    sales_price=rec.get("sales_price"),
                    target_month=rec.get("target_month"),
                ))
        except Exception as e:
            logger.debug("Skip commission upsert: %s", e)

        data = map_at_product_to_offer(it, commission=policies, promotion=promotions_data)
        if not data.get("url") or not data.get("source_id"):
            continue

        data["campaign_id"] = camp_id
        data["source_type"] = "manual"
        _camp_row = crud.get_campaign_by_cid(db, camp_id)
        if _camp_row:
            us = (_camp_row.user_registration_status or "").upper()
            if us == "SUCCESSFUL":
                us = "APPROVED"
            data["approval_status"] = (
                "successful" if us == "APPROVED" else
                "pending" if us == "PENDING" else
                "unregistered" if us == "NOT_REGISTERED" else None
            )
            data["eligible_commission"] = (
                (_camp_row.status == "running") and (us == "APPROVED")
            )

        if not await _check_url_alive(str(data.get("url") or "")):
            logger.info("Skip dead product [manual ingest]: title='%s'", data.get("title"))
            _vlog("dead_url", {"url": data.get("url")})
            continue

        try:
            crud.upsert_offer_for_excel(db, schemas.ProductOfferCreate(**data))
        except Exception:
            crud.upsert_offer_by_source(db, schemas.ProductOfferCreate(**data))
        imported += 1

    return {"ok": True, "imported": imported}

async def ingest_accesstrade_datafeeds_all(
    req: IngestAllDatafeedsReq,
    db: Session = Depends(get_db),
):

    # D√πng lu√¥n session `db` t·ª´ Depends; kh√¥ng m·ªü/ƒë√≥ng session m·ªõi t·∫°i ƒë√¢y
    from accesstrade_service import fetch_campaigns_full_all, fetch_campaign_detail
    items = await fetch_campaigns_full_all(
        db,
        status="running",
        limit_per_page=req.limit_per_page or 100,
        max_pages=req.max_pages or 200,
        throttle_ms=req.throttle_ms or 0
    )
    imported = 0
    for camp in (items or []):
        try:
            camp_id = str(camp.get("campaign_id") or camp.get("id") or "").strip()
            merchant = str(camp.get("merchant") or camp.get("name") or "").lower().strip()
            status_val = camp.get("status")
            approval_val = camp.get("approval")

            # map status "1/0" -> "running/paused" n·∫øu API tr·∫£ d·∫°ng s·ªë
            def _map_status(v):
                s = str(v).strip() if v is not None else None
                if s == "1": return "running"
                if s == "0": return "paused"
                return s

            # T√°ch approval (ki·ªÉu duy·ªát campaign) ‚Üî user_status (tr·∫°ng th√°i ƒëƒÉng k√Ω c·ªßa ri√™ng m√¨nh)
            def _split_approval_or_user(v):
                if v is None:
                    return (None, None)
                s = str(v).strip().lower()
                if s in ("successful", "pending", "unregistered"):
                    # ƒê√¢y th·ª±c ch·∫•t l√† tr·∫°ng th√°i ƒëƒÉng k√Ω c·ªßa b·∫°n
                    user = "APPROVED" if s == "successful" else s.upper()
                    return (None, user)
                return (str(v), None)

            approval_for_campaign, user_status = _split_approval_or_user(approval_val)

            # NEW: n·∫øu API kh√¥ng cung c·∫•p user_status, d√πng gi√° tr·ªã c≈© trong DB ƒë·ªÉ tr√°nh m·∫•t record
            existing = crud.get_campaign_by_cid(db, camp_id)
            eff_user = user_status or (existing.user_registration_status if existing else None)

            # L·ªçc: ch·ªâ gi·ªØ APPROVED/PENDING
            if eff_user not in ("APPROVED", "PENDING"):
                continue
            # Kh√¥ng enrich ·ªü job ƒë·ªãnh k·ª≥ ƒë·ªÉ nhanh (c√≥ th·ªÉ b·∫≠t ·ªü API /ingest/v2/campaigns/sync)

            payload = schemas.CampaignCreate(
                campaign_id=camp_id,
                merchant=merchant or None,
                name=camp.get("name"),
                status=_map_status(status_val),
                approval=approval_for_campaign,                 # KH√îNG c√≤n ghi 'successful/pending/unregistered' ·ªü ƒë√¢y
                start_time=camp.get("start_time"),
                end_time=camp.get("end_time"),
                # Ghi user_status hi·ªáu d·ª•ng (∆∞u ti√™n gi√° tr·ªã m·ªõi; n·∫øu None d√πng gi√° tr·ªã c≈© ƒë·ªÉ tr√°nh NULL)
                user_registration_status=eff_user,           # NOT_REGISTERED/PENDING/APPROVED ho·∫∑c None
            )

            crud.upsert_campaign(db, payload)
            imported += 1
        except Exception as e:
            logger.debug("Skip campaign upsert: %s", e)

    logger.info("Scheduled campaigns sync done: %s", imported)

    from accesstrade_service import (
        fetch_products, fetch_active_campaigns, fetch_promotions,
        fetch_commission_policies, fetch_campaign_detail,
        map_at_product_to_offer, _check_url_alive
    )

    # 0) L·∫•y danh s√°ch campaign ƒëang ch·∫°y ƒë·ªÉ l·ªçc
    active_campaigns = await fetch_active_campaigns(db)  # dict {campaign_id: merchant}
    if not active_campaigns:
        # Fallback: l·∫•y t·ª´ DB n·∫øu API kh√¥ng tr·∫£ (·ªïn ƒë·ªãnh cho smoke test)
        active_campaigns = {
            c.campaign_id: c.merchant
            for c in db.query(models.Campaign)
                        .filter(models.Campaign.status == "running")
                        .filter(models.Campaign.user_registration_status.in_(["APPROVED","SUCCESSFUL"]))
                        .all()
            if c.campaign_id and c.merchant
        }
    merchant_campaign_map = {v: k for k, v in active_campaigns.items()}  # {merchant: campaign_id}

    # Map merchant -> approved campaign_id (running + user APPROVED) for fallback rebinding
    approved_cid_by_merchant: dict[str, str] = {}
    try:
        for cid, m in active_campaigns.items():
            _row = crud.get_campaign_by_cid(db, cid)
            if _row:
                _us = (_row.user_registration_status or "").upper()
                if _us == "SUCCESSFUL":
                    _us = "APPROVED"
                if _us == "APPROVED":
                    approved_cid_by_merchant[(m or "").lower()] = cid
    except Exception:
        pass

    # ch√≠nh s√°ch ingest (API b·ªè qua policy; policy ch·ªâ √°p d·ª•ng cho import Excel)
    only_with_commission = False

    # 2) Cache promotions theo merchant ƒë·ªÉ tr√°nh g·ªçi tr√πng
    promotion_cache: dict[str, list[dict]] = {}

    # NEW: Cache commission theo campaign_id ƒë·ªÉ tr√°nh spam API (fix NameError)
    cache_commissions: dict[str, list[dict]] = {}

    # 3) Tham s·ªë g·ªçi API datafeeds + b·ªô l·ªçc ph√≠a server
    base_params = dict(req.params or {})
    base_params.pop("page", None)   # client kh√¥ng c·∫ßn truy·ªÅn
    base_params.pop("limit", None)  # client kh√¥ng c·∫ßn truy·ªÅn

    # Chu·∫©n ho√° alias filters
    filter_merchant = (base_params.get("merchant") or base_params.get("campaign") or base_params.get("merchant_slug"))
    if isinstance(filter_merchant, str):
        filter_merchant = filter_merchant.strip().lower()
    filter_cid = (base_params.get("campaign_id") or base_params.get("camp_id"))
    if isinstance(filter_cid, str):
        filter_cid = filter_cid.strip()

    imported = 0
    total_pages = 0

    # X√¢y danh s√°ch merchants c·∫ßn ch·∫°y: ∆∞u ti√™n t·ª´ active_campaigns (ƒëang ch·∫°y) ‚à© DB (APPROVED)
    approved_merchants: set[str] = set()
    try:
        for cid, m in active_campaigns.items():
            _row = crud.get_campaign_by_cid(db, cid)
            if _row:
                _us = (_row.user_registration_status or "").upper()
                if _us == "SUCCESSFUL":
                    _us = "APPROVED"
                if _us == "APPROVED":
                    approved_merchants.add((m or "").lower())
    except Exception:
        pass
    if not approved_merchants:
        # Fallback: l·∫•y t·ª´ DB
        approved_merchants = {
            (c.merchant or "").lower()
            for c in db.query(models.Campaign)
                        .filter(models.Campaign.status == "running")
                        .filter(models.Campaign.user_registration_status.in_(["APPROVED","SUCCESSFUL"]))
                        .all()
            if c.merchant
        }

    # √Åp d·ª•ng filter merchant/campaign_id n·∫øu c√≥
    forced_cid_by_merchant: dict[str, str] = {}
    if filter_cid:
        # N·∫øu campaign_id c√≥ trong active list, gi·ªõi h·∫°n merchant t∆∞∆°ng ·ª©ng
        cid = str(filter_cid)
        m = active_campaigns.get(cid)
        if m:
            m_norm = (m or "").lower()
            approved_merchants = {m_norm} if m_norm in approved_merchants else set()
            forced_cid_by_merchant[m_norm] = cid
        else:
            # Kh√¥ng t√¨m th·∫•y campaign_id ƒëang ch·∫°y ‚Üí kh√¥ng ingest g√¨
            approved_merchants = set()

    if filter_merchant:
        m_norm = filter_merchant
        # alias n·ªôi b·ªô
        _alias = {"lazadacps": "lazada", "tikivn": "tiki"}
        m_norm = _alias.get(m_norm, m_norm)
        if approved_merchants:
            approved_merchants = {m for m in approved_merchants if (m == m_norm or m.endswith(m_norm) or (m_norm in m))}
        else:
            # n·∫øu tr∆∞·ªõc ƒë√≥ r·ªóng (v√≠ d·ª• ƒë√£ l·ªçc theo campaign_id kh√¥ng kh·ªõp) th√¨ gi·ªØ r·ªóng
            pass

    # verbose helper
    def _vlog(reason: str, extra: dict | None = None):
        try:
            from accesstrade_service import _log_jsonl as _rawlog
            payload = {"endpoint": "datafeeds_all", "reason": reason}
            if extra:
                payload.update(extra)
            _rawlog("ingest_skips.jsonl", payload)
        except Exception:
            pass

    # L·∫∑p t·ª´ng merchant ƒë√£ APPROVED v√† g·ªçi /v1/datafeeds v·ªõi b·ªô l·ªçc merchant
    for m in sorted(approved_merchants):
        _alias = {"lazadacps": "lazada", "tikivn": "tiki"}
        merchant_fetch = _alias.get(m, m)

        # X√°c ƒë·ªãnh campaign_id t∆∞∆°ng ·ª©ng merchant ƒëang fetch (∆∞u ti√™n exact, sau ƒë√≥ suffix/contains)
        cid_for_fetch = None
        # ∆Øu ti√™n forced campaign id n·∫øu ƒë√£ x√°c ƒë·ªãnh
        if m in forced_cid_by_merchant:
            cid_for_fetch = forced_cid_by_merchant[m]
        for cid, mm in active_campaigns.items():
            if (mm or "").lower() == merchant_fetch or (mm or "").lower() == m:
                cid_for_fetch = cid
                break
        if not cid_for_fetch:
            for cid, mm in active_campaigns.items():
                mm_l = (mm or "").lower()
                if mm_l.endswith(merchant_fetch) or f"_{merchant_fetch}" in mm_l or (merchant_fetch in mm_l):
                    cid_for_fetch = cid
                    break
        if not cid_for_fetch and merchant_fetch != m:
            for cid, mm in active_campaigns.items():
                mm_l = (mm or "").lower()
                if mm_l.endswith(m) or f"_{m}" in mm_l or (m in mm_l):
                    cid_for_fetch = cid
                    break

        page = 1
        while page <= max(1, req.max_pages):
            params = dict(base_params)
            params["page"] = str(page)
            params["limit"] = str(req.limit_per_page)
            params["merchant"] = merchant_fetch

            items = await fetch_products(db, "/v1/datafeeds", params)
            if not items:
                # Kh√¥ng c√≥ d·ªØ li·ªáu cho merchant/page n√†y ‚Üí d·ª´ng merchant
                break

            # X·ª≠ l√Ω t·ª´ng item
            for it in items:
                # G·∫Øn merchant theo v√≤ng l·∫∑p ngo√†i v√† force-bind campaign_id theo merchant ƒëang fetch
                merchant_norm = m
                camp_id = cid_for_fetch

                # B·ªè qua n·∫øu campaign kh√¥ng active
                if not camp_id or camp_id not in active_campaigns:
                    if req.verbose:
                        _vlog("campaign_not_active", {"campaign_id": camp_id, "merchant": merchant_norm, "page": page})
                    continue

                # Y√äU C·∫¶U: user APPROVED
                try:
                    _row = crud.get_campaign_by_cid(db, camp_id)
                    us = (_row.user_registration_status or "").upper() if _row else ""
                    if us == "SUCCESSFUL":
                        us = "APPROVED"
                    if (not _row) or (us != "APPROVED"):
                        # Fallback: n·∫øu merchant c√≥ campaign kh√°c ƒë√£ APPROVED, d√πng campaign ƒë√≥
                        alt_cid = approved_cid_by_merchant.get(merchant_norm)
                        if alt_cid:
                            if req.verbose:
                                _vlog("rebind_campaign_id", {"from": camp_id, "to": alt_cid, "merchant": merchant_norm, "page": page})
                            camp_id = alt_cid
                        else:
                            if req.verbose:
                                _vlog("campaign_not_approved", {"campaign_id": camp_id, "merchant": merchant_norm, "page": page})
                            continue
                except Exception:
                    continue

                # L·∫•y commission theo camp_id (cache)
                policies = cache_commissions.get(camp_id)
                if policies is None:
                    try:
                        policies = await fetch_commission_policies(db, camp_id)
                        cache_commissions[camp_id] = policies or []
                        for p in (policies or []):
                            crud.upsert_commission_policy(db, schemas.CommissionPolicyCreate(
                                campaign_id=str(camp_id),
                                reward_type=p.get("reward_type") or p.get("type"),
                                sales_ratio=p.get("sales_ratio") or p.get("ratio"),
                                sales_price=p.get("sales_price"),
                                target_month=p.get("target_month"),
                            ))
                    except Exception:
                        policies = []
                        logger.debug("Skip commission upsert")

                if only_with_commission:
                    eligible_by_status = False
                    try:
                        _camp_row = crud.get_campaign_by_cid(db, camp_id)
                        if _camp_row:
                            _us = (_camp_row.user_registration_status or "").upper()
                            if _us == "SUCCESSFUL":
                                _us = "APPROVED"
                            eligible_by_status = (_camp_row.status == "running") and (_us == "APPROVED")
                    except Exception:
                        eligible_by_status = False

                    has_commission = bool(policies) or eligible_by_status
                    if not has_commission:
                        if req.verbose:
                            _vlog("no_commission", {"campaign_id": camp_id, "merchant": merchant_norm, "page": page})
                        continue

                # Promotions: l·∫•y theo merchant, c√≥ cache + upsert DB
                if merchant_norm not in promotion_cache:
                    promotion_cache[merchant_norm] = await fetch_promotions(db, merchant_norm) or []
                pr_list = promotion_cache.get(merchant_norm, [])
                if pr_list:
                    for prom in pr_list:
                        try:
                            crud.upsert_promotion(db, schemas.PromotionCreate(
                                campaign_id=camp_id,
                                name=prom.get("name"),
                                content=prom.get("content") or prom.get("description"),
                                start_time=prom.get("start_time"),
                                end_time=prom.get("end_time"),
                                coupon=prom.get("coupon"),
                                link=prom.get("link"),
                            ))
                        except Exception as e:
                            logger.debug("Skip promotion upsert: %s", e)

                # Campaign detail: ƒë·ªìng nh·∫•t upsert
                try:
                    camp = await fetch_campaign_detail(db, camp_id)
                    if camp:
                        status_val = camp.get("status")
                        approval_val = camp.get("approval")

                        def _map_status(v):
                            s = str(v).strip() if v is not None else None
                            if s == "1": return "running"
                            if s == "0": return "paused"
                            return s

                        _user_raw = (
                            camp.get("user_registration_status")
                            or camp.get("publisher_status")
                            or camp.get("user_status")
                        )
                        crud.upsert_campaign(db, schemas.CampaignCreate(
                            campaign_id=str(camp.get("campaign_id") or camp_id),
                            merchant=str(camp.get("merchant") or merchant_norm or "").lower() or None,
                            name=camp.get("name"),
                            status=_map_status(status_val),
                            approval=(str(approval_val) if approval_val is not None else None),
                            start_time=camp.get("start_time"),
                            end_time=camp.get("end_time"),
                            user_registration_status=(_user_raw if _user_raw not in (None, "", []) else None),
                        ))
                except Exception as e:
                    logger.debug("Skip campaign upsert: %s", e)

                # Chu·∫©n ho√° record ‚Üí ProductOfferCreate
                data = map_at_product_to_offer(it, commission=policies, promotion=pr_list)
                if not data or not data.get("url"):
                    continue
                data["campaign_id"] = camp_id

                # NEW: g·∫Øn lo·∫°i ngu·ªìn + tr·∫°ng th√°i ph√™ duy·ªát & eligibility
                data["source_type"] = "datafeeds"
                _camp_row = crud.get_campaign_by_cid(db, camp_id)
                if _camp_row:
                    us = (_camp_row.user_registration_status or "").upper()
                    if us == "SUCCESSFUL":
                        us = "APPROVED"
                    data["approval_status"] = (
                        "successful" if us == "APPROVED" else
                        "pending" if us == "PENDING" else
                        "unregistered" if us == "NOT_REGISTERED" else None
                    )
                    data["eligible_commission"] = (
                        (_camp_row.status == "running") and (us == "APPROVED")
                    )

                # Link g·ªëc: ch·ªâ ki·ªÉm tra khi b·∫≠t c·ªù (ƒë·ªÉ tr√°nh b·ªè s√≥t do ch·∫∑n bot/timeout trong m√¥i tr∆∞·ªùng container)
                if req.check_urls:
                    if not await _check_url_alive(data["url"]):
                        if req.verbose:
                            _vlog("dead_url", {"url": data.get("url"), "merchant": merchant_norm, "page": page})
                        continue

                try:
                    crud.upsert_offer_for_excel(db, schemas.ProductOfferCreate(**data))
                except Exception:
                    crud.upsert_offer_by_source(db, schemas.ProductOfferCreate(**data))
                imported += 1

            # Sau khi x·ª≠ l√Ω xong 1 trang cho merchant hi·ªán t·∫°i
            total_pages += 1
            # D·ª´ng n·∫øu trang hi·ªán t·∫°i √≠t h∆°n limit ‚Üí coi nh∆∞ trang cu·ªëi
            if len(items) < (req.limit_per_page or 100):
                break

            # Trang ti·∫øp theo
            page += 1
            sleep_ms = getattr(req, "throttle_ms", 0) or 0
            if sleep_ms:
                await asyncio.sleep(sleep_ms / 1000.0)

    return {"ok": True, "imported": imported, "pages": total_pages}

async def ingest_v2_campaigns_sync(
    req: CampaignsSyncReq,
    db: Session = Depends(get_db),
):
    from accesstrade_service import fetch_campaigns_full_all, fetch_campaign_detail

    # --- gom d·ªØ li·ªáu theo nhi·ªÅu tr·∫°ng th√°i (running/paused/...) n·∫øu ƒë∆∞·ª£c truy·ªÅn ---
    statuses = (req.statuses or ["running", "paused"])  # m·∫∑c ƒë·ªãnh: ch·∫°y c·∫£ running v√† paused
    unique = {}
    for st in statuses:
        try:
            items = await fetch_campaigns_full_all(
                db,
                status=st,
                limit_per_page=req.limit_per_page or 50,
                max_pages=1000,
                throttle_ms=req.throttle_ms or 0,
                page_concurrency=req.page_concurrency or 6,
                window_pages=req.window_pages or 10,
            )
            for it in (items or []):
                cid = str(it.get("campaign_id") or it.get("id") or "").strip()
                if cid:
                    unique[cid] = it
        except Exception as e:
            logger.error("ingest_v2_campaigns_sync: fetch failed (%s): %s", st, e)

    imported = 0

    def _map_status(v):
        s = str(v).strip() if v is not None else None
        if s == "1": return "running"
        if s == "0": return "paused"
        return s

    def _split_approval_or_user(v):
        """
        N·∫øu AT tr·∫£ 'approval' ‚àà {successful,pending,unregistered} th√¨ ƒë√¢y th·ª±c ch·∫•t l√† user_status.
        Tr·∫£ v·ªÅ tuple: (approval_for_campaign, user_status_for_me)
        """
        if v is None:
            return (None, None)
        s = str(v).strip().lower()
        if s in ("successful", "pending", "unregistered"):
            # map v·ªÅ NOT_REGISTERED/PENDING/APPROVED
            user = "APPROVED" if s == "successful" else s.upper()
            return (None, user)
        # c√≤n l·∫°i ƒë·ªÉ nguy√™n cho ki·ªÉu duy·ªát (auto/manual/‚Ä¶)
        return (str(v), None)

    for camp in unique.values():
        try:
            camp_id = str(camp.get("campaign_id") or camp.get("id") or "").strip()
            merchant = str(camp.get("merchant") or camp.get("name") or "").lower().strip()
            if req.merchant and merchant != req.merchant.strip().lower():
                continue

            status_val = _map_status(camp.get("status"))
            approval_val, user_status = _split_approval_or_user(camp.get("approval"))

            # enrich user_status t·ª´ detail n·∫øu b·∫≠t c·ªù (ch√≠nh x√°c h∆°n)
            if req.enrich_user_status or (req.only_my and not user_status):
                try:
                    det = await fetch_campaign_detail(db, camp_id)
                    if det:
                        _user_raw = (
                            det.get("user_registration_status")
                            or det.get("publisher_status")
                            or det.get("user_status")
                        )
                        # Fallback: ƒë√¥i khi detail ch·ªâ tr·∫£ 'approval' = successful/pending/unregistered
                        if not _user_raw:
                            appr_det = det.get("approval")
                            if isinstance(appr_det, str) and appr_det.lower() in ("successful","pending","unregistered"):
                                _user_raw = "APPROVED" if appr_det.lower() == "successful" else appr_det.upper()
                        if _user_raw not in (None, "", []):
                            user_status = str(_user_raw).strip().upper()
                except Exception:
                    pass

            # L·ªçc only_my: ch·ªâ gi·ªØ APPROVED/PENDING.
            # N·∫øu ƒë√£ b·∫≠t enrich_user_status nh∆∞ng v·∫´n KH√îNG l·∫•y ƒë∆∞·ª£c user_status (API kh√¥ng tr·∫£),
            # cho ph√©p import ƒë·ªÉ l∆∞u l·∫°i tr∆∞·ªõc (tr√°nh imported=0 ·ªü l·∫ßn ƒë·∫ßu).
            if req.only_my:
                existing = crud.get_campaign_by_cid(db, camp_id)
                eff_user = user_status or (existing.user_registration_status if existing else None)
                if eff_user not in ("APPROVED", "PENDING"):
                    if req.enrich_user_status and eff_user is None:
                        logger.debug("only_my=true: allow %s (%s) d√π user_status ch∆∞a r√µ (first-run).", camp_id, merchant)
                    else:
                        logger.debug("only_my=true: skip %s (%s) v√¨ user_status=%s", camp_id, merchant, eff_user)
                        continue

            payload = schemas.CampaignCreate(
                campaign_id=camp_id,
                merchant=merchant or None,
                name=camp.get("name"),
                status=status_val,
                approval=approval_val,                  # KH√îNG c√≤n ghi 'successful' ·ªü ƒë√¢y n·ªØa
                start_time=camp.get("start_time"),
                end_time=camp.get("end_time"),
                # Ghi user_status hi·ªáu d·ª•ng (∆∞u ti√™n gi√° tr·ªã m·ªõi; n·∫øu None d√πng gi√° tr·ªã c≈© ƒë·ªÉ tr√°nh NULL)
                user_registration_status=eff_user,   # NOT_REGISTERED / PENDING / APPROVED / None
            )
            crud.upsert_campaign(db, payload)
            imported += 1
        except Exception as e:
            logger.debug("Skip campaign upsert: %s", e)

    return {"ok": True, "imported": imported}

# (Removed) Aliases for Accesstrade routes ‚Äî use unified endpoints instead

async def ingest_v2_promotions(
    req: IngestV2PromotionsReq,
    db: Session = Depends(get_db),
):
    from accesstrade_service import fetch_promotions, fetch_active_campaigns, _log_jsonl
    imported_promos = 0

    # Helper: ph√¢n lo·∫°i chu·ªói theo y√™u c·∫ßu
    def _classify_str(rec: dict, key: str) -> str | None:
        if key in rec:
            v = rec.get(key)
            s = (str(v).strip() if v is not None else "")
            # Tr√°nh l∆∞u placeholder v√†o DB: tr·∫£ v·ªÅ None n·∫øu tr·ªëng
            return s if s else None
        # key kh√¥ng t·ªìn t·∫°i ‚Üí kh√¥ng c√≥ d·ªØ li·ªáu m·ªõi
        return None

    # 0) T·∫≠p merchant c·∫ßn ch·∫°y = theo y√™u c·∫ßu ho·∫∑c theo DB c√°c campaign ƒë√£ APPROVED/SUCCESSFUL
    #    KH√îNG b·∫Øt bu·ªôc campaign ƒëang running ƒë·ªëi v·ªõi vi·ªác l∆∞u promotions
    #    L∆∞u √Ω: KH√îNG filter theo req.merchant ·ªü ƒë√¢y ƒë·ªÉ tr√°nh miss do alias (vd tikivn ‚Üî tiki)
    approved_rows = (
        db.query(models.Campaign)
        .filter(func.upper(func.trim(models.Campaign.user_registration_status)).in_(["APPROVED", "SUCCESSFUL"]))  # type: ignore
        .all()
    )

    # Map merchant -> danh s√°ch campaign ƒë√£ APPROVED (∆∞u ti√™n ch·ªçn status=running sau n√†y)
    approved_by_merchant: dict[str, list[models.Campaign]] = {}
    for c in approved_rows:
        if not c.merchant:
            continue
        mkey = c.merchant.lower()
        approved_by_merchant.setdefault(mkey, []).append(c)

    merchants: set[str] = set(approved_by_merchant.keys())
    if not merchants and not req.merchant:
        # Fallback m·ªÅm: n·∫øu DB ch∆∞a c√≥ d·ªØ li·ªáu user_status (l·∫ßn ƒë·∫ßu sync), l·∫•y merchants t·ª´ campaigns running
        active = await fetch_active_campaigns(db)  # {cid: merchant}
        merchants = {m for m in active.values() if m}
    if req.merchant:
        merchants = {req.merchant.strip().lower()}

    # 1) V√≤ng l·∫∑p t·ª´ng merchant
    for m in sorted(merchants):
        _alias = {"lazadacps": "lazada", "tikivn": "tiki"}
        m_fetch = _alias.get(m, m)
        promos = await fetch_promotions(db, m_fetch) or []

        # Ch·ªçn campaign_id ƒë√£ APPROVED & RUNNING cho merchant n√†y
        cid_candidates = approved_by_merchant.get(m, []) or approved_by_merchant.get(m_fetch, [])
        cid_pick: str | None = None
        for row in cid_candidates:
            if (row.status or "").lower() == "running":
                cid_pick = row.campaign_id
                break

        if not cid_pick:
            # Kh√¥ng c√≥ campaign APPROVED ƒëang ch·∫°y cho merchant n√†y ‚Üí kh√¥ng l∆∞u promotions, ch·ªâ log
            _log_jsonl("promotions.jsonl", {
                "endpoint": "promotions",
                "merchant": m,
                "ok": True,
                "items_count": len(promos),
                "skip_reason": "no_running_approved_campaign",
            })
            continue

        # upsert b·∫£ng promotions (CH·ªà khi c√≥ campaign ƒë√£ APPROVED)
        for p in promos:
            try:
                # Ph√¢n lo·∫°i c√°c tr∆∞·ªùng chu·ªói
                name_val = _classify_str(p, "name")
                # content ∆∞u ti√™n content; n·∫øu thi·∫øu content nh∆∞ng c√≥ description th√¨ d√πng description th·ª±c
                if ("content" not in p or not (p.get("content") or "").strip()) and (p.get("description") or "").strip():
                    content_val = str(p.get("description")).strip()
                else:
                    content_val = _classify_str(p, "content")
                coupon_val = _classify_str(p, "coupon")
                # link ∆∞u ti√™n 'link' > 'url'; n·∫øu c·∫£ hai thi·∫øu ‚Üí ph√¢n lo·∫°i theo key
                if ("link" not in p or not (p.get("link") or "").strip()) and (p.get("url") or "").strip():
                    link_val = str(p.get("url")).strip()
                else:
                    link_val = _classify_str(p, "link")

                start_time = p.get("start_time")
                end_time = p.get("end_time")

                # Kh√¥ng truy·ªÅn placeholder; None ƒë∆∞·ª£c ph√©p trong schema/model
                crud.upsert_promotion(db, schemas.PromotionCreate(
                    campaign_id=cid_pick,
                    name=name_val,
                    content=content_val,
                    start_time=start_time,
                    end_time=end_time,
                    coupon=coupon_val,
                    link=link_val,
                ))
                imported_promos += 1

                # Kh√¥ng c√≤n auto t·∫°o ProductOffer t·ª´ Promotions
            except Exception as e:
                logger.debug("Skip promotion/offer upsert: %s", e)

        # ngh·ªâ gi·ªØa c√°c merchant n·∫øu c√≥ c·∫•u h√¨nh throttle_ms
        sleep_ms = getattr(req, "throttle_ms", 0) or 0
        if sleep_ms:
            await asyncio.sleep(sleep_ms / 1000.0)

    return {"ok": True, "promotions": imported_promos}

"""Legacy provider-specific routes have been removed. Use unified endpoints."""

async def ingest_v2_top_products(
    req: IngestV2TopProductsReq,
    db: Session = Depends(get_db),
):
    from accesstrade_service import fetch_top_products, fetch_active_campaigns, _check_url_alive

    # 0) L·∫•y map campaign ƒëang ch·∫°y {campaign_id: merchant}
    active = await fetch_active_campaigns(db)  # {campaign_id: merchant}
    if not active:
        active = {
            c.campaign_id: c.merchant
            for c in db.query(models.Campaign)
                        .filter(models.Campaign.status == "running")
                        .filter(models.Campaign.user_registration_status.in_(["APPROVED","SUCCESSFUL"]))
                        .all()
            if c.campaign_id and c.merchant
        }

    # X√¢y danh s√°ch merchants ƒë√£ APPROVED & running
    approved_running_merchants: set[str] = set()
    for cid, m in active.items():
        row = crud.get_campaign_by_cid(db, cid)
        if not row:
            continue
        us = (row.user_registration_status or "").upper()
        if us == "SUCCESSFUL":
            us = "APPROVED"
        if us == "APPROVED" and (row.status or "").lower() == "running":
            approved_running_merchants.add((m or "").lower())

    # To√†n b·ªô merchants ƒëang active (ch·ªâ x√©t running theo API)
    all_active_merchants: set[str] = { (m or "").lower() for m in active.values() if m }

    # N·∫øu truy·ªÅn merchant ‚Üí ch·ªâ ch·∫°y merchant ƒë√≥; n·∫øu kh√¥ng ‚Üí ch·∫°y t·∫•t c·∫£ merchant ƒë√£ approved_running
    if req.merchant:
        merchants = {req.merchant.strip().lower()}
    else:
        merchants = set(approved_running_merchants)

    # DEFAULT date range: 30 ng√†y g·∫ßn nh·∫•t n·∫øu kh√¥ng truy·ªÅn
    if not req.date_from or not req.date_to:
        from datetime import datetime, timedelta, UTC
        _to = datetime.now(UTC).date()
        _from = _to - timedelta(days=30)
        date_from_use = req.date_from or _from.strftime("%Y-%m-%d")
        date_to_use = req.date_to or _to.strftime("%Y-%m-%d")
    else:
        date_from_use = req.date_from
        date_to_use = req.date_to

    imported_total = 0
    result_by_merchant: dict[str, int] = {}
    skipped_merchants: set[str] = set()

    _alias = {"lazadacps": "lazada", "tikivn": "tiki"}

    for m_req in sorted(merchants):
        m_fetch = _alias.get(m_req, m_req)

        # map merchant -> campaign_id ƒëang ch·∫°y
        campaign_id = None
        for cid, mm in active.items():
            mm_l = (mm or "").lower()
            if mm_l == m_req or mm_l == m_fetch:
                campaign_id = cid
                break
        if not campaign_id:
            for cid, mm in active.items():
                mm_l = (mm or "").lower()
                if mm_l.endswith(m_req) or f"_{m_req}" in mm_l or (m_req in mm_l):
                    campaign_id = cid
                    break
        if not campaign_id and m_fetch != m_req:
            for cid, mm in active.items():
                mm_l = (mm or "").lower()
                if mm_l.endswith(m_fetch) or f"_{m_fetch}" in mm_l or (m_fetch in mm_l):
                    campaign_id = cid
                    break

        if not campaign_id:
            # Kh√¥ng t√¨m th·∫•y campaign ƒëang ch·∫°y cho merchant n√†y
            skipped_merchants.add(m_req)
            continue

        page = 1
        imported = 0
        while page <= max(1, req.max_pages):
            items = await fetch_top_products(
                db,
                merchant=m_fetch,
                date_from=date_from_use,
                date_to=date_to_use,
                page=page,
                limit=req.limit_per_page
            )
            if not items:
                break

            for it in items:
                try:
                    title = it.get("name") or "S·∫£n ph·∫©m"
                    link = it.get("link") or it.get("url")
                    aff = it.get("aff_link")
                    img = it.get("image") or it.get("thumb")
                    price = it.get("price")
                    product_id = it.get("product_id") or it.get("id")

                    if not link and not aff:
                        logger.debug("[TOP] skip: no link/aff for %s", title)
                        continue
                    url_to_check = link or aff

                    alive = True if not req.check_urls else await _check_url_alive(str(url_to_check or ""))
                    if not alive:
                        logger.debug("[TOP] skip: dead url %s", url_to_check)
                        continue

                    base_key = str(product_id or url_to_check)
                    sid = hashlib.md5(base_key.encode("utf-8")).hexdigest()

                    extra = {
                        "source_type": "top_products",
                        "raw": it,
                    }
                    try:
                        _row = crud.get_campaign_by_cid(db, campaign_id) if campaign_id else None
                        _user = (_row.user_registration_status or "").upper() if _row else ""
                        if not _row or _user not in ("APPROVED", "SUCCESSFUL"):
                            continue
                    except Exception:
                        continue

                    payload = schemas.ProductOfferCreate(
                        source="accesstrade",
                        source_id=f"top:{m_req}:{sid}",
                        merchant=m_req,
                        title=title,
                        url=link or aff,
                        affiliate_url=aff,
                        image_url=img,
                        price=price,
                        currency="VND",
                        campaign_id=campaign_id,
                        source_type="top_products",
                        eligible_commission=bool(
                            _row and _row.status == "running" and (_row.user_registration_status or "").upper() in ("APPROVED", "SUCCESSFUL")
                        ),
                        affiliate_link_available=bool(aff),
                        product_id=str(product_id) if product_id is not None else None,
                        extra=json.dumps(extra, ensure_ascii=False),
                    )

                    try:
                        crud.upsert_offer_for_excel(db, payload)
                    except Exception:
                        crud.upsert_offer_by_source(db, payload)
                    imported += 1
                except Exception as e:
                    logger.debug("Skip top_product upsert: %s", e)

            page += 1
            sleep_ms = getattr(req, "throttle_ms", 0) or 0
            if sleep_ms:
                await asyncio.sleep(sleep_ms / 1000.0)

        imported_total += imported
        result_by_merchant[m_req] = imported

    resp = {"ok": True, "imported": imported_total, "by_merchant": result_by_merchant}
    if req.verbose:
        # N·∫øu kh√¥ng truy·ªÅn merchant: coi c√°c merchant active nh∆∞ng kh√¥ng approved l√† b·ªã b·ªè qua
        # N·∫øu c√≥ truy·ªÅn merchant c·ª• th·ªÉ: th√™m v√†o skipped n·∫øu merchant ƒë√≥ kh√¥ng thu·ªôc approved_running
        skipped = set(skipped_merchants)
        if not req.merchant:
            skipped.update(all_active_merchants - approved_running_merchants)
        else:
            m_norm = req.merchant.strip().lower()
            if m_norm not in approved_running_merchants:
                skipped.add(m_norm)
        resp["skipped_merchants"] = sorted(skipped)
    return resp

# =============================================
# Unified provider-agnostic ingest endpoints üåê
# =============================================

class ProviderReq(BaseModel):
    provider: str = "accesstrade"

class CampaignsSyncUnifiedReq(ProviderReq, CampaignsSyncReq):
    pass

class PromotionsUnifiedReq(ProviderReq, IngestV2PromotionsReq):
    pass

class TopProductsUnifiedReq(ProviderReq, IngestV2TopProductsReq):
    pass

class DatafeedsAllUnifiedReq(ProviderReq, IngestAllDatafeedsReq):
    pass

class IngestCommissionsReq(ProviderReq, BaseModel):
    """
    Ingest commission policies (hoa h·ªìng) cho campaign.
    - campaign_ids: danh s√°ch campaign_id c·∫ßn l·∫•y. N·∫øu kh√¥ng c√≥, ch·ªçn theo merchant ho·∫∑c t·∫•t c·∫£ campaign ƒëang ch·∫°y ƒë√£ APPROVED.
    - merchant: l·ªçc theo merchant (n·∫øu kh√¥ng truy·ªÅn campaign_ids).
    - max_campaigns: gi·ªõi h·∫°n s·ªë campaign t·ªëi ƒëa s·∫Ω qu√©t (ƒë·ªÉ an to√†n). M·∫∑c ƒë·ªãnh 100.
    - verbose: ghi log chi ti·∫øt v√†o JSONL.
    """
    campaign_ids: list[str] | None = None
    merchant: str | None = None
    max_campaigns: int = 100
    verbose: bool = False

    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "summary": "Theo campaign c·ª• th·ªÉ",
                    "value": {"provider": "accesstrade", "campaign_ids": ["CAMP3"]}
                },
                {
                    "summary": "Theo merchant",
                    "value": {"provider": "accesstrade", "merchant": "tikivn"}
                },
                {
                    "summary": "T·∫•t c·∫£ campaign APPROVED ƒëang ch·∫°y",
                    "value": {"provider": "accesstrade"}
                }
            ]
        }
    }

@app.post(
    "/ingest/campaigns/sync",
    tags=["Campaigns üì¢"],
    summary="ƒê·ªìng b·ªô campaigns (provider-agnostic)",
    description=(
        "ƒê·ªìng b·ªô danh s√°ch campaigns.\n\n"
        "- B·∫Øt bu·ªôc: (kh√¥ng c√≥).\n"
        "- Tu·ª≥ ch·ªçn: provider (m·∫∑c ƒë·ªãnh \"accesstrade\"), statuses (m·∫∑c ƒë·ªãnh [\"running\",\"paused\"]), only_my (m·∫∑c ƒë·ªãnh true),\n"
        "  enrich_user_status (m·∫∑c ƒë·ªãnh true), limit_per_page, page_concurrency, window_pages, throttle_ms (m·∫∑c ƒë·ªãnh 50ms), merchant.\n\n"
        "V√≠ d·ª• body JSON:\n"
        "{\n  \"provider\": \"accesstrade\",\n  \"statuses\": [\"running\", \"paused\"],\n  \"only_my\": true,\n  \"throttle_ms\": 50\n}"
    )
)
async def ingest_campaigns_sync_unified(
    req: CampaignsSyncUnifiedReq = Body(
        ...,
        example={
            "provider": "accesstrade",
            "statuses": ["running", "paused"],
            "only_my": True,
            "enrich_user_status": True,
            "limit_per_page": 50,
            "page_concurrency": 6,
            "window_pages": 10,
            "throttle_ms": 50
        }
    ),
    db: Session = Depends(get_db)
):
    prov = (req.provider or "accesstrade").lower()
    if prov == "accesstrade":
        inner = CampaignsSyncReq(**req.model_dump(exclude={"provider"}))
        return await ingest_v2_campaigns_sync(inner, db)
    raise HTTPException(status_code=400, detail=f"Provider '{prov}' hi·ªán ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£")

@app.post(
    "/ingest/promotions",
    tags=["Ingest üåê"],
    summary="Ingest promotions (provider-agnostic)",
    description=(
        "Nh·∫≠p khuy·∫øn m√£i theo merchant.\n\n"
        "- B·∫Øt bu·ªôc: (kh√¥ng c√≥).\n"
        "- Tu·ª≥ ch·ªçn: provider (m·∫∑c ƒë·ªãnh \"accesstrade\"), merchant (l·ªçc theo merchant), verbose (m·∫∑c ƒë·ªãnh false), throttle_ms (m·∫∑c ƒë·ªãnh 50ms).\n\n"
        "V√≠ d·ª• body JSON:\n"
        "{\n  \"provider\": \"accesstrade\",\n  \"merchant\": \"tikivn\",\n  \"verbose\": false,\n  \"throttle_ms\": 50\n}"
    )
)
async def ingest_promotions_unified(
    req: PromotionsUnifiedReq = Body(
        ...,
        examples={
            "default": {
                "summary": "V√≠ d·ª• merchant",
                "value": {"provider": "accesstrade", "merchant": "tikivn", "verbose": False, "throttle_ms": 50}
            }
        }
    ),
    db: Session = Depends(get_db)
):
    prov = (req.provider or "accesstrade").lower()
    if prov == "accesstrade":
        inner = IngestV2PromotionsReq(**req.model_dump(exclude={"provider"}))
        return await ingest_v2_promotions(inner, db)
    raise HTTPException(status_code=400, detail=f"Provider '{prov}' hi·ªán ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£")

@app.post(
    "/ingest/top-products",
    tags=["Ingest üåê"],
    summary="Ingest top products (provider-agnostic)",
    description=(
        "Nh·∫≠p s·∫£n ph·∫©m b√°n ch·∫°y theo merchant.\n\n"
        "- B·∫Øt bu·ªôc: (kh√¥ng c√≥). N·∫øu kh√¥ng truy·ªÅn merchant, h·ªá th·ªëng s·∫Ω ch·∫°y cho T·∫§T C·∫¢ merchant c√≥ campaign ƒëang ch·∫°y v√† ƒë√£ duy·ªát (APPROVED/SUCCESSFUL).\n"
        "- Tu·ª≥ ch·ªçn: provider (m·∫∑c ƒë·ªãnh \"accesstrade\"), date_from/date_to (YYYY-MM-DD), limit_per_page (<=100),\n"
        "  max_pages, check_urls (m·∫∑c ƒë·ªãnh false), verbose (m·∫∑c ƒë·ªãnh false), throttle_ms (m·∫∑c ƒë·ªãnh 50ms).\n\n"
        "V√≠ d·ª• body JSON:\n"
        "{\n  \"provider\": \"accesstrade\",\n  \"merchant\": \"tikivn\",\n  \"limit_per_page\": 50,\n  \"max_pages\": 1,\n  \"check_urls\": false,\n  \"verbose\": false,\n  \"throttle_ms\": 50\n}"
    )
)
async def ingest_top_products_unified(
    req: TopProductsUnifiedReq = Body(
        ...,
        examples={
            "default": {
                "summary": "Top products 1 trang",
                "value": {"provider": "accesstrade", "merchant": "tikivn", "limit_per_page": 50, "max_pages": 1, "check_urls": False, "verbose": False, "throttle_ms": 50}
            }
        }
    ),
    db: Session = Depends(get_db)
):
    prov = (req.provider or "accesstrade").lower()
    if prov == "accesstrade":
        inner = IngestV2TopProductsReq(**req.model_dump(exclude={"provider"}))
        return await ingest_v2_top_products(inner, db)
    raise HTTPException(status_code=400, detail=f"Provider '{prov}' hi·ªán ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£")

@app.post(
    "/ingest/datafeeds/all",
    tags=["Ingest üåê"],
    summary="Ingest datafeeds to√†n b·ªô (provider-agnostic)",
    description=(
        "G·ªçi datafeeds cho t·∫•t c·∫£ merchant ƒë√£ duy·ªát.\n\n"
        "- B·∫Øt bu·ªôc: (kh√¥ng c√≥).\n"
        "- Tu·ª≥ ch·ªçn: provider (m·∫∑c ƒë·ªãnh \"accesstrade\"), params (truy·ªÅn xu·ªëng API AT), limit_per_page (m·∫∑c ƒë·ªãnh 100),\n"
        "  max_pages (m·∫∑c ƒë·ªãnh 2000), check_urls (m·∫∑c ƒë·ªãnh false), verbose (m·∫∑c ƒë·ªãnh false), throttle_ms (m·∫∑c ƒë·ªãnh 50ms).\n\n"
        "V√≠ d·ª• body JSON:\n"
        "{\n  \"provider\": \"accesstrade\",\n  \"params\": {\"merchant\": \"tikivn\"},\n  \"max_pages\": 1,\n  \"check_urls\": false,\n  \"verbose\": false,\n  \"throttle_ms\": 50\n}"
    )
)
async def ingest_datafeeds_all_unified(
    req: DatafeedsAllUnifiedReq = Body(
        ...,
        examples={
            "default": {
                "summary": "Qu√©t to√†n b·ªô ƒë√£ duy·ªát",
                "value": {"provider": "accesstrade", "params": {"merchant": "tikivn"}, "max_pages": 1, "check_urls": False, "verbose": False, "throttle_ms": 50}
            }
        }
    ),
    db: Session = Depends(get_db)
):
    prov = (req.provider or "accesstrade").lower()
    if prov == "accesstrade":
        inner = IngestAllDatafeedsReq(**req.model_dump(exclude={"provider"}))
        return await ingest_accesstrade_datafeeds_all(inner, db)
    raise HTTPException(status_code=400, detail=f"Provider '{prov}' hi·ªán ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£")

"""Legacy provider-specific routes have been removed. Use unified endpoints."""

@app.post(
    "/ingest/commissions",
    tags=["Ingest üåê"],
    summary="Ingest commission policies (hoa h·ªìng)",
    description=(
        "G·ªçi datafeeds commissions cho danh s√°ch campaign ƒë√£ ch·ªçn.\n\n"
        "- B·∫Øt bu·ªôc: (kh√¥ng c√≥).\n"
        "- Tu·ª≥ ch·ªçn: provider (m·∫∑c ƒë·ªãnh 'accesstrade'), campaign_ids (danh s√°ch), merchant (l·ªçc theo merchant n·∫øu kh√¥ng truy·ªÅn campaign_ids),\n"
        "  max_campaigns (m·∫∑c ƒë·ªãnh 100), verbose (m·∫∑c ƒë·ªãnh false).\n\n"
        "V√≠ d·ª• body JSON: { \"provider\": \"accesstrade\", \"merchant\": \"tikivn\", \"max_campaigns\": 50 }"
    )
)
async def ingest_commissions_unified(
    req: IngestCommissionsReq = Body(
        ...,
        examples={
            "by_campaign": {
                "summary": "Theo campaign c·ª• th·ªÉ",
                "value": {"provider": "accesstrade", "campaign_ids": ["CAMP3"]},
            },
            "by_merchant": {
                "summary": "Theo merchant",
                "value": {"provider": "accesstrade", "merchant": "tikivn"},
            },
            "all_running": {
                "summary": "T·∫•t c·∫£ campaign APPROVED ƒëang ch·∫°y",
                "value": {"provider": "accesstrade"},
            },
        },
    ),
    db: Session = Depends(get_db),
):
    from accesstrade_service import fetch_active_campaigns, fetch_commission_policies
    prov = (req.provider or "accesstrade").lower()
    if prov != "accesstrade":
        raise HTTPException(status_code=400, detail=f"Provider '{prov}' hi·ªán ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£")

    # X√°c ƒë·ªãnh danh s√°ch campaign_id c·∫ßn l·∫•y
    campaign_ids: list[str] = []
    if req.campaign_ids:
        campaign_ids = [str(c).strip() for c in req.campaign_ids if str(c).strip()]
    else:
        # t·∫•t c·∫£ campaign ƒëang ch·∫°y ƒë√£ APPROVED (ho·∫∑c l·ªçc theo merchant)
        active = await fetch_active_campaigns(db)  # {cid: merchant}
        for cid, m in active.items():
            row = crud.get_campaign_by_cid(db, cid)
            if not row:
                continue
            us = (row.user_registration_status or "").upper()
            if us == "SUCCESSFUL":
                us = "APPROVED"
            if us != "APPROVED":
                continue
            if req.merchant and (m or "").lower() != req.merchant.strip().lower():
                continue
            campaign_ids.append(cid)
        if req.max_campaigns and len(campaign_ids) > req.max_campaigns:
            campaign_ids = campaign_ids[: max(1, int(req.max_campaigns))]

    imported = 0
    for cid in campaign_ids:
        try:
            items = await fetch_commission_policies(db, cid)
            for rec in (items or []):
                crud.upsert_commission_policy(db, schemas.CommissionPolicyCreate(
                    campaign_id=str(cid),
                    reward_type=rec.get("reward_type") or rec.get("type"),
                    sales_ratio=rec.get("sales_ratio") or rec.get("ratio"),
                    sales_price=rec.get("sales_price"),
                    target_month=rec.get("target_month"),
                ))
                imported += 1
        except Exception as e:
            if req.verbose:
                logger.debug("Ingest commission failed for %s: %s", cid, e)
            continue

    return {"ok": True, "campaigns": len(campaign_ids), "policies_imported": imported}

# ================================
# NEW: One-shot ingest ALL sources for APPROVED merchants
# ================================
## Removed deprecated endpoint: POST /ingest/v2/offers/all-approved (per requirements)

@app.put(
    "/offers/{offer_id}",
    tags=["Offers üõí"],
    summary="C·∫≠p nh·∫≠t th√¥ng tin s·∫£n ph·∫©m",
    description="S·ª≠a th√¥ng tin 1 s·∫£n ph·∫©m trong DB theo ID.",
    response_model=schemas.ProductOfferOut
)
def update_offer_api(
    offer_id: int,
    data: schemas.ProductOfferUpdate = Body(
        ...,
        examples={
            "patch-minimal": {
                "summary": "C·∫≠p nh·∫≠t m·ªôt ph·∫ßn",
                "value": {"title": "S·∫£n ph·∫©m m·ªõi", "price": 199000, "currency": "VND"}
            }
        }
    ),
    db: Session = Depends(get_db)
):
    obj = crud.update_offer(db, offer_id, data)
    if not obj:
        raise HTTPException(status_code=404, detail="Offer not found")
    return obj

@app.delete(
    "/offers/{offer_id}",
    tags=["Offers üõí"],
    summary="Xo√° 1 b·∫£n ghi theo ID",
    description=(
        "Xo√° m·ªôt b·∫£n ghi duy nh·∫•t theo ID.\n\n"
        "- category: offers (m·∫∑c ƒë·ªãnh) | top-products | promotions | commissions.\n"
        "- L∆∞u √Ω: bulk delete theo campaign_id h√£y d√πng DELETE /offers (kh√¥ng k√®m {offer_id})."
    )
)
def delete_offer_api(
    offer_id: int,
    category: Literal["offers", "top-products", "promotions", "commissions"] = Query(
        "offers", description="offers | top-products | promotions | commissions"
    ),
    db: Session = Depends(get_db)
):
    cat = (category or "offers").strip().lower()
    if cat in ("offers", "top-products"):
        obj = crud.delete_offer(db, offer_id)
        if not obj:
            raise HTTPException(status_code=404, detail="Offer not found")
        return {"ok": True, "deleted_id": offer_id, "category": "top-products" if cat == "top-products" else "offers"}
    elif cat == "promotions":
        obj = crud.delete_promotion(db, offer_id)
        if not obj:
            raise HTTPException(status_code=404, detail="Promotion not found")
        return {"ok": True, "deleted_id": offer_id, "category": "promotions"}
    elif cat == "commissions":
        obj = crud.delete_commission_policy(db, offer_id)
        if not obj:
            raise HTTPException(status_code=404, detail="Commission policy not found")
        return {"ok": True, "deleted_id": offer_id, "category": "commissions"}
    else:
        raise HTTPException(status_code=400, detail="category kh√¥ng h·ª£p l·ªá")

# --- API cleanup: x√≥a s·∫£n ph·∫©m c√≥ link ch·∫øt ---
@app.delete(
    "/offers/cleanup/dead",
    tags=["Offers üõí"],
    summary="D·ªçn link ch·∫øt (cleanup)",
    description=(
        "B·∫Øt bu·ªôc: (kh√¥ng c√≥).\n"
        "T√°c v·ª• qu√©t to√†n b·ªô s·∫£n ph·∫©m trong DB, ki·ªÉm tra link s·ªëng/ch·∫øt v√† **xo√° t·∫•t c·∫£** link ch·∫øt."
    )
)
async def cleanup_dead_offers(db: Session = Depends(get_db)):
    offers = crud.list_offers(db, limit=1000)
    removed = 0
    alive_count = 0
    total = len(offers)
    for idx, o in enumerate(offers, start=1):
        if idx % 50 == 0 or idx == total:
            logger.info("Cleanup progress: %d/%d", idx, total)
        alive = await _check_url_alive(o.url)  # ch·ªâ d√πng link g·ªëc ƒë·ªÉ tr√°nh click ·∫£o
        if not alive:
            logger.info("Removing dead product via API: id=%s, title='%s'", o.id, o.title)
            db.delete(o)
            removed += 1
        else:
            alive_count += 1
    db.commit()
    logger.info("API cleanup done: %s dead / %s alive / %s scanned", removed, alive_count, total)
    return {"dead": removed, "alive": alive_count, "scanned": total}

@app.post(
    "/scheduler/linkcheck/rotate",
    tags=["Settings ‚öôÔ∏è"],
    summary="Ki·ªÉm tra link s·ªëng theo l√°t c·∫Øt v√† xoay v√≤ng",
    description=(
        "C√°ch d√πng: g·ªçi 1 l·∫ßn s·∫Ω ki·ªÉm tra m·ªôt l√°t c·∫Øt theo ƒëi·ªÅu ki·ªán id % M = cursor.\n"
        "- B·∫Øt bu·ªôc: (kh√¥ng c√≥) ‚Äî endpoint kh√¥ng y√™u c·∫ßu body.\n"
        "- Tu·ª≥ ch·ªçn: query delete_dead=true ƒë·ªÉ xo√° link ch·∫øt trong l√°t hi·ªán t·∫°i.\n"
        "- M: s·ªë l√°t c·∫Øt (m·∫∑c ƒë·ªãnh 24 do h·ªá th·ªëng ƒë·∫∑t s·∫µn ‚Äî c√≥ th·ªÉ ƒë·ªïi qua /settings/linkcheck/config).\n"
        "- linkcheck_limit: gi·ªõi h·∫°n s·ªë b·∫£n ghi m·ªói l·∫ßn (ƒë·∫∑t qua /settings/linkcheck/config).\n"
        "Sau m·ªói l·∫ßn ch·∫°y, cursor t·ª± tƒÉng (mod M)."
    )
)
async def scheduler_linkcheck_rotate(
    delete_dead: bool = False,
    db: Session = Depends(get_db),
):
    from accesstrade_service import _check_url_alive
    flags = crud.get_policy_flags(db)
    mod = int(flags.get("linkcheck_mod", 10) or 10)
    if mod < 1:
        mod = 10
    cursor = int(flags.get("linkcheck_cursor", 0)) % mod
    limit = flags.get("linkcheck_limit")

    from models import ProductOffer
    # l·ªçc theo modulo tu·ª≥ bi·∫øn
    slice_q = db.query(ProductOffer).filter(text("id % :mod = :cur")).params(mod=mod, cur=cursor)
    if isinstance(limit, int) and limit > 0:
        slice_q = slice_q.limit(limit)
    offers = slice_q.all()

    total = len(offers)
    removed = 0
    alive_count = 0
    for idx, o in enumerate(offers, start=1):
        if idx % 50 == 0 or idx == total:
            logger.info("[ROTATE] progress: %d/%d (cursor=%d)", idx, total, cursor)
        alive = await _check_url_alive(o.url)
        if alive:
            alive_count += 1
        else:
            if delete_dead:
                db.delete(o)
                removed += 1
    db.commit()

    next_cursor = (cursor + 1) % mod
    crud.set_policy_flag(db, "linkcheck_cursor", next_cursor)

    return {
        "cursor_used": cursor,
        "next_cursor": next_cursor,
        "mod": mod,
        "limit": limit,
        "scanned": total,
        "alive": alive_count,
        "deleted": removed,
    }

class LinkcheckConfigBody(BaseModel):
    linkcheck_mod: int | None = None
    linkcheck_limit: int | None = None

    model_config = {
        "json_schema_extra": {
            "examples": [
                {"linkcheck_mod": 24, "linkcheck_limit": 1000},
                {"linkcheck_mod": 20},
                {"linkcheck_limit": 500},
            ],
            "description": (
                "B·∫Øt bu·ªôc: kh√¥ng c√≥ tr∆∞·ªùng n√†o b·∫Øt bu·ªôc.\n"
                "- linkcheck_mod (tu·ª≥ ch·ªçn): s·ªë l√°t c·∫Øt (v√≠ d·ª• 24 ‚Üí 1/24 m·ªói l·∫ßn).\n"
                "- linkcheck_limit (tu·ª≥ ch·ªçn): gi·ªõi h·∫°n s·ªë record m·ªói l·∫ßn."
            ),
        }
    }

@app.post(
    "/settings/linkcheck/config",
    tags=["Settings ‚öôÔ∏è"],
    summary="C·∫•u h√¨nh tham s·ªë link-check (mod/limit)",
    description=(
        "Thi·∫øt l·∫≠p tham s·ªë xoay v√≤ng ki·ªÉm tra link.\n"
        "- B·∫Øt bu·ªôc: (kh√¥ng c√≥).\n"
        "- Tu·ª≥ ch·ªçn trong body JSON: linkcheck_mod, linkcheck_limit.\n"
        "Ngo√†i ra c√≥ th·ªÉ g·ª≠i qua query string (t∆∞∆°ng th√≠ch ng∆∞·ª£c). Gi√° tr·ªã ƒë∆∞·ª£c l∆∞u trong API Config name=ingest_policy.\n\n"
        "V√≠ d·ª• body JSON:\n{\n  \"linkcheck_mod\": 24,\n  \"linkcheck_limit\": 1000\n}"
    )
)
def settings_linkcheck_config(
    body: LinkcheckConfigBody | None = Body(
        None,
        examples={
            "default": {"summary": "Thi·∫øt l·∫≠p m·∫∑c ƒë·ªãnh 24/1000", "value": {"linkcheck_mod": 24, "linkcheck_limit": 1000}},
            "gioi_han_nho": {"summary": "Gi·ªõi h·∫°n 500 m·ªói l∆∞·ª£t", "value": {"linkcheck_limit": 500}}
        }
    ),
    linkcheck_mod: int | None = None,
    linkcheck_limit: int | None = None,
    db: Session = Depends(get_db),
):
    # ∆Øu ti√™n body; n·∫øu kh√¥ng c√≥, l·∫•y t·ª´ query ƒë·ªÉ t∆∞∆°ng th√≠ch ng∆∞·ª£c
    mod_val = body.linkcheck_mod if body else linkcheck_mod
    limit_val = body.linkcheck_limit if body else linkcheck_limit
    if mod_val is not None:
        crud.set_policy_flag(db, "linkcheck_mod", max(1, int(mod_val)))
    if limit_val is not None:
        crud.set_policy_flag(db, "linkcheck_limit", max(1, int(limit_val)))
    flags = crud.get_policy_flags(db)
    return {"ok": True, "flags": flags}

# --- API test nhanh: check 1 s·∫£n ph·∫©m trong DB ---
from datetime import datetime, UTC

@app.get(
    "/offers/check/{offer_id}",
    tags=["Offers üõí"],
    summary="Ki·ªÉm tra 1 s·∫£n ph·∫©m (alive/dead)",
    description=(
        "B·∫Øt bu·ªôc: offer_id trong path.\n"
        "Tu·ª≥ ch·ªçn: (kh√¥ng c√≥).\n"
        "Ki·ªÉm tra nhanh tr·∫°ng th√°i link c·ªßa m·ªôt s·∫£n ph·∫©m trong DB theo ID."
    )
)
async def check_offer_status(offer_id: int, db: Session = Depends(get_db)):
    offer = db.query(models.ProductOffer).filter(models.ProductOffer.id == offer_id).first()
    if not offer:
        raise HTTPException(status_code=404, detail="Offer not found")
    alive = await _check_url_alive(offer.url)  # ch·ªâ check link g·ªëc ƒë·ªÉ tr√°nh click ·∫£o
    return {
        "id": offer.id,
        "title": offer.title,
        "url": offer.url,
        "affiliate_url": offer.affiliate_url,
        "alive": alive,
    "checked_at": datetime.now(UTC).isoformat()
    }

"""Legacy v2 routes have been removed. Use unified endpoints."""

@app.delete(
    "/offers",
    tags=["Offers üõí"],
    summary="Xo√° d·ªØ li·ªáu theo nh√≥m (bulk)",
    description=(
        "Xo√° nhi·ªÅu b·∫£n ghi theo nh√≥m v√† (tu·ª≥ ch·ªçn) campaign_id.\n\n"
        "- category: offers (m·∫∑c ƒë·ªãnh) | top-products | promotions | commissions.\n"
        "- V·ªõi category=offers: s·∫Ω xo√° t·∫•t c·∫£ ProductOffer TR·ª™ nh√≥m top-products (bao g·ªìm c·∫£ c√°c offer c√≥ source_type='promotions').\n"
        "- D√πng campaign_id ƒë·ªÉ gi·ªõi h·∫°n theo chi·∫øn d·ªãch."
    )
)
def delete_all_offers_api(
    category: Literal["offers", "top-products", "promotions", "commissions"] = Query(
        "offers", description="offers | top-products | promotions | commissions"
    ),
    campaign_id: str | None = Query(None, description="Xo√° theo campaign_id (tu·ª≥ ch·ªçn)"),
    db: Session = Depends(get_db)
):
    cat = (category or "offers").strip().lower()
    deleted = 0
    if cat in ("offers", "top-products"):
        if cat in ("top-products",):
            deleted = crud.delete_offers_by_filter(db, source_type="top_products", campaign_id=campaign_id)
            effective_cat = "top-products"
        else:
            # Xo√° t·∫•t c·∫£ offer nh∆∞ng lo·∫°i tr·ª´ nh√≥m top-products; gi·ªØ l·∫°i promotions-source ƒë·ªÉ xo√° ƒë∆∞·ª£c theo campaign
            if campaign_id:
                deleted = crud.delete_offers_by_filter(db, exclude_source_types=["top_products"], campaign_id=campaign_id)
            else:
                deleted = crud.delete_offers_by_filter(db, exclude_source_types=["top_products"])
            effective_cat = "offers"
    elif cat == "promotions":
        deleted = crud.delete_promotions_by_campaign(db, campaign_id) if campaign_id else crud.delete_all_promotions(db)
        effective_cat = "promotions"
    elif cat == "commissions":
        deleted = crud.delete_commission_policies_by_campaign(db, campaign_id) if campaign_id else crud.delete_all_commission_policies(db)
        effective_cat = "commissions"
    else:
        raise HTTPException(status_code=400, detail="category kh√¥ng h·ª£p l·ªá")
    return {"ok": True, "deleted": deleted, "category": effective_cat}

# ---- Catalog listing for other categories ----
@app.get(
    "/catalog/promotions",
    tags=["Offers üõí"],
    response_model=list[schemas.PromotionOut],
    summary="Li·ªát k√™ promotions",
    description="Danh s√°ch promotions trong DB (ph√¢n trang)."
)
def list_catalog_promotions(
    skip: int = 0,
    limit: int = 50,
    campaign_id: str | None = Query(None, description="L·ªçc theo campaign_id (tu·ª≥ ch·ªçn)"),
    db: Session = Depends(get_db)
):
    return crud.list_promotions(db, skip=skip, limit=limit, campaign_id=campaign_id)

@app.get(
    "/catalog/commissions",
    tags=["Offers üõí"],
    response_model=list[schemas.CommissionPolicyOut],
    summary="Li·ªát k√™ commission policies",
    description="Danh s√°ch ch√≠nh s√°ch hoa h·ªìng theo chi·∫øn d·ªãch (ph√¢n trang)."
)
def list_catalog_commissions(
    skip: int = 0,
    limit: int = 50,
    campaign_id: str | None = Query(None, description="L·ªçc theo campaign_id (tu·ª≥ ch·ªçn)"),
    db: Session = Depends(get_db)
):
    return crud.list_commission_policies(db, skip=skip, limit=limit, campaign_id=campaign_id)

# --- Import s·∫£n ph·∫©m t·ª´ Excel ---
import pandas as pd
@app.post(
    "/offers/import-excel",
    tags=["Offers üõí"],
    summary="Import s·∫£n ph·∫©m t·ª´ Excel",
    description="Upload file Excel (.xlsx) ch·ª©a danh s√°ch s·∫£n ph·∫©m ƒë·ªÉ import v√†o DB."
)
async def import_offers_excel(file: UploadFile = File(...), db: Session = Depends(get_db)):
    if not file.filename.endswith(".xlsx"):
        raise HTTPException(status_code=400, detail="Ch·ªâ h·ªó tr·ª£ file .xlsx")

    # ƒê·ªçc to√†n b·ªô n·ªôi dung file m·ªôt l·∫ßn ƒë·ªÉ parse nhi·ªÅu sheet an to√†n
    try:
        content = file.file.read()
        xls = pd.ExcelFile(io.BytesIO(content))
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"L·ªói ƒë·ªçc file Excel: {e}")

    # B·∫ÆT BU·ªòC: File Excel ph·∫£i c√≥ 2 h√†ng ti√™u ƒë·ªÅ
    # - H√†ng 1: ti√™u ƒë·ªÅ k·ªπ thu·∫≠t (t√™n c·ªôt g·ªëc) ‚Üí ƒë∆∞·ª£c pandas d√πng l√†m df.columns
    # - H√†ng 2: ti√™u ƒë·ªÅ ti·∫øng Vi·ªát (human-readable) ‚Üí l√† d√≤ng ƒë·∫ßu ti√™n c·ªßa df v√† s·∫Ω b·ªã b·ªè qua khi import
    # N·∫øu kh√¥ng c√≥ h√†ng 2 n√†y, tr·∫£ l·ªói 400 ƒë·ªÉ ƒë·∫£m b·∫£o th·ªëng nh·∫•t ƒë·ªãnh d·∫°ng trong d·ª± √°n
    # Map d·ªãch d√πng ƒë·ªÉ ki·ªÉm tra (h√†ng 2). ƒê√°nh d·∫•u (*) cho c·ªôt b·∫Øt bu·ªôc.
    trans_products = {
        "id": "M√£ ID", "source": "Ngu·ªìn", "source_id": "M√£ ngu·ªìn (*)", "source_type": "Lo·∫°i ngu·ªìn",
        "merchant": "Nh√† b√°n (*)",
        "title": "T√™n s·∫£n ph·∫©m (*)", "url": "Link g·ªëc", "affiliate_url": "Link ti·∫øp th·ªã",
        "image_url": "·∫¢nh s·∫£n ph·∫©m", "price": "Gi√°", "currency": "Ti·ªÅn t·ªá",
        "campaign_id": "Chi·∫øn d·ªãch", "product_id": "M√£ s·∫£n ph·∫©m ngu·ªìn", "affiliate_link_available": "C√≥ affiliate?",
        "domain": "T√™n mi·ªÅn", "sku": "SKU", "discount": "Gi√° KM", "discount_amount": "M·ª©c gi·∫£m",
        "discount_rate": "T·ª∑ l·ªá gi·∫£m (%)", "status_discount": "C√≥ khuy·∫øn m√£i?",
        "updated_at": "Ng√†y c·∫≠p nh·∫≠t", "desc": "M√¥ t·∫£ chi ti·∫øt",
        "cate": "Danh m·ª•c", "shop_name": "T√™n c·ª≠a h√†ng", "update_time_raw": "Th·ªùi gian c·∫≠p nh·∫≠t t·ª´ ngu·ªìn",
    }

    # Helper: ki·ªÉm tra 2 h√†ng header v√† b·ªè h√†ng TV cho m·ªôt DataFrame
    def _validate_and_strip_header(df: pd.DataFrame, trans_map: dict, sheet_name: str):
        if df.empty:
            raise HTTPException(status_code=400, detail=f"Sheet {sheet_name} tr·ªëng ho·∫∑c kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng (thi·∫øu d·ªØ li·ªáu)")
        first = df.iloc[0]
        matches = 0
        total_keys = 0
        for k, v in trans_map.items():
            if k in df.columns:
                total_keys += 1
                try:
                    def _norm_header(s: str) -> str:
                        s = str(s or "").strip()
                        return s.replace("(*)", "").replace("( * )", "").replace("(*) ", "").strip()
                    if _norm_header(str(first[k])) == _norm_header(str(v)):
                        matches += 1
                except Exception:
                    pass
        threshold = max(3, total_keys // 3)
        if not (total_keys and matches >= threshold):
            raise HTTPException(
                status_code=400,
                detail=(
                    f"Sheet {sheet_name}: thi·∫øu h√†ng ti√™u ƒë·ªÅ ti·∫øng Vi·ªát (h√†ng 2). "
                    "M·ªçi sheet ph·∫£i c√≥ 2 h√†ng ti√™u ƒë·ªÅ: h√†ng 1 l√† t√™n c·ªôt k·ªπ thu·∫≠t, h√†ng 2 l√† t√™n c·ªôt ti·∫øng Vi·ªát."
                ),
            )
        return df.iloc[1:].reset_index(drop=True)

    # Helper: sinh m√£ theo format ex+prefix+digits t·ªïng ƒë·ªô d√†i 14; ƒë·∫£m b·∫£o kh√¥ng tr√πng cho Products
    import secrets, string
    def _gen_code(prefix: str, exists_check=None, max_tries: int = 20) -> str:
        base = "ex" + prefix
        digits_len = max(1, 14 - len(base))
        for _ in range(max_tries):
            n = ''.join(secrets.choice(string.digits) for _ in range(digits_len))
            code = base + n
            if exists_check is None:
                return code
            if not exists_check(code):
                return code
        # fallback: v·∫´n tr·∫£ v·ªÅ code cu·ªëi c√πng n·∫øu qu√° s·ªë l·∫ßn th·ª≠
        return code
    # L·∫•y sheet Products n·∫øu c√≥; n·∫øu kh√¥ng c√≥, fallback sheet ƒë·∫ßu ti√™n ƒë·ªÉ t∆∞∆°ng th√≠ch
    if "Products" in xls.sheet_names:
        df_products = xls.parse("Products")
    else:
        df_products = xls.parse(0)

    # X√°c th·ª±c header cho Products
    df = _validate_and_strip_header(df_products, trans_products, "Products")

    # Ch·ªâ import Excel m·ªõi √°p d·ª•ng policy; m·∫∑c ƒë·ªãnh False n·∫øu ch∆∞a set
    flags = crud.get_policy_flags(db)
    only_with_commission = bool(flags.get("only_with_commission"))
    check_urls_excel = bool(flags.get("check_urls"))
    from accesstrade_service import _check_url_alive

    imported = 0
    skipped_required = 0
    required_errors: list[dict] = []
    
    def _opt_str(v):
        try:
            import pandas as _pd
            if v is None or (isinstance(v, float) and _pd.isna(v)) or (hasattr(_pd, "isna") and _pd.isna(v)):
                return None
        except Exception:
            if v is None:
                return None
        s = str(v)
        s = s.strip()
        return s if s != "" else None
    for _, row in df.iterrows():
        # Map columns expected in Products sheet coming from API datafeeds
        # Coerce and sanitize typical Excel NaN/empty values
        _price_val = row.get("price")
        try:
            if _price_val in (None, "") or (hasattr(pd, "isna") and pd.isna(_price_val)):
                _price_val = None
            else:
                _price_val = float(_price_val)
        except Exception:
            _price_val = None

        base = {
            "source": "excel",
            "source_type": "excel",
            "source_id": _opt_str(row.get("source_id") or row.get("product_id") or row.get("id") or "") or "",
            "merchant": (_opt_str(row.get("merchant") or row.get("campaign")) or "").lower(),
            "title": _opt_str(row.get("title") or row.get("name") or "") or "",
            "url": _opt_str(row.get("url") or row.get("landing_url") or "") or "",
            "affiliate_url": _opt_str(row.get("affiliate_url") or row.get("aff_link")),
            "image_url": _opt_str(row.get("image_url") or row.get("image") or row.get("thumbnail")),
            "price": _price_val,
            "currency": _opt_str(row.get("currency")) or "VND",
        }

        # REQUIRED validation: merchant, title, price, and at least one of url/affiliate_url
        missing = []
        if not base["merchant"]:
            missing.append("merchant")
        if not base["title"]:
            missing.append("title")
        if base.get("price") in (None,):
            missing.append("price")
        if not (base["url"] or base["affiliate_url"]):
            missing.append("url|affiliate_url")
        if missing:
            skipped_required += 1
            required_errors.append({"row": int(_)+2, "missing": missing})
            continue

        # Auto-generate source_id n·∫øu thi·∫øu: theo format ex + 'p' + s·ªë ng·∫´u nhi√™n (ƒë·ªô d√†i t·ªïng 14)
        if not base["source_id"]:
            def _exists_in_db(sid: str) -> bool:
                from sqlalchemy import select
                from models import ProductOffer
                stmt = select(ProductOffer.id).where(ProductOffer.source == "excel", ProductOffer.source_id == sid)
                return db.execute(stmt).first() is not None
            base["source_id"] = _gen_code("p", exists_check=_exists_in_db)

        # Ghi campaign_id n·∫øu c√≥ trong file Excel
        campaign_id = row.get("campaign_id")
        if pd.notna(campaign_id):
            base["campaign_id"] = str(campaign_id).strip()

        # Gom promotion (if Products sheet contains promotion fields)
        promotion = {
            "name": row.get("promotion_name") or row.get("name"),
            "content": row.get("promotion_content") or row.get("content") or row.get("description"),
            "start_time": row.get("promotion_start_time") or row.get("start_time"),
            "end_time": row.get("promotion_end_time") or row.get("end_time"),
            "coupon": row.get("promotion_coupon") or row.get("coupon"),
            "link": row.get("promotion_link") or row.get("link"),
        }
        promotion = {k: v for k, v in promotion.items() if pd.notna(v)}

        # Gom commission (n·∫øu Products sheet c√≥ c√°c c·ªôt n√†y)
        commission = {
            "sales_ratio": row.get("sales_ratio") or row.get("commission_sales_ratio"),
            "sales_price": row.get("sales_price") or row.get("commission_sales_price"),
            "reward_type": row.get("reward_type") or row.get("commission_reward_type"),
            "target_month": row.get("target_month") or row.get("commission_target_month"),
        }
        commission = {k: v for k, v in commission.items() if pd.notna(v)}

        # C√°c c·ªôt m·ªü r·ªông trong ·∫£nh: domain, sku, discount, discount_amount, discount_rate, status_discount, updated_at, desc, cate, shop_name, update_time_raw
        extra_fields = {
            "domain": row.get("domain"),
            "sku": row.get("sku"),
            "discount": row.get("discount"),
            "discount_amount": row.get("discount_amount"),
            "discount_rate": row.get("discount_rate"),
            "status_discount": row.get("status_discount"),
            "updated_at": row.get("updated_at"),
            "desc": row.get("desc"),
            "cate": row.get("cate"),
            "shop_name": row.get("shop_name"),
            "update_time_raw": row.get("update_time_raw"),
        }
        # L·ªçc b·ªè c√°c gi√° tr·ªã NaN
        extra_fields = {k: v for k, v in extra_fields.items() if pd.notna(v)}

        # G·ªôp v√†o extra (kh√¥ng c√≤n xu·∫•t extra_raw trong Excel, nh∆∞ng DB v·∫´n gi·ªØ extra n·∫øu c√≥)
        extra = {}
        if promotion:
            extra["promotion"] = promotion
        if commission:
            extra["commission"] = commission
        # Th√™m c√°c tr∆∞·ªùng m·ªü r·ªông
        for k, v in extra_fields.items():
            extra[k] = v
        base["extra"] = json.dumps(extra, ensure_ascii=False)
        
        if only_with_commission:
            # X√°c ƒë·ªãnh ƒë·ªß ƒëi·ªÅu ki·ªán: c√≥ c·ªôt eligible_commission=True ho·∫∑c c√≥ √≠t nh·∫•t m·ªôt tr∆∞·ªùng commission h·ª£p l·ªá
            eligible_flag = False
            try:
                eligible_flag = bool(str(row.get("eligible_commission") or "").strip().lower() in ("true","1","yes"))
            except Exception:
                eligible_flag = False

            has_comm = False
            try:
                _comm = commission if isinstance(commission, dict) else {}
                for _k in ("sales_ratio","sales_price","reward_type","target_month"):
                    v = _comm.get(_k)
                    if v not in (None, "", float("nan")):
                        has_comm = True
                        break
            except Exception:
                has_comm = False

            if not (eligible_flag or has_comm):
                continue

        # affiliate_url: n·∫øu file c√≥ th√¨ ∆∞u ti√™n gi·ªØ ƒë√∫ng theo file; n·∫øu kh√¥ng c√≥ v√† c√≥ url + template ‚Üí auto convert
        if (not base.get("affiliate_url")) and base.get("url") and base.get("merchant"):
            try:
                tpl = crud.get_affiliate_template(db, base["merchant"], "accesstrade")
                if tpl:
                    merged_params: dict[str, str] = {}
                    if tpl.default_params:
                        merged_params.update(tpl.default_params)
                    # apply template: replace {target} and any params
                    aff = tpl.template.replace("{target}", quote_plus(base["url"]))
                    for k, v in merged_params.items():
                        aff = aff.replace("{"+k+"}", str(v))
                    base["affiliate_url"] = aff
            except Exception:
                pass

        # Set affiliate_link_available by presence of affiliate_url
        base["affiliate_link_available"] = bool(base.get("affiliate_url"))

        data = schemas.ProductOfferCreate(**base)

        if not data.url or not data.source_id:
            continue

        # N·∫øu b·∫≠t check link cho Excel th√¨ ch·ªâ ghi khi url s·ªëng
        if check_urls_excel:
            try:
                if not await _check_url_alive(data.url or ""):
                    continue
            except Exception:
                continue

        # D√πng upsert ƒë·∫∑c th√π cho Excel: ∆∞u ti√™n c·∫≠p nh·∫≠t theo source_id (b·∫•t k·ªÉ source hi·ªán c√≥)
        try:
            crud.upsert_offer_for_excel(db, data)
        except Exception:
            # fallback an to√†n n·∫øu h√†m m·ªõi kh√¥ng kh·∫£ d·ª•ng
            crud.upsert_offer_by_source(db, data)
        imported += 1

    # =========================
    # IMPORT: Campaigns sheet
    # =========================
    imported_campaigns = 0
    if "Campaigns" in xls.sheet_names:
        trans_campaigns = {
            "campaign_id": "M√£ chi·∫øn d·ªãch", "merchant": "Nh√† b√°n", "campaign_name": "T√™n chi·∫øn d·ªãch",
            "approval_type": "Approval", "user_status": "Tr·∫°ng th√°i c·ªßa t√¥i", "status": "T√¨nh tr·∫°ng",
            "start_time": "B·∫Øt ƒë·∫ßu", "end_time": "K·∫øt th√∫c",
            "category": "Danh m·ª•c ch√≠nh", "conversion_policy": "Ch√≠nh s√°ch chuy·ªÉn ƒë·ªïi",
            "cookie_duration": "Hi·ªáu l·ª±c cookie (gi√¢y)", "cookie_policy": "Ch√≠nh s√°ch cookie",
            "description_url": "M√¥ t·∫£ (Web)", "scope": "Ph·∫°m vi", "sub_category": "Danh m·ª•c ph·ª•",
            "type": "Lo·∫°i", "campaign_url": "URL chi·∫øn d·ªãch",
        }
        df_camp_raw = xls.parse("Campaigns")
        df_camp = _validate_and_strip_header(df_camp_raw, trans_campaigns, "Campaigns")

        # set d√πng ƒë·ªÉ tr√°nh sinh tr√πng trong c√πng file
        generated_ids_camp: set[str] = set()
        for _, row in df_camp.iterrows():
            cid = row.get("campaign_id")
            cid = str(cid).strip() if pd.notna(cid) else None
            if not cid:
                def _exists_campaign(c: str) -> bool:
                    return crud.get_campaign_by_cid(db, c) is not None or (c in generated_ids_camp)
                cid = _gen_code("ca", exists_check=_exists_campaign)
                generated_ids_camp.add(cid)
            try:
                payload = schemas.CampaignCreate(
                    campaign_id=cid,
                    merchant=(str(row.get("merchant")).strip().lower() if pd.notna(row.get("merchant")) else None),
                    name=(str(row.get("campaign_name")).strip() if pd.notna(row.get("campaign_name")) else None),
                    status=(str(row.get("status")).strip() if pd.notna(row.get("status")) else None),
                    approval=(str(row.get("approval_type")).strip() if pd.notna(row.get("approval_type")) else None),
                    start_time=(str(row.get("start_time")).strip() if pd.notna(row.get("start_time")) else None),
                    end_time=(str(row.get("end_time")).strip() if pd.notna(row.get("end_time")) else None),
                    user_registration_status=(str(row.get("user_status")).strip() if pd.notna(row.get("user_status")) else None),
                )
                crud.upsert_campaign(db, payload)
                imported_campaigns += 1
            except Exception:
                continue

    # =========================
    # IMPORT: Commissions sheet
    # =========================
    imported_commissions = 0
    if "Commissions" in xls.sheet_names:
        trans_commissions = {
            "id": "M√£ ID",
            "campaign_id": "M√£ chi·∫øn d·ªãch", "reward_type": "Ki·ªÉu th∆∞·ªüng", "sales_ratio": "T·ª∑ l·ªá (%)",
            "sales_price": "Hoa h·ªìng c·ªë ƒë·ªãnh", "target_month": "Th√°ng √°p d·ª•ng",
        }
        df_comm_raw = xls.parse("Commissions")
        df_comm = _validate_and_strip_header(df_comm_raw, trans_commissions, "Commissions")

        # N·∫øu c√≥ c·ªôt id: ∆∞u ti√™n c·∫≠p nh·∫≠t theo ID ƒë·ªÉ tr√°nh ph√°t sinh tr√πng; n·∫øu kh√¥ng c√≥ th√¨ upsert theo (campaign_id,reward_type,target_month)
        for _, row in df_comm.iterrows():
            cid = row.get("campaign_id")
            cid = str(cid).strip() if pd.notna(cid) else None
            if not cid:
                # Kh√¥ng y√™u c·∫ßu uniqueness tuy·ªát ƒë·ªëi v·ªõi campaign_id ·∫£o trong b·∫£ng commissions, nh∆∞ng tr√°nh va ch·∫°m nh·∫π
                cid = _gen_code("cm")
            try:
                payload = schemas.CommissionPolicyCreate(
                    campaign_id=cid,
                    reward_type=(str(row.get("reward_type")).strip() if pd.notna(row.get("reward_type")) else None),
                    sales_ratio=(float(row.get("sales_ratio")) if pd.notna(row.get("sales_ratio")) else None),
                    sales_price=(float(row.get("sales_price")) if pd.notna(row.get("sales_price")) else None),
                    target_month=(str(row.get("target_month")).strip() if pd.notna(row.get("target_month")) else None),
                )
                _id_val = row.get("id")
                if pd.notna(_id_val):
                    try:
                        _id_int = int(_id_val)
                    except Exception:
                        _id_int = None
                else:
                    _id_int = None
                if _id_int:
                    # c·∫≠p nh·∫≠t theo ID, b·ªè qua gi√° tr·ªã r·ªóng trong payload (ƒë√£ x·ª≠ l√Ω ·ªü CRUD)
                    updated = crud.update_commission_policy_by_id(db, _id_int, payload)
                    if updated is None:
                        # n·∫øu ID kh√¥ng t·ªìn t·∫°i ‚Üí fallback upsert theo kh√≥a nghi·ªáp v·ª•
                        crud.upsert_commission_policy(db, payload)
                else:
                    crud.upsert_commission_policy(db, payload)
                imported_commissions += 1
            except Exception:
                continue

    # =========================
    # IMPORT: Promotions sheet
    # =========================
    imported_promotions = 0
    if "Promotions" in xls.sheet_names:
        trans_promotions = {
            "id": "M√£ ID",
            "campaign_id": "M√£ chi·∫øn d·ªãch", "merchant": "Nh√† b√°n", "name": "T√™n khuy·∫øn m√£i", "content": "N·ªôi dung",
            "start_time": "B·∫Øt ƒë·∫ßu KM", "end_time": "K·∫øt th√∫c KM", "coupon": "M√£ gi·∫£m", "link": "Link khuy·∫øn m√£i",
        }
        df_prom_raw = xls.parse("Promotions")
        df_prom = _validate_and_strip_header(df_prom_raw, trans_promotions, "Promotions")

        for _, row in df_prom.iterrows():
            cid = row.get("campaign_id")
            cid = str(cid).strip() if pd.notna(cid) else None
            if not cid:
                cid = _gen_code("pr")
            try:
                payload = schemas.PromotionCreate(
                    campaign_id=cid,
                    name=(str(row.get("name")).strip() if pd.notna(row.get("name")) else None),
                    content=(str(row.get("content")).strip() if pd.notna(row.get("content")) else None),
                    start_time=(row.get("start_time") if pd.notna(row.get("start_time")) else None),
                    end_time=(row.get("end_time") if pd.notna(row.get("end_time")) else None),
                    coupon=(str(row.get("coupon")).strip() if pd.notna(row.get("coupon")) else None),
                    link=(str(row.get("link")).strip() if pd.notna(row.get("link")) else None),
                )
                _id_val = row.get("id")
                if pd.notna(_id_val):
                    try:
                        _id_int = int(_id_val)
                    except Exception:
                        _id_int = None
                else:
                    _id_int = None
                if _id_int:
                    updated = crud.update_promotion_by_id(db, _id_int, payload)
                    if updated is None:
                        crud.upsert_promotion(db, payload)
                else:
                    crud.upsert_promotion(db, payload)
                imported_promotions += 1
            except Exception:
                continue

    result = {
        "ok": True,
        "imported": imported,  # backward-compatible: s·ªë s·∫£n ph·∫©m Products
        "campaigns": imported_campaigns,
        "commissions": imported_commissions,
        "promotions": imported_promotions,
    }
    if required_errors:
        result.update({
            "skipped_required": skipped_required,
            "errors": required_errors[:50]
        })
    return result

# --- Export s·∫£n ph·∫©m t·ª´ DB ra file Excel ---
@app.get(
    "/offers/export-excel",
    tags=["Offers üõí"],
    summary="Xu·∫•t Excel chuy√™n bi·ªát (Products/Campaigns/Commissions/Promotions)",
    description=(
        "Xu·∫•t Excel g·ªìm 4 sheet ƒë·ªôc l·∫≠p. Products ch·ªâ g·ªìm s·∫£n ph·∫©m g·ªëc (datafeeds/top-products/manual/excel) v√† c√≥ c·ªôt source_type; "
        "Campaigns ch·ªâ c√°c campaign ƒë√£ APPROVED/SUCCESSFUL; Commissions/Promotions ƒë·ªôc l·∫≠p, kh√¥ng ph·ª• thu·ªôc s·∫£n ph·∫©m."
    )
)
def export_offers_excel(
    merchant: str | None = None,
    title: str | None = None,
    skip: int = 0,
    limit: int = 0,  # n·∫øu =0 th√¨ xu·∫•t to√†n b·ªô
    max_text_len: int | None = None,  # tu·ª≥ ch·ªçn: gi·ªõi h·∫°n k√Ω t·ª± cho c√°c tr∆∞·ªùng vƒÉn b·∫£n d√†i
    db: Session = Depends(get_db)
):
    import os, json
    import pandas as pd
    from collections import defaultdict

    # 1) Products: ch·ªâ l·∫•y offers g·ªëc (datafeeds/top-products/manual/excel) ‚Äî KH√îNG bao g·ªìm promotions-source
    q_offers = db.query(models.ProductOffer).filter(
        models.ProductOffer.source_type.in_(["datafeeds", "top_products", "manual", "excel"])  # lo·∫°i b·ªè "promotions"
    )
    if merchant:
        q_offers = q_offers.filter(models.ProductOffer.merchant == merchant.lower())
    if title:
        q_offers = q_offers.filter(models.ProductOffer.title.ilike(f"%{title.lower()}%"))
    if skip:
        q_offers = q_offers.offset(skip)
    if limit:
        q_offers = q_offers.limit(limit)
    offers = q_offers.all()

    # 2) Campaigns: ƒë·ªôc l·∫≠p, ch·ªâ APPROVED/SUCCESSFUL (chu·∫©n ho√° theo uppercase/trim)
    norm_user = func.upper(func.trim(models.Campaign.user_registration_status))
    campaigns_all = (
        db.query(models.Campaign)
        .filter(norm_user.in_(["APPROVED", "SUCCESSFUL"]))
        .order_by(models.Campaign.campaign_id.asc())
        .all()
    )
    campaign_map = {c.campaign_id: c for c in campaigns_all}

    # 3) Commissions: ƒë·ªôc l·∫≠p, l·∫•y t·ª´ b·∫£ng CommissionPolicy
    commissions_all = db.query(models.CommissionPolicy).all()

    # 4) Promotions: ƒë·ªôc l·∫≠p, l·∫•y t·ª´ b·∫£ng Promotion (k√®m merchant t·ª´ campaign n·∫øu c√≥)
    promotions_all = db.query(models.Promotion).all()

    # Helper: sanitize values for Excel XML (remove control chars, limit length)
    import re
    _illegal_xml_re = re.compile(r"[\x00-\x08\x0B\x0C\x0E-\x1F]")
    def _sanitize_val(v):
        import datetime as _dt
        if v is None:
            return None
        # Convert dict/list to JSON string
        if isinstance(v, (dict, list)):
            try:
                v = json.dumps(v, ensure_ascii=False)
            except Exception:
                v = str(v)
        # Convert datetime to ISO
        if hasattr(v, 'isoformat') and not isinstance(v, str):
            try:
                v = v.isoformat()
            except Exception:
                v = str(v)
        s = str(v)
        # Remove illegal XML control characters and truncate to Excel cell limit
        s = _illegal_xml_re.sub(" ", s)
        # NgƒÉn Excel hi·ªÉu nh·∫ßm chu·ªói l√† c√¥ng th·ª©c (='+-@) ‚Üí prefix b·∫±ng d·∫•u nh√°y ƒë∆°n
        if s and s[0] in ("=", "+", "-", "@"):
            s = "'" + s
        # Gi·ªõi h·∫°n ƒë·ªô d√†i: ∆∞u ti√™n max_text_len n·∫øu ƒë∆∞·ª£c truy·ªÅn, ng∆∞·ª£c l·∫°i 32K (gi·ªõi h·∫°n Excel ~32767)
        _limit = 32000 if (max_text_len is None or max_text_len <= 0) else max_text_len
        if len(s) > _limit:
            s = s[:_limit]
        return s

    # Helper: strip HTML to plain text (simple, dependency-free)
    def _strip_html(val):
        if val in (None, "", []):
            return None
        try:
            import re, html as _html
            s = str(val)
            # Remove script/style blocks
            s = re.sub(r"<\s*(script|style)[^>]*>[\s\S]*?<\s*/\s*\1\s*>", " ", s, flags=re.IGNORECASE)
            # Remove all tags
            s = re.sub(r"<[^>]+>", " ", s)
            # Unescape HTML entities
            s = _html.unescape(s)
            # Collapse whitespace
            s = re.sub(r"\s+", " ", s).strip()
            return s
        except Exception:
            return str(val)

    # 5) ƒê·ªçc JSONL logs ƒë·ªÉ enrich Campaign fields (gi·ªëng tr∆∞·ªõc ƒë√¢y)
    LOG_DIR = os.getenv("API_LOG_DIR", "./logs")
    def _read_jsonl(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        yield json.loads(line)
                    except Exception:
                        pass
        except FileNotFoundError:
            return

    CAMP_LAST = {}
    for rec in _read_jsonl(os.path.join(LOG_DIR, "campaign_detail.jsonl")) or []:
        cid = str(rec.get("campaign_id") or "")
        if cid:
            CAMP_LAST[cid] = rec

    def _campaign_field_from_log(cid: str, field_name: str):
        rec = CAMP_LAST.get(str(cid) if cid is not None else "")
        if not rec:
            return None
        if field_name == "end_time" and rec.get("has_end_time") is False:
            return None
        if field_name == "user_registration_status" and rec.get("has_user_status") is False:
            return None
        if rec.get("empty") is True:
            return None
        raw = rec.get("raw")
        if isinstance(raw, dict):
            data = None
            d = raw.get("data")
            if isinstance(d, dict):
                data = d
            elif isinstance(d, list) and d:
                data = d[0]
            if isinstance(data, dict):
                if field_name == "user_registration_status":
                    for k in ("user_registration_status", "publisher_status", "user_status"):
                        v = data.get(k, None)
                        if v not in (None, "", []):
                            return v
                    return None
                v = data.get(field_name, None)
                return v if v not in (None, "", []) else None
        return None

    # ---------------------------
    # Build Products rows
    # ---------------------------
    df_products_rows = []
    for o in offers:
        extra = {}
        if o.extra:
            try:
                extra = json.loads(o.extra)
            except Exception:
                extra = {}
        df_products_rows.append({
            "id": o.id,
            "source": o.source,
            "source_id": o.source_id,
            "source_type": o.source_type,
            "merchant": _sanitize_val(o.merchant),
            "title": _sanitize_val(o.title),
            "url": _sanitize_val(o.url),
            "affiliate_url": _sanitize_val(o.affiliate_url),
            "image_url": _sanitize_val(o.image_url),
            "price": o.price,
            "currency": _sanitize_val(o.currency),
            "campaign_id": o.campaign_id,
            "product_id": _sanitize_val(extra.get("product_id") or getattr(o, "product_id", None)),
            "affiliate_link_available": o.affiliate_link_available,
            "domain": _sanitize_val(extra.get("domain")),
            "sku": _sanitize_val(extra.get("sku")),
            "discount": extra.get("discount"),
            "discount_amount": extra.get("discount_amount"),
            "discount_rate": extra.get("discount_rate"),
            "status_discount": extra.get("status_discount"),
            "updated_at": _sanitize_val(o.updated_at.isoformat() if o.updated_at else None),
            "desc": _sanitize_val(extra.get("desc")),
            "cate": _sanitize_val(extra.get("cate")),
            "shop_name": _sanitize_val(extra.get("shop_name")),
            "update_time_raw": _sanitize_val(extra.get("update_time_raw") or extra.get("update_time")),
        })

    # ---------------------------
    # Build Campaigns rows (independent)
    # ---------------------------
    df_campaigns_rows = []
    # Chu·∫©n b·ªã base URL c√¥ng khai (n·∫øu c√≥) ƒë·ªÉ t·∫°o link m·ªü tr√¨nh duy·ªát
    PUBLIC_BASE = os.getenv("EXPORT_PUBLIC_BASE_URL") or os.getenv("PUBLIC_BASE_URL") or "http://localhost:8000"

    for idx, c in enumerate(campaigns_all, start=1):
        cid = c.campaign_id
        _desc_raw = _campaign_field_from_log(cid, "description")
        has_desc = bool(_strip_html(_desc_raw))
        df_campaigns_rows.append({
            "campaign_id": c.campaign_id,
            "merchant": _sanitize_val(c.merchant),
            "campaign_name": _sanitize_val(c.name),
            "approval_type": _sanitize_val(c.approval),
            "user_status": _sanitize_val(c.user_registration_status),
            "status": _sanitize_val(c.status or _campaign_field_from_log(cid, "status")),
            "start_time": _sanitize_val(c.start_time),
            "end_time": _sanitize_val(c.end_time if c.end_time else _campaign_field_from_log(cid, "end_time")),
            "category": _sanitize_val(_campaign_field_from_log(cid, "category")),
            "conversion_policy": _sanitize_val(_campaign_field_from_log(cid, "conversion_policy")),
            "cookie_duration": _sanitize_val(_campaign_field_from_log(cid, "cookie_duration")),
            "cookie_policy": _sanitize_val(_campaign_field_from_log(cid, "cookie_policy")),
            # Ch·ªâ t·∫°o link ngo√†i n·∫øu th·ª±c s·ª± c√≥ m√¥ t·∫£
            "description_url": (f"{PUBLIC_BASE}/campaigns/{cid}/description" if (PUBLIC_BASE and has_desc) else None),
            "scope": _sanitize_val(_campaign_field_from_log(cid, "scope")),
            "sub_category": _sanitize_val(_campaign_field_from_log(cid, "sub_category")),
            "type": _sanitize_val(_campaign_field_from_log(cid, "type")),
            "campaign_url": _sanitize_val(_campaign_field_from_log(cid, "url")),
        })

    # ---------------------------
    # Build Commissions rows (independent)
    # ---------------------------
    df_commissions_rows = []
    for cp in commissions_all:
        df_commissions_rows.append({
            "id": cp.id,
            "campaign_id": cp.campaign_id,
            "reward_type": cp.reward_type,
            "sales_ratio": cp.sales_ratio,
            "sales_price": cp.sales_price,
            "target_month": cp.target_month,
        })

    # ---------------------------
    # Build Promotions rows (independent + merchant)
    # ---------------------------
    df_promotions_rows = []
    for pr in promotions_all:
        m = None
        if pr.campaign_id and pr.campaign_id in campaign_map:
            m = campaign_map[pr.campaign_id].merchant
        df_promotions_rows.append({
            "id": pr.id,
            "campaign_id": pr.campaign_id,
            "merchant": _sanitize_val(m),
            "name": _sanitize_val(pr.name),
            "content": _sanitize_val(pr.content),
            "start_time": _sanitize_val(pr.start_time),
            "end_time": _sanitize_val(pr.end_time),
            "coupon": _sanitize_val(pr.coupon),
            "link": _sanitize_val(pr.link),
        })

    # DataFrames
    df_products = pd.DataFrame(df_products_rows)
    df_campaigns = pd.DataFrame(df_campaigns_rows)
    df_commissions = pd.DataFrame(df_commissions_rows)
    df_promotions = pd.DataFrame(df_promotions_rows)

    # Header translations (Vietnamese) ‚Äî add (*) markers for required in Products
    trans_products = {
        "id": "M√£ ID", "source": "Ngu·ªìn", "source_id": "M√£ ngu·ªìn", "source_type": "Lo·∫°i ngu·ªìn",
        "merchant": "Nh√† b√°n (*)", "title": "T√™n s·∫£n ph·∫©m (*)", "url": "Link g·ªëc", "affiliate_url": "Link ti·∫øp th·ªã",
        "image_url": "·∫¢nh s·∫£n ph·∫©m", "price": "Gi√° (*)", "currency": "Ti·ªÅn t·ªá",
        "campaign_id": "Chi·∫øn d·ªãch", "product_id": "M√£ s·∫£n ph·∫©m ngu·ªìn", "affiliate_link_available": "C√≥ affiliate?",
        "domain": "T√™n mi·ªÅn", "sku": "SKU", "discount": "Gi√° KM", "discount_amount": "M·ª©c gi·∫£m",
        "discount_rate": "T·ª∑ l·ªá gi·∫£m (%)", "status_discount": "C√≥ khuy·∫øn m√£i?",
        "updated_at": "Ng√†y c·∫≠p nh·∫≠t", "desc": "M√¥ t·∫£ chi ti·∫øt",
        "cate": "Danh m·ª•c", "shop_name": "T√™n c·ª≠a h√†ng", "update_time_raw": "Th·ªùi gian c·∫≠p nh·∫≠t t·ª´ ngu·ªìn",
    }
    trans_campaigns = {
        "campaign_id": "M√£ chi·∫øn d·ªãch", "merchant": "Nh√† b√°n", "campaign_name": "T√™n chi·∫øn d·ªãch",
        "approval_type": "Approval", "user_status": "Tr·∫°ng th√°i c·ªßa t√¥i", "status": "T√¨nh tr·∫°ng",
        "start_time": "B·∫Øt ƒë·∫ßu", "end_time": "K·∫øt th√∫c",
        "category": "Danh m·ª•c ch√≠nh", "conversion_policy": "Ch√≠nh s√°ch chuy·ªÉn ƒë·ªïi",
        "cookie_duration": "Hi·ªáu l·ª±c cookie (gi√¢y)", "cookie_policy": "Ch√≠nh s√°ch cookie",
        "description_url": "M√¥ t·∫£ (Web)", "scope": "Ph·∫°m vi", "sub_category": "Danh m·ª•c ph·ª•",
        "type": "Lo·∫°i", "campaign_url": "URL chi·∫øn d·ªãch",
    }
    trans_commissions = {
        "id": "M√£ ID",
        "campaign_id": "M√£ chi·∫øn d·ªãch", "reward_type": "Ki·ªÉu th∆∞·ªüng", "sales_ratio": "T·ª∑ l·ªá (%)",
        "sales_price": "Hoa h·ªìng c·ªë ƒë·ªãnh", "target_month": "Th√°ng √°p d·ª•ng",
    }
    trans_promotions = {
        "id": "M√£ ID",
        "campaign_id": "M√£ chi·∫øn d·ªãch", "merchant": "Nh√† b√°n", "name": "T√™n khuy·∫øn m√£i", "content": "N·ªôi dung",
        "start_time": "B·∫Øt ƒë·∫ßu KM", "end_time": "K·∫øt th√∫c KM", "coupon": "M√£ gi·∫£m", "link": "Link khuy·∫øn m√£i",
    }

    def _with_header(df, trans):
        # Lu√¥n t·∫°o m·ªôt h√†ng ti√™u ƒë·ªÅ TV l√†m h√†ng ƒë·∫ßu ti√™n
        # N·∫øu df ƒëang r·ªóng, t·∫°o h√†ng ƒë·∫ßu v·ªõi to√†n b·ªô c·ªôt theo trans
        if df.empty:
            header = {c: trans.get(c, c) for c in trans.keys()}
            return pd.DataFrame([header])
        header = {c: trans.get(c, c) for c in df.columns}
        return pd.concat([pd.DataFrame([header]), df], ignore_index=True)

    df_products = _with_header(df_products, trans_products)
    df_campaigns = _with_header(df_campaigns, trans_campaigns)
    df_commissions = _with_header(df_commissions, trans_commissions)
    df_promotions = _with_header(df_promotions, trans_promotions)

    output = io.BytesIO()
    # T·∫Øt auto-detect c√¥ng th·ª©c/URL c·ªßa xlsxwriter ƒë·ªÉ tr√°nh Excel t·ª± t·∫°o c√¥ng th·ª©c ho·∫∑c hyperlink
    with pd.ExcelWriter(
        output,
        engine="xlsxwriter",
        engine_kwargs={"options": {"strings_to_formulas": False, "strings_to_urls": False}},
    ) as writer:
        # N·∫øu DataFrame r·ªóng, v·∫´n c·∫ßn t·∫°o c·ªôt theo trans ƒë·ªÉ sheet c√≥ header
        def _ensure_cols(df, trans_map):
            cols = list(trans_map.keys())
            if df.empty:
                return pd.DataFrame(columns=cols)
            # Reorder/align columns to match trans_map keys; include missing columns as empty
            for c in cols:
                if c not in df.columns:
                    df[c] = None
            return df[cols]

        df_products = _ensure_cols(df_products, trans_products)
        df_campaigns = _ensure_cols(df_campaigns, trans_campaigns)
        df_commissions = _ensure_cols(df_commissions, trans_commissions)
        df_promotions = _ensure_cols(df_promotions, trans_promotions)

        df_products.to_excel(writer, sheet_name="Products", index=False)
        df_campaigns.to_excel(writer, sheet_name="Campaigns", index=False)
        df_commissions.to_excel(writer, sheet_name="Commissions", index=False)
        df_promotions.to_excel(writer, sheet_name="Promotions", index=False)

        # Re-add clickable hyperlinks explicitly for known URL columns
        wb = writer.book
        url_format = wb.add_format({"font_color": "blue", "underline": 1})
        def _write_urls(ws, df, cols: list[str]):
            for col in cols:
                if col not in df.columns:
                    continue
                c_idx = df.columns.get_loc(col)
                # Skip the Vietnamese header row at df index 0; Excel row = df_index + 1
                for r_idx, row in df.iloc[1:].iterrows():
                    val = row.get(col)
                    if not val:
                        continue
                    s = str(val)
                    if s.lower().startswith(("http://", "https://")):
                        excel_row = r_idx + 1  # account for header row
                        try:
                            ws.write_url(excel_row, c_idx, s, url_format, string=s)
                        except Exception:
                            pass

        ws_prod = writer.sheets.get("Products")
        ws_camp = writer.sheets.get("Campaigns")
        ws_prom = writer.sheets.get("Promotions")
        if ws_prod is not None:
            _write_urls(ws_prod, df_products, ["url", "affiliate_url", "image_url"])
        if ws_camp is not None:
            _write_urls(ws_camp, df_campaigns, ["campaign_url", "description_url"])
        if ws_prom is not None:
            _write_urls(ws_prom, df_promotions, ["link"])

        # Style the Vietnamese header row (row index 1) as bold + italic
        workbook = writer.book
        fmt_vi_header = workbook.add_format({"bold": True, "italic": True})
        for sheet_name in ("Products", "Campaigns", "Commissions", "Promotions"):
            ws = writer.sheets.get(sheet_name)
            if ws is not None:
                try:
                    ws.set_row(1, None, fmt_vi_header)
                except Exception:
                    pass
    output.seek(0)

    filename = f"offers_export_{int(time.time())}.xlsx"
    headers = {"Content-Disposition": f"attachment; filename={filename}"}
    return StreamingResponse(
        output,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers=headers
    )

@app.get(
    "/offers/export-template",
    tags=["Offers üõí"],
    summary="T·∫£i template Excel (4 sheet)",
    description="T·∫£i file m·∫´u c√≥ s·∫µn 4 sheet v·ªõi header 2 h√†ng; ƒë√°nh d·∫•u (*) ·ªü c√°c c·ªôt b·∫Øt bu·ªôc c·ªßa Products."
)
def export_excel_template():
    import pandas as pd
    # T·∫°o DataFrames r·ªóng v·ªõi ƒë√∫ng c·ªôt v√† ch√®n h√†ng ti√™u ƒë·ªÅ TV
    trans_products = {
        "id": "M√£ ID", "source": "Ngu·ªìn", "source_id": "M√£ ngu·ªìn", "source_type": "Lo·∫°i ngu·ªìn",
        "merchant": "Nh√† b√°n (*)", "title": "T√™n s·∫£n ph·∫©m (*)", "url": "Link g·ªëc", "affiliate_url": "Link ti·∫øp th·ªã",
        "image_url": "·∫¢nh s·∫£n ph·∫©m", "price": "Gi√° (*)", "currency": "Ti·ªÅn t·ªá",
        "campaign_id": "Chi·∫øn d·ªãch", "product_id": "M√£ s·∫£n ph·∫©m ngu·ªìn", "affiliate_link_available": "C√≥ affiliate?",
        "domain": "T√™n mi·ªÅn", "sku": "SKU", "discount": "Gi√° KM", "discount_amount": "M·ª©c gi·∫£m",
        "discount_rate": "T·ª∑ l·ªá gi·∫£m (%)", "status_discount": "C√≥ khuy·∫øn m√£i?",
        "updated_at": "Ng√†y c·∫≠p nh·∫≠t", "desc": "M√¥ t·∫£ chi ti·∫øt",
        "cate": "Danh m·ª•c", "shop_name": "T√™n c·ª≠a h√†ng", "update_time_raw": "Th·ªùi gian c·∫≠p nh·∫≠t t·ª´ ngu·ªìn",
    }
    trans_campaigns = {
        "campaign_id": "M√£ chi·∫øn d·ªãch", "merchant": "Nh√† b√°n", "campaign_name": "T√™n chi·∫øn d·ªãch",
        "approval_type": "Approval", "user_status": "Tr·∫°ng th√°i c·ªßa t√¥i", "status": "T√¨nh tr·∫°ng",
        "start_time": "B·∫Øt ƒë·∫ßu", "end_time": "K·∫øt th√∫c",
        "category": "Danh m·ª•c ch√≠nh", "conversion_policy": "Ch√≠nh s√°ch chuy·ªÉn ƒë·ªïi",
        "cookie_duration": "Hi·ªáu l·ª±c cookie (gi√¢y)", "cookie_policy": "Ch√≠nh s√°ch cookie",
        "description_url": "M√¥ t·∫£ (Web)", "scope": "Ph·∫°m vi", "sub_category": "Danh m·ª•c ph·ª•",
        "type": "Lo·∫°i", "campaign_url": "URL chi·∫øn d·ªãch",
    }
    trans_commissions = {
        "id": "M√£ ID",
        "campaign_id": "M√£ chi·∫øn d·ªãch", "reward_type": "Ki·ªÉu th∆∞·ªüng", "sales_ratio": "T·ª∑ l·ªá (%)",
        "sales_price": "Hoa h·ªìng c·ªë ƒë·ªãnh", "target_month": "Th√°ng √°p d·ª•ng",
    }
    trans_promotions = {
        "id": "M√£ ID",
        "campaign_id": "M√£ chi·∫øn d·ªãch", "merchant": "Nh√† b√°n", "name": "T√™n khuy·∫øn m√£i", "content": "N·ªôi dung",
        "start_time": "B·∫Øt ƒë·∫ßu KM", "end_time": "K·∫øt th√∫c KM", "coupon": "M√£ gi·∫£m", "link": "Link khuy·∫øn m√£i",
    }

    def _df_with_header(cols_map):
        df = pd.DataFrame(columns=list(cols_map.keys()))
        header = {c: cols_map.get(c, c) for c in df.columns}
        return pd.concat([pd.DataFrame([header]), df], ignore_index=True)

    df_products = _df_with_header(trans_products)
    df_campaigns = _df_with_header(trans_campaigns)
    df_commissions = _df_with_header(trans_commissions)
    df_promotions = _df_with_header(trans_promotions)

    output = io.BytesIO()
    with pd.ExcelWriter(
        output,
        engine="xlsxwriter",
        engine_kwargs={"options": {"strings_to_formulas": False, "strings_to_urls": False}},
    ) as writer:
        df_products.to_excel(writer, sheet_name="Products", index=False)
        df_campaigns.to_excel(writer, sheet_name="Campaigns", index=False)
        df_commissions.to_excel(writer, sheet_name="Commissions", index=False)
        df_promotions.to_excel(writer, sheet_name="Promotions", index=False)

        # Style the Vietnamese header row (row index 1) as bold + italic
        workbook = writer.book
        fmt_vi_header = workbook.add_format({"bold": True, "italic": True})
        for sheet_name in ("Products", "Campaigns", "Commissions", "Promotions"):
            ws = writer.sheets.get(sheet_name)
            if ws is not None:
                try:
                    ws.set_row(1, None, fmt_vi_header)
                except Exception:
                    pass
    output.seek(0)

    filename = f"offers_template_{int(time.time())}.xlsx"
    headers = {"Content-Disposition": f"attachment; filename={filename}"}
    return StreamingResponse(
        output,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers=headers
    )
@app.get(
    "/alerts/campaigns-registration",
    tags=["Campaigns üì¢"],
    summary="C·∫£nh b√°o ƒëƒÉng k√Ω chi·∫øn d·ªãch",
    description="Li·ªát k√™ c√°c campaign ƒëang ch·∫°y v√† ƒë√£ c√≥ s·∫£n ph·∫©m trong DB, nh∆∞ng user ch∆∞a ·ªü tr·∫°ng th√°i APPROVED (ch∆∞a ƒëƒÉng k√Ω ho·∫∑c ƒëang ch·ªù duy·ªát)."
)
def campaigns_registration_alerts(db: Session = Depends(get_db)):
    return crud.campaigns_need_registration_alerts(db)

# ---------------- Optional helper page: campaign description as HTML ----------------
@app.get(
        "/campaigns/{campaign_id}/description",
        tags=["Campaigns üì¢"],
        summary="Xem m√¥ t·∫£ chi·∫øn d·ªãch (HTML r√∫t g·ªçn)",
)
def campaign_description_page(campaign_id: str, db: Session = Depends(get_db)):
        import html, re
        # L·∫•y t·ª´ log ƒë√£ l∆∞u (∆∞u ti√™n, v√¨ ƒë·∫ßy ƒë·ªß h∆°n DB)
        LOG_DIR = os.getenv("API_LOG_DIR", "./logs")
        path = os.path.join(LOG_DIR, "campaign_detail.jsonl")
        raw_html = None
        try:
                with open(path, "r", encoding="utf-8") as f:
                        for line in f:
                                try:
                                        rec = json.loads(line)
                                        if str(rec.get("campaign_id")) == str(campaign_id):
                                                data = rec.get("raw", {}).get("data")
                                                if isinstance(data, list) and data:
                                                        data = data[0]
                                                if isinstance(data, dict):
                                                        raw_html = data.get("description")
                                except Exception:
                                        continue
        except FileNotFoundError:
                pass
        # Fallback r·ªóng n·∫øu kh√¥ng c√≥
        raw_html = raw_html or "<p>Kh√¥ng t√¨m th·∫•y m√¥ t·∫£.</p>"
        # V·ªá sinh t·ªëi thi·ªÉu: ch·∫∑n script/style
        raw_html = re.sub(r"<\s*(script|style)[^>]*>[\s\S]*?<\s*/\s*\1\s*>", "", str(raw_html), flags=re.IGNORECASE)
        body = f"""
        <!doctype html>
        <html lang=vi>
        <head>
            <meta charset="utf-8" />
            <title>M√¥ t·∫£ chi·∫øn d·ªãch {html.escape(str(campaign_id))}</title>
            <style>
                body {{ font-family: -apple-system, Segoe UI, Roboto, Arial, sans-serif; margin: 24px; line-height: 1.6; }}
                .container {{ max-width: 980px; margin: 0 auto; }}
                .meta {{ color: #666; margin-bottom: 16px; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="meta">Campaign ID: {html.escape(str(campaign_id))}</div>
                <div class="content">{raw_html}</div>
            </div>
        </body>
        </html>
        """
        return HTMLResponse(content=body)
