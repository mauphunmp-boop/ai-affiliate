# backend/main.py
import logging, traceback
import os, hmac, hashlib, base64, json, time, asyncio
from urllib.parse import urlparse, quote_plus
from typing import Optional, Dict, List, Any

from fastapi import FastAPI, Depends, HTTPException, Request, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, RedirectResponse, StreamingResponse
import io
from fastapi.exceptions import RequestValidationError

from sqlalchemy.orm import Session
from sqlalchemy import text, or_, and_

from ai_service import suggest_products_with_config
import models, schemas, crud
from database import Base, engine, SessionLocal
from pydantic import BaseModel, HttpUrl
from accesstrade_service import (
    fetch_products, map_at_product_to_offer, _check_url_alive, fetch_promotions,
    fetch_campaign_detail, fetch_commission_policies  # NEW
)

# ---------------- Logging ----------------
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger("affiliate_api")

# H·∫° m·ª©c log c·ªßa httpx/httpcore/uvicorn ƒë·ªÉ tr√°nh spam d√†i d√≤ng
for noisy in ("httpx", "httpcore", "uvicorn", "uvicorn.error", "uvicorn.access"):
    logging.getLogger(noisy).setLevel(logging.WARNING)

# ---------------- DB init ----------------
Base.metadata.create_all(bind=engine)

# --- Default ingest policy on startup ---
# M·∫∑c ƒë·ªãnh:
# - only_with_commission=false  (Excel m·ªõi √°p d·ª•ng)
# - check_urls=false            (t·∫Øt check link khi ingest qua API/Excel)
# - linkcheck_cursor=0          (scheduler qu√©t lu√¢n phi√™n 10 "l√°t c·∫Øt")
try:
    _db = SessionLocal()
    existing = crud.get_api_config(_db, "ingest_policy")
    if not existing:
        crud.create_api_config(_db, schemas.APIConfigCreate(
            name="ingest_policy", base_url="-", api_key="-",
            model="only_with_commission=false;check_urls=false;linkcheck_cursor=0"
        ))
    else:
        model_str = (existing.model or "").lower()
        if "check_urls=" not in model_str or "linkcheck_cursor=" not in model_str:
            # B·ªï sung ph·∫ßn c√≤n thi·∫øu, kh√¥ng ph√° gi√° tr·ªã c≈©
            parts = [model_str] if model_str else []
            if "check_urls=" not in model_str:
                parts.append("check_urls=false")
            if "linkcheck_cursor=" not in model_str:
                parts.append("linkcheck_cursor=0")
            updated = ";".join([p for p in parts if p])
            crud.upsert_api_config_by_name(_db, schemas.APIConfigCreate(
                name="ingest_policy", base_url=existing.base_url or "-",
                api_key=existing.api_key or "-", model=updated
            ))
finally:
    try:
        _db.close()
    except Exception:
        pass

# --- DB MIGRATION V2 (th√™m c·ªôt & b·∫£ng ph·ª•c v·ª• hybrid 3 l·ªõp) ---
try:
    with engine.begin() as conn:
        conn.execute(text("ALTER TABLE product_offers ADD COLUMN IF NOT EXISTS approval_status VARCHAR"))
        conn.execute(text("ALTER TABLE product_offers ADD COLUMN IF NOT EXISTS eligible_commission BOOLEAN DEFAULT FALSE"))
        conn.execute(text("ALTER TABLE product_offers ADD COLUMN IF NOT EXISTS source_type VARCHAR"))
        conn.execute(text("ALTER TABLE product_offers ADD COLUMN IF NOT EXISTS affiliate_link_available BOOLEAN DEFAULT FALSE"))
        conn.execute(text("ALTER TABLE product_offers ADD COLUMN IF NOT EXISTS product_id VARCHAR"))
        conn.execute(text("CREATE INDEX IF NOT EXISTS ix_product_offers_approval_status ON product_offers (approval_status)"))
        conn.execute(text("CREATE INDEX IF NOT EXISTS ix_product_offers_campaign_id ON product_offers (campaign_id)"))
        conn.execute(text("CREATE INDEX IF NOT EXISTS ix_product_offers_product_id ON product_offers (product_id)"))
        # NEW: unique index ch·ªëng tr√πng (source, source_id)
        conn.execute(text("CREATE UNIQUE INDEX IF NOT EXISTS uq_product_offers_source_source_id ON product_offers (source, source_id)"))
except Exception as e:
    logger.error("DB migration V2 failed: %s", e)

# ---------------- FastAPI App (UI ƒë·∫πp & c√≥ nh√≥m) ----------------
app = FastAPI(
    title="AI Affiliate Advisor API",
    version="1.0.0",
    description=(
        "üìò **T√†i li·ªáu API h·ªá th·ªëng Affiliate**\n\n"
        "Qu·∫£n l√Ω link ti·∫øp th·ªã li√™n k·∫øt, ingest s·∫£n ph·∫©m, ki·ªÉm tra alive/dead, "
        "v√† s·ª≠ d·ª•ng AI ƒë·ªÉ t∆∞ v·∫•n s·∫£n ph·∫©m.\n\n"
        "C√°c endpoint ƒë∆∞·ª£c nh√≥m theo **tags** ƒë·ªÉ d·ªÖ s·ª≠ d·ª•ng."
    ),
    openapi_tags=[
    {"name": "System üõ†Ô∏è", "description": "Ki·ªÉm tra tr·∫°ng th√°i h·ªá th·ªëng & s·ª©c kh·ªèe d·ªãch v·ª•."},
    {"name": "Links üîó", "description": "CRUD link ti·∫øp th·ªã (hi·ªÉn th·ªã, th√™m, s·ª≠a, xo√°)."},
    {"name": "API Configs ‚öôÔ∏è", "description": "Qu·∫£n l√Ω c·∫•u h√¨nh AI/API (t·∫°o, danh s√°ch, c·∫≠p nh·∫≠t, xo√°)."},
    {"name": "Affiliate üéØ", "description": "M·∫´u deeplink, chuy·ªÉn link g·ªëc ‚Üí deeplink & shortlink, redirect an to√†n."},
    {"name": "Offers üõí", "description": "Qu·∫£n l√Ω s·∫£n ph·∫©m (ingest t·ª´ Accesstrade, danh s√°ch, cleanup link ch·∫øt, ki·ªÉm tra 1 s·∫£n ph·∫©m)."},
    {"name": "AI ü§ñ", "description": "G·ª£i √Ω/Tr·∫£ l·ªùi c·ªßa AI d·ª±a tr√™n c√°c s·∫£n ph·∫©m ƒë√£ ingest trong DB."},
    {"name": "Campaigns üì¢", "description": "C·∫£nh b√°o ƒëƒÉng k√Ω chi·∫øn d·ªãch & t√¨nh tr·∫°ng user."}
    ],
    swagger_ui_parameters={
        "docExpansion": "list",               # M·ªü theo nh√≥m, g·ªçn g√†ng
        "defaultModelsExpandDepth": -1,       # ·∫®n schema m·∫∑c ƒë·ªãnh cho ƒë·ª° r·ªëi
        "displayRequestDuration": True,       # Hi·ªán th·ªùi gian th·ª±c thi
        "deepLinking": True,                  # Cho ph√©p deep link t·ªõi t·ª´ng API
        "filter": True                        # √î l·ªçc endpoint nhanh
    }
)

# --- Scheduler ƒë·ªÉ cleanup + ingest datafeeds h·∫±ng ng√†y ---
from fastapi_utils.tasks import repeat_every

@app.on_event("startup")
@repeat_every(seconds=86400, wait_first=True)  # ch·∫°y m·ªói ng√†y, ch·ªù 1 ng√†y m·ªõi ch·∫°y l·∫ßn ƒë·∫ßu
async def scheduled_ingest_accesstrade() -> None:
    db = SessionLocal()
    try:
        # --- Cleanup link ch·∫øt: chuy·ªÉn sang xoay v√≤ng 10%/l∆∞·ª£t ---
        try:
            # m·ªói ng√†y ki·ªÉm 1 "l√°t c·∫Øt": id % 10 = cursor; xong t·ª± tƒÉng cursor (mod 10)
            res = await scheduler_linkcheck_rotate(delete_dead=True, db=db)
            logger.info("[ROTATE] daily linkcheck: %s", res)
        except Exception as e:
            logger.error("[ROTATE] daily linkcheck failed: %s", e)

        # --- L·∫•y campaign ƒëang ch·∫°y ---
        from accesstrade_service import fetch_active_campaigns
        active_campaigns = await fetch_active_campaigns(db)
        logger.info("Fetched %d active campaigns", len(active_campaigns))

        # T·∫°o map merchant -> campaign_id t·ª´ danh s√°ch active ƒë·ªÉ suy ng∆∞·ª£c
        merchant_campaign_map = {v: k for k, v in active_campaigns.items()}

        # --- Ingest khuy·∫øn m√£i & top products theo ki·∫øn tr√∫c m·ªõi ---
        try:
            await ingest_v2_promotions(IngestV2PromotionsReq(merchant=None, create_offers=True), db)
            approved_merchants = list_approved_merchants_api(db)  # danh s√°ch merchant ƒë√£ APPROVED & running
            for m in approved_merchants:
                await ingest_v2_top_products(
                    IngestV2TopProductsReq(merchant=m, limit_per_page=100, max_pages=1, throttle_ms=0), db
                )
        except Exception as e:
            logger.error("Scheduled v2 ingest (promotions/top-products) failed: %s", e)

        # --- Ingest datafeeds full (t√πy ch·ªçn, ch·∫°y sau c√πng) ---
        try:
            res = await ingest_accesstrade_datafeeds_all(
                IngestAllDatafeedsReq(limit_per_page=100, max_pages=2000, throttle_ms=200),
                db
            )
            logger.info("Scheduled full ingest done: %s", res)
        except Exception as e:
            logger.error("Scheduled full ingest failed: %s", e)

    except Exception as e:
        logger.error("Scheduled ingest failed: %s", e)
    finally:
        db.close()

# ---------------- CORS ----------------
origins: List[str] = ["http://localhost:5173", "http://127.0.0.1:5173"]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------------- DB dependency ----------------
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ---------------- Error handlers ----------------
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    logger.warning(
        "Validation error on %s %s: %s | body=%s",
        request.method, request.url.path, exc, getattr(exc, "body", None)
    )
    return JSONResponse(
        status_code=422,
        content={"detail": exc.errors(), "body": getattr(exc, "body", None)}
    )

@app.exception_handler(Exception)
async def all_exception_handler(request: Request, exc: Exception):
    tb = traceback.format_exc()
    logger.error("Unhandled exception: %s\n%s", exc, tb)
    return JSONResponse(status_code=500, content={"error": str(exc), "traceback": tb})

# ---------------- System ----------------
@app.get(
    "/",
    tags=["System üõ†Ô∏è"],
    summary="Ch√†o m·ª´ng",
    description="Th√¥ng b√°o API ƒëang ch·∫°y v√† h∆∞·ªõng d·∫´n truy c·∫≠p t√†i li·ªáu t·∫°i **/docs**."
)
def root():
    return {"message": "Affiliate API is running. See /docs"}

@app.get(
    "/health",
    tags=["System üõ†Ô∏è"],
    summary="Ki·ªÉm tra s·ª©c kh·ªèe h·ªá th·ªëng",
    description="Th·ª±c hi·ªán truy v·∫•n SQL ƒë∆°n gi·∫£n ƒë·ªÉ ki·ªÉm tra k·∫øt n·ªëi DB v√† t√¨nh tr·∫°ng d·ªãch v·ª•."
)
def health(db: Session = Depends(get_db)):
    try:
        db.execute(text("SELECT 1"))
        return {"ok": True}
    except Exception as e:
        logger.exception("Health check failed")
        return {"ok": False, "error": str(e)}

# =====================================================================
#                       AFFILIATE ‚Äî SAFE SHORTLINK
# =====================================================================

# Secret k√Ω HMAC cho shortlink /r/{token}
AFF_SECRET = os.getenv("AFF_SECRET", "change-me")  # nh·ªõ ƒë·∫∑t trong docker-compose/.env khi ch·∫°y th·∫≠t

# Whitelist domain theo merchant ƒë·ªÉ ch·ªëng open-redirect
ALLOWED_DOMAINS = {
    "shopee": ["shopee.vn", "shopee.sg", "shopee.co.id", "shopee.co.th", "shopee.com.my", "shopee.ph"],
    "lazada": ["lazada.vn", "lazada.co.id", "lazada.co.th", "lazada.com.my", "lazada.sg", "lazada.com.ph"],
    "tiki":   ["tiki.vn"],
}

def _is_allowed_domain(merchant: str, url: str) -> bool:
    try:
        netloc = urlparse(url).netloc.lower()
        return any(netloc.endswith(dom) for dom in ALLOWED_DOMAINS.get(merchant, []))
    except Exception:
        return False

def _apply_template(template: str, target_url: str, params: Optional[Dict[str, str]]) -> str:
    # Encode link g·ªëc v√†o placeholder {target}; c√°c {param} kh√°c thay tr·ª±c ti·∫øp
    aff = template.replace("{target}", quote_plus(target_url))
    if params:
        for k, v in params.items():
            aff = aff.replace("{" + k + "}", str(v))
    return aff

def _make_token(affiliate_url: str, ts: Optional[int] = None) -> str:
    payload = {"u": affiliate_url, "ts": ts or int(time.time())}
    b64 = base64.urlsafe_b64encode(json.dumps(payload).encode()).decode().rstrip("=")
    sig = hmac.new(AFF_SECRET.encode(), b64.encode(), hashlib.sha256).hexdigest()
    return f"{b64}.{sig}"

def _parse_token(token: str) -> str:
    try:
        b64, sig = token.split(".", 1)
        expect = hmac.new(AFF_SECRET.encode(), b64.encode(), hashlib.sha256).hexdigest()
        if not hmac.compare_digest(expect, sig):
            raise ValueError("invalid signature")
        pad = "=" * (-len(b64) % 4)
        payload = json.loads(base64.urlsafe_b64decode(b64 + pad).decode())
        return payload["u"]
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Invalid token: {e}")

# ---------------- CRUD: Links ----------------
@app.get(
    "/links",
    tags=["Links üîó"],
    summary="Danh s√°ch link",
    description="L·∫•y danh s√°ch link ti·∫øp th·ªã t·ª´ DB. H·ªó tr·ª£ ph√¢n trang qua `skip`, `limit`.",
    response_model=list[schemas.AffiliateLinkOut]
)
def read_links(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    return crud.get_links(db, skip=skip, limit=limit)

@app.get(
    "/links/{link_id}",
    tags=["Links üîó"],
    summary="Chi ti·∫øt link",
    description="L·∫•y chi ti·∫øt m·ªôt link ti·∫øp th·ªã theo **ID**.",
    response_model=schemas.AffiliateLinkOut
)
def read_link(link_id: int, db: Session = Depends(get_db)):
    db_link = crud.get_link(db, link_id)
    if db_link is None:
        raise HTTPException(status_code=404, detail="Link not found")
    return db_link

@app.post(
    "/links",
    tags=["Links üîó"],
    summary="Th√™m link m·ªõi",
    description="T·∫°o m·ªõi m·ªôt link ti·∫øp th·ªã v√† l∆∞u v√†o DB.",
    response_model=schemas.AffiliateLinkOut
)
def create_link(link: schemas.AffiliateLinkCreate, db: Session = Depends(get_db)):
    logger.debug("Create link payload: %s", link.model_dump() if hasattr(link, "model_dump") else link.dict())
    return crud.create_link(db, link)

@app.put(
    "/links/{link_id}",
    tags=["Links üîó"],
    summary="C·∫≠p nh·∫≠t link",
    description="C·∫≠p nh·∫≠t th√¥ng tin m·ªôt link ti·∫øp th·ªã theo **ID**.",
    response_model=schemas.AffiliateLinkOut
)
def update_link(link_id: int, link: schemas.AffiliateLinkUpdate, db: Session = Depends(get_db)):
    db_link = crud.update_link(db, link_id, link)
    if db_link is None:
        raise HTTPException(status_code=404, detail="Link not found")
    return db_link

@app.delete(
    "/links/{link_id}",
    tags=["Links üîó"],
    summary="Xo√° link",
    description="Xo√° link ti·∫øp th·ªã theo **ID**."
)
def delete_link(link_id: int, db: Session = Depends(get_db)):
    db_link = crud.delete_link(db, link_id)
    if db_link is None:
        raise HTTPException(status_code=404, detail="Link not found")
    return {"ok": True, "message": "Link deleted"}

# ---------------- CRUD: API Configs ----------------

@app.get(
    "/api-configs",
    tags=["API Configs ‚öôÔ∏è"],
    summary="Danh s√°ch c·∫•u h√¨nh API",
    description="Li·ªát k√™ to√†n b·ªô c·∫•u h√¨nh nh√† cung c·∫•p AI/API.",
    response_model=list[schemas.APIConfigOut]
)
def read_api_configs(db: Session = Depends(get_db)):
    return crud.list_api_configs(db)

@app.post(
    "/api-configs/upsert",
    tags=["API Configs ‚öôÔ∏è"],
    summary="Upsert c·∫•u h√¨nh API",
    description="**T·∫°o m·ªõi ho·∫∑c c·∫≠p nh·∫≠t** c·∫•u h√¨nh d·ª±a tr√™n `name`. Thu·∫≠n ti·ªán ƒë·ªÉ c·∫≠p nh·∫≠t nhanh.",
    response_model=schemas.APIConfigOut
)
def upsert_api_config(config: schemas.APIConfigCreate, db: Session = Depends(get_db)):
    """T·∫°o m·ªõi ho·∫∑c c·∫≠p nh·∫≠t API config theo name."""
    return crud.upsert_api_config_by_name(db, config)

@app.put(
    "/api-configs/{config_id}",
    tags=["API Configs ‚öôÔ∏è"],
    summary="C·∫≠p nh·∫≠t c·∫•u h√¨nh API",
    description="C·∫≠p nh·∫≠t th√¥ng tin c·∫•u h√¨nh theo **ID**.",
    response_model=schemas.APIConfigOut
)
def update_api_config(config_id: int, config: schemas.APIConfigCreate, db: Session = Depends(get_db)):
    db_config = db.query(models.APIConfig).filter(models.APIConfig.id == config_id).first()
    if not db_config:
        raise HTTPException(status_code=404, detail="API config not found")
    db_config.name = config.name
    db_config.base_url = config.base_url
    db_config.api_key = config.api_key
    db_config.model = config.model
    db.commit()
    db.refresh(db_config)
    return db_config

@app.delete(
    "/api-configs/{config_id}",
    tags=["API Configs ‚öôÔ∏è"],
    summary="Xo√° c·∫•u h√¨nh API",
    description="Xo√° c·∫•u h√¨nh nh√† cung c·∫•p theo **ID**."
)
def delete_api_config_route(config_id: int, db: Session = Depends(get_db)):
    deleted = crud.delete_api_config(db, config_id)
    if not deleted:
        raise HTTPException(status_code=404, detail="API config not found")
    return {"ok": True, "deleted_id": config_id, "name": deleted.name}

# ---------------- AI: Suggest/Test ----------------
@app.post(
    "/ai/suggest",
    tags=["AI ü§ñ"],
    summary="AI g·ª£i √Ω theo s·∫£n ph·∫©m trong DB",
    description="Tr·∫£ l·ªùi/g·ª£i √Ω b·∫±ng AI d·ª±a tr√™n danh s√°ch s·∫£n ph·∫©m ƒë√£ ingest."
)
async def ai_suggest(
    query: str,
    provider: str = "groq",
    db: Session = Depends(get_db)
):
    # Gi·ªØ nguy√™n logic g·ªëc
    products = []
    for o in crud.list_offers(db, limit=50):
        desc = None
        if o.extra:
            try:
                desc = json.loads(o.extra).get("desc")
            except:
                pass
        products.append({
            "name": o.title,
            "url": o.url,
            "affiliate_url": o.affiliate_url or o.url,
            "desc": desc
        })
    if not products:
        raise HTTPException(status_code=404, detail="Ch∆∞a c√≥ s·∫£n ph·∫©m n√†o trong DB")
    response = await suggest_products_with_config(query, products, db, provider)
    return {"suggestion": response}

@app.post(
    "/ai/test",
    tags=["AI ü§ñ"],
    summary="Test AI nhanh",
    description="G·ªçi AI v·ªõi c√¢u h·ªèi m·∫´u & 10 s·∫£n ph·∫©m g·∫ßn nh·∫•t trong DB ƒë·ªÉ ki·ªÉm tra nhanh ch·∫•t l∆∞·ª£ng tr·∫£ l·ªùi."
)
async def ai_test(
    query: str = "Gi·ªõi thi·ªáu s·∫£n ph·∫©m t·ªët nh·∫•t tr√™n Shopee",
    provider: str = "groq",
    db: Session = Depends(get_db)
):
    # Gi·ªØ nguy√™n logic g·ªëc
    products = []
    for o in crud.list_offers(db, limit=50):
        desc = None
        if o.extra:
            try:
                desc = json.loads(o.extra).get("desc")
            except:
                pass
        products.append({
            "name": o.title,
            "url": o.url,
            "affiliate_url": o.affiliate_url or o.url,
            "desc": desc
        })
    if not products:
        return {"suggestion": "‚ö†Ô∏è Ch∆∞a c√≥ s·∫£n ph·∫©m n√†o trong DB ƒë·ªÉ g·ª£i √Ω."}
    response = await suggest_products_with_config(query, products, db, provider)
    return {"suggestion": response}

# =====================================================================
#                  NEW: Templates + Convert + Redirect
# =====================================================================

# Upsert template deeplink (m·ªói merchant/network m·ªôt m·∫´u)

@app.get(
    "/aff/templates",
    tags=["Affiliate üéØ"],
    summary="Danh s√°ch m·∫´u deeplink",
    description="Hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß c√°c m·∫´u deeplink hi·ªán c√≥ trong DB.",
    response_model=list[schemas.AffiliateTemplateOut]
)
def list_templates(db: Session = Depends(get_db)):
    return crud.list_affiliate_templates(db)

@app.post(
    "/aff/templates/upsert",
    tags=["Affiliate üéØ"],
    summary="Upsert m·∫´u deeplink",
    description="Th√™m/c·∫≠p nh·∫≠t m·∫´u deeplink cho t·ª´ng **merchant** v√† **network**.",
    response_model=schemas.AffiliateTemplateOut
)
def upsert_template(data: schemas.AffiliateTemplateCreate, db: Session = Depends(get_db)):
    tpl = crud.upsert_affiliate_template(db, data)
    return tpl

@app.put(
    "/aff/templates/{template_id}",
    tags=["Affiliate üéØ"],
    summary="C·∫≠p nh·∫≠t m·∫´u deeplink",
    description="S·ª≠a m·∫´u deeplink theo ID.",
    response_model=schemas.AffiliateTemplateOut
)
def update_template(template_id: int, data: schemas.AffiliateTemplateCreate, db: Session = Depends(get_db)):
    tpl = crud.update_affiliate_template(db, template_id, data)
    if not tpl:
        raise HTTPException(status_code=404, detail="Template not found")
    return tpl

@app.delete(
    "/aff/templates/{template_id}",
    tags=["Affiliate üéØ"],
    summary="Xo√° m·∫´u deeplink",
    description="Xo√° m·∫´u deeplink theo ID."
)
def delete_template(template_id: int, db: Session = Depends(get_db)):
    tpl = crud.delete_affiliate_template_by_id(db, template_id)
    if not tpl:
        raise HTTPException(status_code=404, detail="Template not found")
    return {"ok": True, "deleted_id": template_id}

# Y√™u c·∫ßu convert
class ConvertReq(BaseModel):
    merchant: str
    url: HttpUrl
    network: str = "accesstrade"
    params: Optional[Dict[str, str]] = None  # v√≠ d·ª• {"sub1": "my_subid"}

class ConvertRes(BaseModel):
    affiliate_url: str
    short_url: str

# Convert link g·ªëc -> deeplink + shortlink /r/{token}
@app.post(
    "/aff/convert",
    tags=["Affiliate üéØ"],
    summary="Chuy·ªÉn link g·ªëc ‚Üí deeplink + shortlink",
    description=(
        "Nh·∫≠n link g·ªëc + merchant ‚Üí tr·∫£ v·ªÅ **affiliate_url** (deeplink) v√† **short_url** d·∫°ng `/r/{token}`.\n"
        "H·ªó tr·ª£ merge `default_params` t·ª´ template + `params` ng∆∞·ªùi d√πng truy·ªÅn."
    ),
    response_model=ConvertRes
)
def aff_convert(req: ConvertReq, db: Session = Depends(get_db)):
    if not _is_allowed_domain(req.merchant, str(req.url)):
        raise HTTPException(status_code=400, detail=f"URL kh√¥ng thu·ªôc domain h·ª£p l·ªá c·ªßa {req.merchant}")

    tpl = crud.get_affiliate_template(db, req.merchant, req.network)
    if not tpl:
        raise HTTPException(status_code=404, detail=f"Ch∆∞a c·∫•u h√¨nh template cho merchant={req.merchant}, network={req.network}")

    merged: Dict[str, str] = {}
    if tpl.default_params:
        merged.update(tpl.default_params)
    if req.params:
        merged.update(req.params)

    affiliate_url = _apply_template(tpl.template, str(req.url), merged)
    token = _make_token(affiliate_url)
    short_url = f"/r/{token}"
    return ConvertRes(affiliate_url=affiliate_url, short_url=short_url)

# Redirect t·ª´ shortlink -> deeplink th·∫≠t
@app.get(
    "/r/{token}",
    tags=["Affiliate üéØ"],
    summary="Redirect shortlink",
    description="Gi·∫£i m√£ token v√† chuy·ªÉn h∆∞·ªõng 302 t·ªõi **affiliate_url** th·ª±c t·∫ø."
)
def redirect_short_link(token: str):
    affiliate_url = _parse_token(token)
    return RedirectResponse(url=affiliate_url, status_code=302)

# =====================================================================
#                  NEW (B∆∞·ªõc 3): Ingest/List t·ª´ Accesstrade
# =====================================================================

class IngestReq(BaseModel):
    provider: str = "accesstrade"                 # v√≠ d·ª•: "accesstrade", "adpia", ...
    path: str = "/v1/publishers/product_search"   # tu·ª≥ provider
    params: Dict[str, str] | None = None

class IngestAllDatafeedsReq(BaseModel):
    """
    Ingest to√†n b·ªô datafeeds trong m·ªôt l·∫ßn (t·ª± ph√¢n trang n·ªôi b·ªô).
    - params: c√≥ th·ªÉ truy·ªÅn campaign/domain n·∫øu mu·ªën l·ªçc (vd: {"campaign":"shopee","domain":"shopee.vn"})
    - limit_per_page: k√≠ch th∆∞·ªõc trang khi g·ªçi ra Accesstrade (m·∫∑c ƒë·ªãnh 100)
    - max_pages: ch·∫∑n v√≤ng l·∫∑p v√¥ h·∫°n n·∫øu API tr·∫£ b·∫•t th∆∞·ªùng (m·∫∑c ƒë·ªãnh 2000 trang)
    - throttle_ms: ngh·ªâ gi·ªØa c√°c l·∫ßn g·ªçi ƒë·ªÉ t√¥n tr·ªçng rate-limit (m·∫∑c ƒë·ªãnh 0ms)
    - check_urls: n·∫øu True m·ªõi ki·ªÉm tra link s·ªëng (m·∫∑c ƒë·ªãnh False).
    """
    params: Dict[str, str] | None = None
    limit_per_page: int = 100
    max_pages: int = 2000
    throttle_ms: int = 0
    check_urls: bool = False
    
class CampaignsSyncReq(BaseModel):
    """
    ƒê·ªìng b·ªô campaigns t·ª´ Accesstrade (t·ªëi ∆∞u t·ªëc ƒë·ªô).
    - statuses: danh s√°ch tr·∫°ng th√°i c·∫ßn qu√©t, m·∫∑c ƒë·ªãnh ["running","paused"].
    - only_my: True -> ch·ªâ gi·ªØ approval in {"successful","pending"} (nhanh h∆°n, √≠t ghi DB).
    - enrich_user_status: l·∫•y user_status th·∫≠t t·ª´ campaign detail (ch·∫≠m). M·∫∑c ƒë·ªãnh False ƒë·ªÉ nhanh.
    - limit_per_page, page_concurrency, window_pages, throttle_ms: tinh ch·ªânh t·ªëc ƒë·ªô vs ƒë·ªô ·ªïn ƒë·ªãnh.
    - merchant: n·∫øu truy·ªÅn s·∫Ω l·ªçc theo merchant sau khi fetch.
    """
    statuses: List[str] | None = None
    only_my: bool = True
    enrich_user_status: bool = True
    limit_per_page: int = 50
    page_concurrency: int = 6
    window_pages: int = 10
    throttle_ms: int = 300
    merchant: str | None = None

class IngestV2PromotionsReq(BaseModel):
    """
    Ingest khuy·∫øn m√£i (offers_informations) theo merchant ƒë√£ duy·ªát.
    - merchant: n·∫øu truy·ªÅn, ch·ªâ ingest ƒë√∫ng merchant n√†y; n·∫øu b·ªè tr·ªëng s·∫Ω ch·∫°y cho t·∫•t c·∫£ merchant active.
    - create_offers: n·∫øu True, s·∫Ω map m·ªói promotion th√†nh 1 offer t·ªëi thi·ªÉu (title/url/affiliate_url/image).
    - check_urls: n·∫øu True m·ªõi ki·ªÉm tra link s·ªëng (m·∫∑c ƒë·ªãnh False).
    """
    merchant: str | None = None
    create_offers: bool = True
    check_urls: bool = False

class IngestV2TopProductsReq(BaseModel):
    """
    Ingest top_products (b√°n ch·∫°y) theo merchant & kho·∫£ng ng√†y.
    - date_from/date_to: 'YYYY-MM-DD' (t√πy Accesstrade h·ªó tr·ª£); n·∫øu b·ªè tr·ªëng c√≥ th·ªÉ l·∫•y m·∫∑c ƒë·ªãnh ph√≠a API.
    - limit_per_page: k√≠ch th∆∞·ªõc trang (<=100)
    - max_pages: s·ªë trang t·ªëi ƒëa s·∫Ω qu√©t
    - throttle_ms: ngh·ªâ gi·ªØa c√°c l·∫ßn g·ªçi
    - check_urls: n·∫øu True m·ªõi ki·ªÉm tra link s·ªëng (m·∫∑c ƒë·ªãnh False).
    """
    merchant: str
    date_from: str | None = None
    date_to: str | None = None
    check_urls: bool = False
    limit_per_page: int = 100
    max_pages: int = 200
    throttle_ms: int = 0

from sqlalchemy import func

@app.get("/campaigns/summary", tags=["Campaigns üì¢"])
def campaigns_summary(db: Session = Depends(get_db)):
    total = db.query(func.count(models.Campaign.campaign_id)).scalar() or 0

    by_status = {
        (k or "NULL"): v
        for (k, v) in db.query(models.Campaign.status, func.count())
                        .group_by(models.Campaign.status).all()
    }
    by_user_status = {
        (k or "NULL"): v
        for (k, v) in db.query(models.Campaign.user_registration_status, func.count())
                        .group_by(models.Campaign.user_registration_status).all()
    }

    running_approved_count = (
            db.query(func.count(models.Campaign.campaign_id))
            .filter(models.Campaign.status == "running")
            .filter(models.Campaign.user_registration_status.in_(["APPROVED", "SUCCESSFUL"]))
            .scalar() or 0
    )
    approved_merchants = sorted({
            m for (m,) in db.query(models.Campaign.merchant)
                            .filter(models.Campaign.status == "running")
                            .filter(models.Campaign.user_registration_status.in_(["APPROVED", "SUCCESSFUL"]))
                            .distinct().all()
            if m
    })

    return {
        "total": total,
        "by_status": by_status,
        "by_user_status": by_user_status,
        "running_approved_count": running_approved_count,
        "approved_merchants": approved_merchants
    }

@app.post("/maintenance/normalize-campaigns", tags=["Campaigns üì¢"], summary="Chu·∫©n ho√° d·ªØ li·ªáu campaign (v1 ‚Üí v2)")
def normalize_campaigns(db: Session = Depends(get_db)):
    """
    Di chuy·ªÉn c√°c gi√° tr·ªã 'successful/pending/unregistered' t·ª´ c·ªôt approval
    sang user_registration_status, r·ªìi set approval = NULL.
    """
    rows = db.query(models.Campaign).all()
    moved = 0
    for r in rows:
        val = (r.approval or "").strip().lower() if r.approval else ""
        if val in ("successful", "pending", "unregistered"):
            r.user_registration_status = "APPROVED" if val == "successful" else val.upper()
            r.approval = None
            db.add(r)
            moved += 1
    db.commit()
    return {"ok": True, "moved": moved}

@app.get("/campaigns", response_model=list[schemas.CampaignOut], tags=["Campaigns üì¢"])
def list_campaigns_api(
    status: str | None = None,
    approval: str | None = None,
    user_status: str | None = None,
    merchant: str | None = None,
    db: Session = Depends(get_db),
):
    q = db.query(models.Campaign)
    if status:
        q = q.filter(models.Campaign.status == status)
    # filter ch√≠nh x√°c theo t√†i li·ªáu: approval = unregistered/pending/successful
    if approval:
        q = q.filter(models.Campaign.approval == approval)
    # h·ªó tr·ª£ user_status: ∆∞u ti√™n c·ªôt user_registration_status; n·∫øu NULL m·ªõi fallback v·ªÅ approval map
    if user_status:
        us = user_status.strip().upper()
        fallback = {
            "APPROVED": "successful",
            "PENDING": "pending",
            "NOT_REGISTERED": "unregistered",
        }.get(us)
        if fallback:
            q = q.filter(
                or_(
                    models.Campaign.user_registration_status == us,
                    and_(models.Campaign.user_registration_status == None,
                         models.Campaign.approval == fallback)
                )
            )
        else:
            q = q.filter(models.Campaign.user_registration_status == us)
    if merchant:
        q = q.filter(models.Campaign.merchant == merchant)
    return q.order_by(models.Campaign.updated_at.desc()).all()

@app.get("/campaigns/approved-merchants", response_model=list[str], tags=["Campaigns üì¢"])
def list_approved_merchants_api(db: Session = Depends(get_db)):
    rows = (
        db.query(models.Campaign.merchant)
        .filter(models.Campaign.status == "running")
        .filter(or_(
            models.Campaign.user_registration_status == "APPROVED",
            models.Campaign.user_registration_status == "SUCCESSFUL",
        ))
        .distinct()
        .all()
    )
    merchants = sorted({m for (m,) in rows if m})
    return merchants

@app.get("/offers", response_model=list[schemas.ProductOfferOut], tags=["Offers üõí"])
def list_offers_api(
    merchant: str | None = None,
    skip: int = 0,
    limit: int = 50,
    db: Session = Depends(get_db)
):
    """
    üõí L·∫•y danh s√°ch s·∫£n ph·∫©m trong DB c√≥ ph√¢n trang  
    - `merchant`: l·ªçc theo t√™n merchant (vd: `shopee`, `lazada`, `tiki`)  
    - `skip`: s·ªë b·∫£n ghi b·ªè qua (offset)  
    - `limit`: s·ªë b·∫£n ghi t·ªëi ƒëa tr·∫£ v·ªÅ  
    """
    rows = crud.list_offers(db, merchant=merchant, skip=skip, limit=limit)

    out: list[dict] = []
    for o in rows:
        item = {
            "id": o.id,
            "title": o.title,
            "url": o.url,
            "affiliate_url": o.affiliate_url,
            "image_url": o.image_url,
            "merchant": o.merchant,
            "campaign_id": o.campaign_id,
            "price": o.price,
            "currency": o.currency,
            # Model kh√¥ng c√≥ 'status'; gi·ªØ key cho t∆∞∆°ng th√≠ch, map sang approval_status
            "status": getattr(o, "status", None) or o.approval_status,
            "approval_status": o.approval_status,
            "eligible_commission": o.eligible_commission,
            "source_type": o.source_type,
            "affiliate_link_available": o.affiliate_link_available,
            "product_id": o.product_id,
            "extra": o.extra,
            "updated_at": o.updated_at,
            "desc": None, "cate": None, "shop_name": None, "update_time_raw": None,
        }

        try:
            ex = json.loads(o.extra) if o.extra else {}
            item["desc"] = ex.get("desc")
            item["cate"] = ex.get("cate")
            item["shop_name"] = ex.get("shop_name")
            item["update_time_raw"] = ex.get("update_time_raw") or ex.get("update_time")
        except Exception:
            pass
        out.append(item)

    return out

@app.post(
    "/ingest/policy",
    tags=["Offers üõí"],
    summary="C·∫•u h√¨nh policy ingest",
    description="B·∫≠t/t·∫Øt ch·∫ø ƒë·ªô ch·ªâ ingest s·∫£n ph·∫©m c√≥ commission policy."
)
def set_ingest_policy(only_with_commission: bool = False, db: Session = Depends(get_db)):
    model_str = f"only_with_commission={'true' if only_with_commission else 'false'}"
    cfg = crud.upsert_api_config_by_name(db, schemas.APIConfigCreate(
        name="ingest_policy",
        base_url="-",
        api_key="-",
        model=model_str,
    ))
    return {"ok": True, "ingest_policy": model_str, "config_id": cfg.id}

@app.post(
    "/ingest/policy/check-urls",
    tags=["Offers üõí"],
    summary="B·∫≠t/t·∫Øt ki·ªÉm tra link khi IMPORT EXCEL",
    description="Ch·ªâ ·∫£nh h∆∞·ªüng import Excel. API ingest (V1/V2) lu√¥n m·∫∑c ƒë·ªãnh KH√îNG check link."
)
def set_ingest_policy_check_urls(enable: bool = False, db: Session = Depends(get_db)):
    # d√πng store flags trong api_configs.name='ingest_policy'
    crud.set_policy_flag(db, "check_urls", enable)
    flags = crud.get_policy_flags(db)
    return {"ok": True, "flags": flags}

@app.post(
    "/ingest/products",
    tags=["Offers üõí"],
    summary="Ingest s·∫£n ph·∫©m t·ª´ nhi·ªÅu provider",
    description=(
        "Nh·∫≠p s·∫£n ph·∫©m v√†o DB t·ª´ nhi·ªÅu provider (v√≠ d·ª•: Accesstrade). "
        "Hi·ªán h·ªó tr·ª£ `provider=accesstrade`. C√°c provider kh√°c c√≥ th·ªÉ b·ªï sung sau."
    )
)
async def ingest_products(
    req: IngestReq,
    db: Session = Depends(get_db),
):

    provider = (req.provider or "accesstrade").lower()

    # --- Provider: Accesstrade (ƒë√£ h·ªó tr·ª£) ---
    if provider == "accesstrade":
        from accesstrade_service import fetch_active_campaigns, fetch_campaign_detail
        active_campaigns = await fetch_active_campaigns(db)
        logger.info("Fetched %d active campaigns", len(active_campaigns))
        merchant_campaign_map = {v: k for k, v in active_campaigns.items()}

        items = await fetch_products(db, req.path, req.params or {})
        if not items:
            return {"ok": True, "imported": 0}

        # API ingest b·ªè qua policy; policy ch·ªâ √°p d·ª•ng cho import Excel
        only_with_commission = False

        imported = 0
        for it in items:
            camp_id = str(it.get("campaign_id") or it.get("campaign_id_str") or "").strip()
            merchant = str(it.get("merchant") or it.get("campaign") or "").lower().strip()
            # Chu·∫©n ho√° merchant ƒë·ªÉ kh·ªõp v·ªõi merchant_campaign_map (vd: "shopee.vn" -> "shopee")
            _alias = {"lazadacps": "lazada", "tikivn": "tiki"}
            merchant_norm = _alias.get(merchant, merchant.split(".")[0] if "." in merchant else merchant)

            def _resolve_campaign_id_by_suffix(m_name: str) -> tuple[str | None, str]:
                if m_name in merchant_campaign_map:
                    return merchant_campaign_map[m_name], "exact"
                for m_key, cid in merchant_campaign_map.items():
                    if m_key.endswith(m_name) or f"_{m_name}" in m_key:
                        return cid, f"suffix({m_key})"
                for m_key, cid in merchant_campaign_map.items():
                    if m_name in m_key:
                        return cid, f"contains({m_key})"
                return None, ""

            if not camp_id:
                camp_id, how = _resolve_campaign_id_by_suffix(merchant_norm)
                if camp_id:
                    logger.debug("Fallback campaign_id=%s via %s cho merchant=%s (norm=%s) [manual ingest]",
                                camp_id, how, merchant, merchant_norm)

            # Ch·ªâ ingest n·∫øu campaign_id thu·ªôc campaign ƒëang ch·∫°y
            if not camp_id or camp_id not in active_campaigns:
                logger.info("Skip product v√¨ campaign_id=%s kh√¥ng active [manual ingest] (merchant=%s)", camp_id, merchant_norm)
                continue
            
            # Y√äU C·∫¶U: user APPROVED (API ingest b·ªè qua policy, nh∆∞ng v·∫´n c·∫ßn APPROVED)
            try:
                _row = crud.get_campaign_by_cid(db, camp_id)
                if not _row or (_row.user_registration_status or "").upper() != "APPROVED":
                    logger.info("Skip product v√¨ campaign_id=%s ch∆∞a APPROVED [manual ingest]", camp_id)
                    continue
            except Exception:
                continue

            # 1) Commission hi·ªán ch∆∞a d√πng ƒë·ªÉ l·ªçc/ghi ri√™ng
            commission_data = None

            # 2) Promotions theo merchant (v·ª´a enrich extra, v·ª´a ghi b·∫£ng promotions)
            promotions_data = await fetch_promotions(db, merchant_norm) if merchant_norm else []
            if promotions_data:
                # NEW: upsert promotions theo campaign_id
                for prom in promotions_data:
                    try:
                        crud.upsert_promotion(db, schemas.PromotionCreate(
                            campaign_id=camp_id,
                            name=prom.get("name"),
                            content=prom.get("content") or prom.get("description"),
                            start_time=prom.get("start_time"),
                            end_time=prom.get("end_time"),
                            coupon=prom.get("coupon"),
                            link=prom.get("link"),
                        ))
                    except Exception as e:
                        logger.debug("Skip promotion upsert: %s", e)

            # 3) Campaign detail (ƒë·ªÉ c√≥ approval/status/time & tr·∫°ng th√°i ƒëƒÉng k√Ω user)
            try:
                camp = await fetch_campaign_detail(db, camp_id)
                if camp:
                    status_val = camp.get("status")
                    approval_val = camp.get("approval")
                    # KH√îNG default "unregistered" khi API kh√¥ng tr·∫£ user_status
                    _user_raw = (
                        camp.get("user_registration_status")
                        or camp.get("publisher_status")
                        or camp.get("user_status")
                    )
                    def _map_status(v):
                        s = str(v).strip() if v is not None else None
                        if s == "1": return "running"
                        if s == "0": return "paused"
                        return s
                    crud.upsert_campaign(db, schemas.CampaignCreate(
                        campaign_id=str(camp.get("campaign_id") or camp_id),
                        merchant=str(camp.get("merchant") or merchant_norm or "").lower() or None,
                        name=camp.get("name"),
                        status=_map_status(status_val),
                        approval=(str(approval_val) if approval_val is not None else None),
                        start_time=camp.get("start_time"),
                        end_time=camp.get("end_time"),
                        user_registration_status=(_user_raw if _user_raw not in (None, "", []) else None),
                    ))
            except Exception as e:
                logger.debug("Skip campaign upsert: %s", e)

            # 4) Commission policies (ghi b·∫£ng commission_policies) + eligibility fallback
            try:
                policies = await fetch_commission_policies(db, camp_id)
                for rec in (policies or []):
                    crud.upsert_commission_policy(db, schemas.CommissionPolicyCreate(
                        campaign_id=camp_id,
                        reward_type=rec.get("reward_type") or rec.get("type"),
                        sales_ratio=rec.get("sales_ratio") or rec.get("ratio"),
                        sales_price=rec.get("sales_price"),
                        target_month=rec.get("target_month"),
                    ))

                if only_with_commission:
                    # Fallback gi·ªëng /ingest/accesstrade/datafeeds/all:
                    # n·∫øu campaign ƒëang running + user APPROVED th√¨ coi nh∆∞ "c√≥ commission"
                    eligible_by_status = False
                    try:
                        _camp_row = crud.get_campaign_by_cid(db, camp_id)
                        if _camp_row:
                            _us = (_camp_row.user_registration_status or "").upper()
                            eligible_by_status = (_camp_row.status == "running") and (_us == "APPROVED")
                    except Exception:
                        eligible_by_status = False

                    has_commission = bool(policies) or eligible_by_status
                    if not has_commission:
                        logger.info(
                            "Skip product v√¨ campaign_id=%s kh√¥ng c√≥ commission policy v√† ch∆∞a ƒë·ªß ƒëi·ªÅu ki·ªán (policy.only_with_commission=true)",
                            camp_id
                        )
                        continue

            except Exception as e:
                logger.debug("Skip commission upsert: %s", e)

            # 5) Map + enrich extra tr√™n product_offers
            commission_data = policies  # d√πng ch√≠nh policies v·ª´a fetch
            data = map_at_product_to_offer(it, commission=commission_data, promotion=promotions_data)
            if not data.get("url") or not data.get("source_id"):
                continue

            # B·ªï sung campaign_id r√µ r√†ng
            data["campaign_id"] = camp_id

            # NEW: g·∫Øn lo·∫°i ngu·ªìn + tr·∫°ng th√°i ph√™ duy·ªát & eligibility
            data["source_type"] = "manual"
            _camp_row = crud.get_campaign_by_cid(db, camp_id)
            if _camp_row:
                us = (_camp_row.user_registration_status or "").upper()
                data["approval_status"] = (
                    "successful" if us == "APPROVED" else
                    "pending" if us == "PENDING" else
                    "unregistered" if us == "NOT_REGISTERED" else None
                )
                data["eligible_commission"] = (
                    (_camp_row.status == "running") and (us in ("APPROVED", "SUCCESSFUL"))
                )

            # 6) Ch·ªâ check link g·ªëc ƒë·ªÉ tr√°nh click ·∫£o
            if not await _check_url_alive(data["url"]):
                logger.info("Skip dead product [manual ingest]: title='%s'", data.get("title"))
                continue

            # 7) Ghi/Update product_offers
            crud.upsert_offer_by_source(db, schemas.ProductOfferCreate(**data))
            imported += 1

        return {"ok": True, "imported": imported}

    raise HTTPException(status_code=400, detail=f"Provider '{provider}' hi·ªán ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£")

@app.post(
    "/ingest/accesstrade/datafeeds/all",
    tags=["Offers üõí"],
    summary="Ingest TO√ÄN B·ªò datafeeds (t·ª± ph√¢n trang)",
    description=(
        "G·ªçi Accesstrade /v1/datafeeds nhi·ªÅu l·∫ßn (page=1..N) cho ƒë·∫øn khi h·∫øt d·ªØ li·ªáu, "
        "kh√¥ng y√™u c·∫ßu client truy·ªÅn page/limit."
    )
)
async def ingest_accesstrade_datafeeds_all(
    req: IngestAllDatafeedsReq,
    db: Session = Depends(get_db),
):

    # D√πng lu√¥n session `db` t·ª´ Depends; kh√¥ng m·ªü/ƒë√≥ng session m·ªõi t·∫°i ƒë√¢y
    from accesstrade_service import fetch_campaigns_full_all, fetch_campaign_detail
    items = await fetch_campaigns_full_all(
        db,
        status="running",
        limit_per_page=req.limit_per_page or 100,
        max_pages=req.max_pages or 200,
        throttle_ms=req.throttle_ms or 0
    )
    imported = 0
    for camp in (items or []):
        try:
            camp_id = str(camp.get("campaign_id") or camp.get("id") or "").strip()
            merchant = str(camp.get("merchant") or camp.get("name") or "").lower().strip()
            status_val = camp.get("status")
            approval_val = camp.get("approval")

            # map status "1/0" -> "running/paused" n·∫øu API tr·∫£ d·∫°ng s·ªë
            def _map_status(v):
                s = str(v).strip() if v is not None else None
                if s == "1": return "running"
                if s == "0": return "paused"
                return s

            # T√°ch approval (ki·ªÉu duy·ªát campaign) ‚Üî user_status (tr·∫°ng th√°i ƒëƒÉng k√Ω c·ªßa ri√™ng m√¨nh)
            def _split_approval_or_user(v):
                if v is None:
                    return (None, None)
                s = str(v).strip().lower()
                if s in ("successful", "pending", "unregistered"):
                    # ƒê√¢y th·ª±c ch·∫•t l√† tr·∫°ng th√°i ƒëƒÉng k√Ω c·ªßa b·∫°n
                    user = "APPROVED" if s == "successful" else s.upper()
                    return (None, user)
                return (str(v), None)

            approval_for_campaign, user_status = _split_approval_or_user(approval_val)

            # NEW: n·∫øu API kh√¥ng cung c·∫•p user_status, d√πng gi√° tr·ªã c≈© trong DB ƒë·ªÉ tr√°nh m·∫•t record
            existing = crud.get_campaign_by_cid(db, camp_id)
            eff_user = user_status or (existing.user_registration_status if existing else None)

            # L·ªçc: ch·ªâ gi·ªØ APPROVED/PENDING
            if eff_user not in ("APPROVED", "PENDING"):
                continue
            # Kh√¥ng enrich ·ªü job ƒë·ªãnh k·ª≥ ƒë·ªÉ nhanh (c√≥ th·ªÉ b·∫≠t ·ªü API /ingest/v2/campaigns/sync)

            payload = schemas.CampaignCreate(
                campaign_id=camp_id,
                merchant=merchant or None,
                name=camp.get("name"),
                status=_map_status(status_val),
                approval=approval_for_campaign,                 # KH√îNG c√≤n ghi 'successful/pending/unregistered' ·ªü ƒë√¢y
                start_time=camp.get("start_time"),
                end_time=camp.get("end_time"),
                user_registration_status=user_status,           # NOT_REGISTERED/PENDING/APPROVED ho·∫∑c None
            )

            crud.upsert_campaign(db, payload)
            imported += 1
        except Exception as e:
            logger.debug("Skip campaign upsert: %s", e)

    logger.info("Scheduled campaigns sync done: %s", imported)

    from accesstrade_service import (
        fetch_products, fetch_active_campaigns, fetch_promotions,
        fetch_commission_policies, fetch_campaign_detail,
        map_at_product_to_offer, _check_url_alive
    )

    # 0) L·∫•y danh s√°ch campaign ƒëang ch·∫°y ƒë·ªÉ l·ªçc
    active_campaigns = await fetch_active_campaigns(db)  # dict {campaign_id: merchant}
    merchant_campaign_map = {v: k for k, v in active_campaigns.items()}  # {merchant: campaign_id}

    # ch√≠nh s√°ch ingest (API b·ªè qua policy; policy ch·ªâ √°p d·ª•ng cho import Excel)
    only_with_commission = False

    # 2) Cache promotions theo merchant ƒë·ªÉ tr√°nh g·ªçi tr√πng
    promotion_cache: dict[str, list[dict]] = {}

    # NEW: Cache commission theo campaign_id ƒë·ªÉ tr√°nh spam API (fix NameError)
    cache_commissions: dict[str, list[dict]] = {}

    # 3) Tham s·ªë g·ªçi API datafeeds
    base_params = dict(req.params or {})
    base_params.pop("page", None)   # client kh√¥ng c·∫ßn truy·ªÅn
    base_params.pop("limit", None)  # client kh√¥ng c·∫ßn truy·ªÅn

    imported = 0
    total_pages = 0
    page = 1

    while page <= max(1, req.max_pages):
        params = dict(base_params)
        params["page"]  = str(page)
        params["limit"] = str(req.limit_per_page)

        items = await fetch_products(db, "/v1/datafeeds", params)
        if not items:
            break
        total_pages += 1

        for it in items:
            # L·∫•y campaign/merchant t·ª´ record
            camp_id = str(it.get("campaign_id") or it.get("campaign_id_str") or "").strip()
            merchant = str(it.get("merchant") or it.get("campaign") or "").lower().strip()
            _base = merchant.split(".")[0] if "." in merchant else merchant
            _alias = {"lazadacps": "lazada", "tikivn": "tiki"}
            merchant_norm = _alias.get(_base, _base)

            # Fallback campaign_id theo merchant n·∫øu thi·∫øu
            if not camp_id:
                # exact
                if merchant_norm in merchant_campaign_map:
                    camp_id = merchant_campaign_map[merchant_norm]
                else:
                    # suffix match ki·ªÉu "xxx_shopee" ho·∫∑c "..._shopee"
                    for m_key, cid in merchant_campaign_map.items():
                        if m_key.endswith(merchant_norm) or f"_{merchant_norm}" in m_key:
                            camp_id = cid
                            break
                    if not camp_id:
                        # contains match (vd: 'lazada' ‚äÇ 'lazadacps')
                        for m_key, cid in merchant_campaign_map.items():
                            if merchant_norm in m_key:
                                camp_id = cid
                                break

            # B·ªè qua n·∫øu campaign kh√¥ng active
            if not camp_id or camp_id not in active_campaigns:
                continue
            # Y√äU C·∫¶U: user APPROVED (API ingest b·ªè qua policy, nh∆∞ng v·∫´n c·∫ßn APPROVED)
            try:
                _row = crud.get_campaign_by_cid(db, camp_id)
                if not _row or (_row.user_registration_status or "").upper() != "APPROVED":
                    continue
            except Exception:
                continue

            # L·∫•y commission theo camp_id (cache ƒë·ªÉ tr√°nh spam API)
            policies = cache_commissions.get(camp_id)
            if policies is None:
                try:
                    policies = await fetch_commission_policies(db, camp_id)
                    cache_commissions[camp_id] = policies or []
                    for p in (policies or []):
                        crud.upsert_commission_policy(db, schemas.CommissionPolicyCreate(
                            campaign_id=str(camp_id),
                            reward_type=p.get("reward_type") or p.get("type"),
                            sales_ratio=p.get("sales_ratio") or p.get("ratio"),
                            sales_price=p.get("sales_price"),
                            target_month=p.get("target_month"),
                        ))
                except Exception:
                    policies = []
                    logger.debug("Skip commission upsert")
            # B·∫≠t policy: ch·ªâ ingest khi c√≥ commission (gi·∫£ ƒë·ªãnh m·ªõi: campaign ƒëang ch·∫°y + user APPROVED ƒë∆∞·ª£c xem l√† c√≥ commission)
            if only_with_commission:
                eligible_by_status = False
                try:
                    _camp_row = crud.get_campaign_by_cid(db, camp_id)
                    if _camp_row:
                        _us = (_camp_row.user_registration_status or "").upper()
                        eligible_by_status = (_camp_row.status == "running") and (_us == "APPROVED")
                except Exception:
                    eligible_by_status = False

                has_commission = bool(policies) or eligible_by_status
                if not has_commission:
                    continue

            # Promotions: l·∫•y theo merchant, c√≥ cache + upsert DB
            if merchant_norm not in promotion_cache:
                promotion_cache[merchant_norm] = await fetch_promotions(db, merchant_norm) or []
            pr_list = promotion_cache.get(merchant_norm, [])
            if pr_list:
                for prom in pr_list:
                    try:
                        crud.upsert_promotion(db, schemas.PromotionCreate(
                            campaign_id=camp_id,
                            name=prom.get("name"),
                            content=prom.get("content") or prom.get("description"),
                            start_time=prom.get("start_time"),
                            end_time=prom.get("end_time"),
                            coupon=prom.get("coupon"),
                            link=prom.get("link"),
                        ))
                    except Exception as e:
                        logger.debug("Skip promotion upsert: %s", e)

            # Campaign detail: ƒë·ªìng nh·∫•t upsert
            try:
                camp = await fetch_campaign_detail(db, camp_id)
                if camp:
                    status_val = camp.get("status")
                    approval_val = camp.get("approval")

                    def _map_status(v):
                        s = str(v).strip() if v is not None else None
                        if s == "1": return "running"
                        if s == "0": return "paused"
                        return s

                    _user_raw = (
                        camp.get("user_registration_status")
                        or camp.get("publisher_status")
                        or camp.get("user_status")
                    )
                    crud.upsert_campaign(db, schemas.CampaignCreate(
                        campaign_id=str(camp.get("campaign_id") or camp_id),
                        merchant=str(camp.get("merchant") or merchant_norm or "").lower() or None,
                        name=camp.get("name"),
                        status=_map_status(status_val),
                        approval=(str(approval_val) if approval_val is not None else None),
                        start_time=camp.get("start_time"),
                        end_time=camp.get("end_time"),
                        user_registration_status=(_user_raw if _user_raw not in (None, "", []) else None),
                    ))

            except Exception as e:
                logger.debug("Skip campaign upsert: %s", e)

            # Chu·∫©n ho√° record ‚Üí ProductOfferCreate (nh√∫ng commission ƒë·ªÉ extra c√≥ d·ªØ li·ªáu)
            data = map_at_product_to_offer(it, commission=policies, promotion=pr_list)
            if not data or not data.get("url"):
                continue
            data["campaign_id"] = camp_id

            # NEW: g·∫Øn lo·∫°i ngu·ªìn + tr·∫°ng th√°i ph√™ duy·ªát & eligibility
            data["source_type"] = "datafeeds"
            _camp_row = crud.get_campaign_by_cid(db, camp_id)
            if _camp_row:
                us = (_camp_row.user_registration_status or "").upper()
                data["approval_status"] = (
                    "successful" if us == "APPROVED" else
                    "pending" if us == "PENDING" else
                    "unregistered" if us == "NOT_REGISTERED" else None
                )
                data["eligible_commission"] = (
                    (_camp_row.status == "running") and (us in ("APPROVED", "SUCCESSFUL"))
                )

            # Link g·ªëc ph·∫£i "s·ªëng"
            if not await _check_url_alive(data["url"]):
                continue

            # Ghi/Update product_offers
            crud.upsert_offer_by_source(db, schemas.ProductOfferCreate(**data))
            imported += 1

        # Early stop n·∫øu trang hi·ªán t·∫°i √≠t h∆°n limit -> c√≥ th·ªÉ l√† trang cu·ªëi
        if len(items) < (req.limit_per_page or 100):
            total_pages += 1
            break

        # Ti·∫øp trang
        page += 1
        total_pages += 1
        sleep_ms = getattr(req, "throttle_ms", 0) or 0
        if sleep_ms:
            await asyncio.sleep(sleep_ms / 1000.0)

    return {"ok": True, "imported": imported, "pages": total_pages}

@app.post(
    "/ingest/v2/campaigns/sync",
    tags=["Campaigns üì¢"],
    summary="ƒê·ªìng b·ªô danh s√°ch campaigns t·ª´ Accesstrade",
    description="L∆∞u/ c·∫≠p nh·∫≠t campaigns v√†o DB ƒë·ªÉ l√†m chu·∫©n eligibility v√† theo d√µi."
)
async def ingest_v2_campaigns_sync(
    req: CampaignsSyncReq,
    db: Session = Depends(get_db),
):
    from accesstrade_service import fetch_campaigns_full_all, fetch_campaign_detail

    # --- gom d·ªØ li·ªáu theo nhi·ªÅu tr·∫°ng th√°i (running/paused/...) n·∫øu ƒë∆∞·ª£c truy·ªÅn ---
    statuses = (req.statuses or ["running"])  # m·∫∑c ƒë·ªãnh ch·ªâ 'running' ƒë·ªÉ nhanh; b·∫°n c√≥ th·ªÉ g·ª≠i ["running","paused"]
    unique = {}
    for st in statuses:
        try:
            items = await fetch_campaigns_full_all(
                db,
                status=st,
                limit_per_page=req.limit_per_page or 50,
                max_pages=1000,
                throttle_ms=req.throttle_ms or 0,
                page_concurrency=req.page_concurrency or 6,
                window_pages=req.window_pages or 10,
            )
            for it in (items or []):
                cid = str(it.get("campaign_id") or it.get("id") or "").strip()
                if cid:
                    unique[cid] = it
        except Exception as e:
            logger.error("ingest_v2_campaigns_sync: fetch failed (%s): %s", st, e)

    imported = 0

    def _map_status(v):
        s = str(v).strip() if v is not None else None
        if s == "1": return "running"
        if s == "0": return "paused"
        return s

    def _split_approval_or_user(v):
        """
        N·∫øu AT tr·∫£ 'approval' ‚àà {successful,pending,unregistered} th√¨ ƒë√¢y th·ª±c ch·∫•t l√† user_status.
        Tr·∫£ v·ªÅ tuple: (approval_for_campaign, user_status_for_me)
        """
        if v is None:
            return (None, None)
        s = str(v).strip().lower()
        if s in ("successful", "pending", "unregistered"):
            # map v·ªÅ NOT_REGISTERED/PENDING/APPROVED
            user = "APPROVED" if s == "successful" else s.upper()
            return (None, user)
        # c√≤n l·∫°i ƒë·ªÉ nguy√™n cho ki·ªÉu duy·ªát (auto/manual/‚Ä¶)
        return (str(v), None)

    for camp in unique.values():
        try:
            camp_id = str(camp.get("campaign_id") or camp.get("id") or "").strip()
            merchant = str(camp.get("merchant") or camp.get("name") or "").lower().strip()
            if req.merchant and merchant != req.merchant.strip().lower():
                continue

            status_val = _map_status(camp.get("status"))
            approval_val, user_status = _split_approval_or_user(camp.get("approval"))

            # enrich user_status t·ª´ detail n·∫øu b·∫≠t c·ªù (ch√≠nh x√°c h∆°n)
            if req.enrich_user_status or (req.only_my and not user_status):
                try:
                    det = await fetch_campaign_detail(db, camp_id)
                    if det:
                        _user_raw = (
                            det.get("user_registration_status")
                            or det.get("publisher_status")
                            or det.get("user_status")
                        )
                        # Fallback: ƒë√¥i khi detail ch·ªâ tr·∫£ 'approval' = successful/pending/unregistered
                        if not _user_raw:
                            appr_det = det.get("approval")
                            if isinstance(appr_det, str) and appr_det.lower() in ("successful","pending","unregistered"):
                                _user_raw = "APPROVED" if appr_det.lower() == "successful" else appr_det.upper()
                        if _user_raw not in (None, "", []):
                            user_status = str(_user_raw).strip().upper()
                except Exception:
                    pass

            # L·ªçc only_my: ch·ªâ gi·ªØ APPROVED/PENDING.
            # N·∫øu ƒë√£ b·∫≠t enrich_user_status nh∆∞ng v·∫´n KH√îNG l·∫•y ƒë∆∞·ª£c user_status (API kh√¥ng tr·∫£),
            # cho ph√©p import ƒë·ªÉ l∆∞u l·∫°i tr∆∞·ªõc (tr√°nh imported=0 ·ªü l·∫ßn ƒë·∫ßu).
            if req.only_my:
                existing = crud.get_campaign_by_cid(db, camp_id)
                eff_user = user_status or (existing.user_registration_status if existing else None)
                if eff_user not in ("APPROVED", "PENDING"):
                    if req.enrich_user_status and eff_user is None:
                        logger.debug("only_my=true: allow %s (%s) d√π user_status ch∆∞a r√µ (first-run).", camp_id, merchant)
                    else:
                        logger.debug("only_my=true: skip %s (%s) v√¨ user_status=%s", camp_id, merchant, eff_user)
                        continue

            payload = schemas.CampaignCreate(
                campaign_id=camp_id,
                merchant=merchant or None,
                name=camp.get("name"),
                status=status_val,
                approval=approval_val,                  # KH√îNG c√≤n ghi 'successful' ·ªü ƒë√¢y n·ªØa
                start_time=camp.get("start_time"),
                end_time=camp.get("end_time"),
                user_registration_status=user_status,   # NOT_REGISTERED / PENDING / APPROVED / None
            )
            crud.upsert_campaign(db, payload)
            imported += 1
        except Exception as e:
            logger.debug("Skip campaign upsert: %s", e)

    return {"ok": True, "imported": imported}

@app.post(
    "/ingest/v2/promotions",
    tags=["Offers üõí"],
    summary="Ingest khuy·∫øn m√£i (offers_informations) cho merchant ƒë√£ duy·ªát",
    description="ƒê·ªìng b·ªô promotions v√† (t√πy ch·ªçn) map th√†nh offers t·ªëi thi·ªÉu ƒë·ªÉ hi·ªÉn th·ªã."
)
async def ingest_v2_promotions(
    req: IngestV2PromotionsReq,
    db: Session = Depends(get_db),
):
    from accesstrade_service import fetch_promotions, fetch_active_campaigns, _check_url_alive
    imported_promos = 0
    imported_offers = 0

    # 0) X√°c ƒë·ªãnh merchant c·∫ßn ch·∫°y: 1 merchant ho·∫∑c t·∫•t c·∫£ merchant ƒëang active
    active = await fetch_active_campaigns(db)  # {campaign_id: merchant}
    merchants = set(active.values())
    if req.merchant:
        merchants = {req.merchant.strip().lower()}

    # 1) V√≤ng l·∫∑p t·ª´ng merchant
    for m in sorted(merchants):
        _alias = {"lazadacps": "lazada", "tikivn": "tiki"}
        m_fetch = _alias.get(m, m)
        promos = await fetch_promotions(db, m_fetch) or []
        # upsert b·∫£ng promotions
        for p in promos:
            try:
                # map campaign_id t·ª´ merchant
                # ∆∞u ti√™n exact, n·∫øu kh√¥ng c√≥ th√¨ b·ªè tr·ªëng
                campaign_id = None
                # ∆Øu ti√™n exact theo m ho·∫∑c m_fetch
                for cid, mm in active.items():
                    mm_l = (mm or "").lower()
                    if mm_l == m or mm_l == m_fetch:
                        campaign_id = cid
                        break
                # N·∫øu ch∆∞a kh·ªõp, th·ª≠ suffix/contains (ƒë·ª° l·ªách alias)
                if not campaign_id:
                    for cid, mm in active.items():
                        mm_l = (mm or "").lower()
                        if mm_l.endswith(m) or f"_{m}" in mm_l or (m in mm_l):
                            campaign_id = cid
                            break
                if not campaign_id and m_fetch != m:
                    for cid, mm in active.items():
                        mm_l = (mm or "").lower()
                        if mm_l.endswith(m_fetch) or f"_{m_fetch}" in mm_l or (m_fetch in mm_l):
                            campaign_id = cid
                            break

                crud.upsert_promotion(db, schemas.PromotionCreate(
                    campaign_id=campaign_id or "",
                    name=p.get("name"),
                    content=p.get("content") or p.get("description"),
                    start_time=p.get("start_time"),
                    end_time=p.get("end_time"),
                    coupon=p.get("coupon"),
                    link=p.get("link"),
                ))
                imported_promos += 1

                if req.create_offers:
                    # map promotion -> offer t·ªëi thi·ªÉu
                    title = p.get("name") or "Khuy·∫øn m√£i"
                    link = p.get("link") or p.get("url")
                    aff = p.get("aff_link")
                    img = p.get("image") or p.get("thumb") or p.get("banner")

                    # CHO PH√âP T·∫†O OFFER KHI CH·ªà C√ì aff_link
                    if not link and not aff:
                        logger.debug("[PROMO] skip: no link/aff for %s (merchant=%s)", title, m)
                        continue

                    url_to_check = link or aff

                    # (policy) ch·ªâ check khi b·∫≠t c·ªù
                    alive = True if not req.check_urls else await _check_url_alive(url_to_check)
                    if not alive:
                        logger.debug("[PROMO] skip: dead url %s", url_to_check)
                        continue

                    # source_id c·ªë ƒë·ªãnh theo link/aff_link ƒë·ªÉ idempotent
                    sid_base = (link or aff or "").encode("utf-8")
                    sid = hashlib.md5(sid_base).hexdigest()
                    extra = {
                        "source_type": "promotions",
                        "raw": p,
                    }
                    # Ch·ªâ t·∫°o offer n·∫øu campaign ƒë√£ duy·ªát (SUCCESSFUL/APPROVED)
                    try:
                        _row = crud.get_campaign_by_cid(db, campaign_id) if campaign_id else None
                        _user = (_row.user_registration_status or "").upper() if _row else ""
                        if not _row or _user not in ("APPROVED", "SUCCESSFUL"):
                            continue
                    except Exception:
                        continue

                    payload = schemas.ProductOfferCreate(
                        source="accesstrade",
                        source_id=f"promo:{m}:{sid}",
                        merchant=m,
                        title=title,
                        url=link,
                        affiliate_url=aff,
                        image_url=img,
                        price=None,
                        currency="VND",
                        campaign_id=campaign_id,
                        source_type="promotions",
                        # eligible_commission = campaign ƒëang ch·∫°y & user APPROVED/SUCCESSFUL (d√πng _row ƒë√£ truy v·∫•n tr∆∞·ªõc ƒë√≥)
                        eligible_commission=bool(
                            _row
                            and _row.status == "running"
                            and (_row.user_registration_status or "").upper() in ("APPROVED", "SUCCESSFUL")
                        ),
                        affiliate_link_available=bool(aff),
                        extra=json.dumps(extra, ensure_ascii=False),
                    )
                    crud.upsert_offer_by_source(db, payload)
                    imported_offers += 1
            except Exception as e:
                logger.debug("Skip promotion/offer upsert: %s", e)

    return {"ok": True, "promotions": imported_promos, "offers_from_promotions": imported_offers}

@app.post(
    "/ingest/v2/top-products",
    tags=["Offers üõí"],
    summary="Ingest Top Products (b√°n ch·∫°y) theo merchant & kho·∫£ng ng√†y",
    description="ƒê·ªìng b·ªô top_products theo trang (1..N), map th√†nh offers t·ªëi thi·ªÉu."
)
async def ingest_v2_top_products(
    req: IngestV2TopProductsReq,
    db: Session = Depends(get_db),
):
    from accesstrade_service import fetch_top_products, fetch_active_campaigns, _check_url_alive

    # 0) map merchant -> campaign_id ƒë·ªÉ g·∫Øn campaign_id cho offer
    active = await fetch_active_campaigns(db)  # {campaign_id: merchant}
    m_req = (req.merchant or "").lower()
    _alias = {"lazadacps": "lazada", "tikivn": "tiki"}
    m_fetch = _alias.get(m_req, m_req)

    campaign_id = None
    for cid, mm in active.items():
        mm_l = (mm or "").lower()
        if mm_l == m_req or mm_l == m_fetch:
            campaign_id = cid
            break
    if not campaign_id:
        for cid, mm in active.items():
            mm_l = (mm or "").lower()
            if mm_l.endswith(m_req) or f"_{m_req}" in mm_l or (m_req in mm_l):
                campaign_id = cid
                break
    if not campaign_id and m_fetch != m_req:
        for cid, mm in active.items():
            mm_l = (mm or "").lower()
            if mm_l.endswith(m_fetch) or f"_{m_fetch}" in mm_l or (m_fetch in mm_l):
                campaign_id = cid
                break

    # DEFAULT date range: 7 ng√†y g·∫ßn nh·∫•t n·∫øu kh√¥ng truy·ªÅn
    if not req.date_from or not req.date_to:
        from datetime import datetime, timedelta
        _to = datetime.utcnow().date()
        _from = _to - timedelta(days=7)
        date_from_use = req.date_from or _from.strftime("%Y-%m-%d")
        date_to_use = req.date_to or _to.strftime("%Y-%m-%d")
    else:
        date_from_use = req.date_from
        date_to_use = req.date_to

    page = 1
    imported = 0
    while page <= max(1, req.max_pages):
        items = await fetch_top_products(
            db,
            merchant=m_fetch,  # d√πng alias ƒë·ªÉ g·ªçi API ·ªïn ƒë·ªãnh
            date_from=date_from_use,
            date_to=date_to_use,
            page=page,
            limit=req.limit_per_page
        )
        if not items:
            break

        for it in items:
            try:
                title = it.get("name") or "S·∫£n ph·∫©m"
                link = it.get("link") or it.get("url")
                aff = it.get("aff_link")
                img = it.get("image") or it.get("thumb")
                price = it.get("price")
                product_id = it.get("product_id") or it.get("id")

                if not link and not aff:
                    logger.debug("[TOP] skip: no link/aff for %s", title)
                    continue
                # ∆Øu ti√™n link g·ªëc cho tr∆∞·ªùng url (affiliate_url s·∫Ω gi·ªØ aff)
                url_to_check = link or aff

                # (policy) ch·ªâ check khi b·∫≠t c·ªù
                alive = True if not req.check_urls else await _check_url_alive(url_to_check)
                if not alive:
                    logger.debug("[TOP] skip: dead url %s", url_to_check)
                    continue

                # idempotent theo product_id n·∫øu c√≥, n·∫øu kh√¥ng theo link
                base_key = str(product_id or url_to_check)
                sid = hashlib.md5(base_key.encode("utf-8")).hexdigest()

                extra = {
                    "source_type": "top_products",
                    "raw": it,
                }
                # Ch·ªâ t·∫°o offer n·∫øu campaign APPROVED (API b·ªè qua policy nh∆∞ng v·∫´n y√™u c·∫ßu APPROVED)
                try:
                    _row = crud.get_campaign_by_cid(db, campaign_id) if campaign_id else None
                    _user = (_row.user_registration_status or "").upper() if _row else ""
                    if not _row or _user not in ("APPROVED", "SUCCESSFUL"):
                        continue
                except Exception:
                    continue

                payload = schemas.ProductOfferCreate(
                    source="accesstrade",
                    source_id=f"top:{req.merchant}:{sid}",
                    merchant=req.merchant,
                    title=title,
                    url=link or aff,
                    affiliate_url=aff,
                    image_url=img,
                    price=price,
                    currency="VND",
                    campaign_id=campaign_id,
                    source_type="top_products",
                    # eligible_commission = campaign ƒëang ch·∫°y & user APPROVED/SUCCESSFUL
                    eligible_commission=bool(
                        _row
                        and _row.status == "running"
                        and (_row.user_registration_status or "").upper() in ("APPROVED", "SUCCESSFUL")
                    ),
                    affiliate_link_available=bool(aff),
                    product_id=str(product_id) if product_id is not None else None,
                    extra=json.dumps(extra, ensure_ascii=False),
                )

                crud.upsert_offer_by_source(db, payload)
                imported += 1
            except Exception as e:
                logger.debug("Skip top_product upsert: %s", e)

        page += 1
        sleep_ms = getattr(req, "throttle_ms", 0) or 0
        if sleep_ms:
            await asyncio.sleep(sleep_ms / 1000.0)

    return {"ok": True, "imported": imported, "merchant": req.merchant}

# ================================
# NEW: One-shot ingest ALL sources for APPROVED merchants
# ================================
class IngestAllApprovedReq(BaseModel):
    # B·∫≠t/t·∫Øt t·ª´ng ngu·ªìn
    include_promotions: bool = True
    include_top_products: bool = True
    include_datafeeds: bool = True

    # Tham s·ªë cho top_products
    top_date_from: str | None = None
    top_date_to: str | None = None
    top_limit_per_page: int = 100
    top_max_pages: int = 2

    # Tham s·ªë cho datafeeds
    datafeeds_limit_per_page: int = 100
    datafeeds_max_pages: int = 5

    # Ngh·ªâ gi·ªØa c√°c l·∫ßn g·ªçi (ms) ƒë·ªÉ t√¥n tr·ªçng rate-limit
    throttle_ms: int = 200


@app.post(
    "/ingest/v2/offers/all-approved",
    tags=["Offers üõí"],
    summary="Ingest t·∫•t c·∫£ s·∫£n ph·∫©m t·ª´ approved merchants (promotions + top_products + datafeeds)",
    description=(
        "M·ªôt l·ªánh duy nh·∫•t:\n"
        "1) Promotions (offers_informations) theo t·ª´ng merchant ƒë√£ APPROVED (t·∫°o offer t·ªëi thi·ªÉu n·∫øu c√≥ link s·ªëng)\n"
        "2) Top products theo t·ª´ng merchant ƒë√£ APPROVED (t·ª± ph√¢n trang theo limit/max_pages)\n"
        "3) Datafeeds full (t·ª± ph√¢n trang 1..N)\n"
        "‚Äî Tu√¢n th·ªß doc Accesstrade v√† logic APPROVED ƒëang c√≥."
    )
)
async def ingest_v2_offers_all_approved(
    req: IngestAllApprovedReq,
    db: Session = Depends(get_db),
):
    # L·∫•y danh s√°ch merchant ƒë√£ APPROVED & campaign ƒëang ch·∫°y
    approved_merchants = list_approved_merchants_api(db)  # ['shopee', 'lazada', ...]
    logger.info("[ALL-APPROVED] merchants=%s", approved_merchants)

    out = {
        "ok": True,
        "approved_merchants": approved_merchants,
        "promotions": 0,
        "offers_from_promotions": 0,
        "top_products_offers": 0,
        "datafeeds_offers": 0,
        "datafeeds_pages": 0,
    }

    # 1) Promotions (ch·∫°y theo t·ª´ng merchant ƒë√£ APPROVED ƒë·ªÉ tr√°nh r√°c)
    if req.include_promotions and approved_merchants:
        for m in approved_merchants:
            try:
                res = await ingest_v2_promotions(
                    IngestV2PromotionsReq(merchant=m, create_offers=True),
                    db
                )
                out["promotions"] += int(res.get("promotions") or 0)
                out["offers_from_promotions"] += int(res.get("offers_from_promotions") or 0)
                if req.throttle_ms:
                    await asyncio.sleep(req.throttle_ms / 1000.0)
            except Exception as e:
                logger.error("[ALL-APPROVED] promotions for %s failed: %s", m, e)

    # 2) Top products (theo t·ª´ng merchant ƒë√£ APPROVED)
    if req.include_top_products and approved_merchants:
        for m in approved_merchants:
            try:
                res = await ingest_v2_top_products(
                    IngestV2TopProductsReq(
                        merchant=m,
                        date_from=req.top_date_from,
                        date_to=req.top_date_to,
                        limit_per_page=req.top_limit_per_page,
                        max_pages=req.top_max_pages,
                        throttle_ms=req.throttle_ms,
                    ),
                    db
                )
                out["top_products_offers"] += int(res.get("imported") or 0)
                if req.throttle_ms:
                    await asyncio.sleep(req.throttle_ms / 1000.0)
            except Exception as e:
                logger.error("[ALL-APPROVED] top_products for %s failed: %s", m, e)

    # 3) Datafeeds (full, t·ª± ph√¢n trang) ‚Äî b·∫£n th√¢n h√†m ƒë√£ y√™u c·∫ßu APPROVED trong qu√° tr√¨nh ghi
    if req.include_datafeeds:
        try:
            res = await ingest_accesstrade_datafeeds_all(
                IngestAllDatafeedsReq(
                    params=None,
                    limit_per_page=req.datafeeds_limit_per_page,
                    max_pages=req.datafeeds_max_pages,
                    throttle_ms=req.throttle_ms,
                ),
                db
            )
            out["datafeeds_offers"] = int(res.get("imported") or 0)
            out["datafeeds_pages"] = int(res.get("pages") or 0)
        except Exception as e:
            logger.error("[ALL-APPROVED] datafeeds failed: %s", e)

    return out

@app.put(
    "/offers/{offer_id}",
    tags=["Offers üõí"],
    summary="C·∫≠p nh·∫≠t th√¥ng tin s·∫£n ph·∫©m",
    description="S·ª≠a th√¥ng tin 1 s·∫£n ph·∫©m trong DB theo ID.",
    response_model=schemas.ProductOfferOut
)
def update_offer_api(offer_id: int, data: schemas.ProductOfferUpdate, db: Session = Depends(get_db)):
    obj = crud.update_offer(db, offer_id, data)
    if not obj:
        raise HTTPException(status_code=404, detail="Offer not found")
    return obj

@app.delete(
    "/offers/{offer_id}",
    tags=["Offers üõí"],
    summary="Xo√° 1 s·∫£n ph·∫©m",
    description="Xo√° m·ªôt s·∫£n ph·∫©m trong DB theo ID."
)
def delete_offer_api(offer_id: int, db: Session = Depends(get_db)):
    obj = crud.delete_offer(db, offer_id)
    if not obj:
        raise HTTPException(status_code=404, detail="Offer not found")
    return {"ok": True, "deleted_id": offer_id}

# --- API cleanup: x√≥a s·∫£n ph·∫©m c√≥ link ch·∫øt ---
@app.delete(
    "/offers/cleanup/dead",
    tags=["Offers üõí"],
    summary="D·ªçn link ch·∫øt (cleanup)",
    description="Qu√©t to√†n b·ªô s·∫£n ph·∫©m trong DB, ki·ªÉm tra link s·ªëng/ch·∫øt v√† **xo√° t·∫•t c·∫£** link ch·∫øt."
)
async def cleanup_dead_offers(db: Session = Depends(get_db)):
    offers = crud.list_offers(db, limit=1000)
    removed = 0
    alive_count = 0
    total = len(offers)
    for idx, o in enumerate(offers, start=1):
        if idx % 50 == 0 or idx == total:
            logger.info("Cleanup progress: %d/%d", idx, total)
        alive = await _check_url_alive(o.url)  # ch·ªâ d√πng link g·ªëc ƒë·ªÉ tr√°nh click ·∫£o
        if not alive:
            logger.info("Removing dead product via API: id=%s, title='%s'", o.id, o.title)
            db.delete(o)
            removed += 1
        else:
            alive_count += 1
    db.commit()
    logger.info("API cleanup done: %s dead / %s alive / %s scanned", removed, alive_count, total)
    return {"dead": removed, "alive": alive_count, "scanned": total}

@app.post(
    "/scheduler/linkcheck/rotate",
    tags=["Maintenance üßπ"],
    summary="Ki·ªÉm tra link s·ªëng theo l√°t c·∫Øt 10% v√† xoay v√≤ng",
    description=(
        "M·ªói l·∫ßn ch·∫°y s·∫Ω ki·ªÉm tra ~10% s·∫£n ph·∫©m theo ƒëi·ªÅu ki·ªán id % 10 = cursor. "
        "Sau khi ch·∫°y xong, cursor t·ª± tƒÉng (modulo 10). "
        "Tu·ª≥ ch·ªçn xo√° link ch·∫øt."
    )
)
async def scheduler_linkcheck_rotate(
    delete_dead: bool = False,
    db: Session = Depends(get_db),
):
    from accesstrade_service import _check_url_alive
    flags = crud.get_policy_flags(db)
    cursor = int(flags.get("linkcheck_cursor", 0)) % 10

    from models import ProductOffer
    slice_q = db.query(ProductOffer).filter(text("id % 10 = :cur")).params(cur=cursor)
    offers = slice_q.all()

    total = len(offers)
    removed = 0
    alive_count = 0
    for idx, o in enumerate(offers, start=1):
        if idx % 50 == 0 or idx == total:
            logger.info("[ROTATE] progress: %d/%d (cursor=%d)", idx, total, cursor)
        alive = await _check_url_alive(o.url)
        if alive:
            alive_count += 1
        else:
            if delete_dead:
                db.delete(o)
                removed += 1
    db.commit()

    next_cursor = (cursor + 1) % 10
    crud.set_policy_flag(db, "linkcheck_cursor", next_cursor)

    return {
        "cursor_used": cursor,
        "next_cursor": next_cursor,
        "scanned": total,
        "alive": alive_count,
        "deleted": removed,
    }

# --- API test nhanh: check 1 s·∫£n ph·∫©m trong DB ---
from datetime import datetime
@app.get(
    "/offers/check/{offer_id}",
    tags=["Offers üõí"],
    summary="Ki·ªÉm tra 1 s·∫£n ph·∫©m (alive/dead)",
    description="Ki·ªÉm tra nhanh **tr·∫°ng th√°i link** c·ªßa m·ªôt s·∫£n ph·∫©m trong DB theo **ID**."
)
async def check_offer_status(offer_id: int, db: Session = Depends(get_db)):
    offer = db.query(models.ProductOffer).filter(models.ProductOffer.id == offer_id).first()
    if not offer:
        raise HTTPException(status_code=404, detail="Offer not found")

    alive = await _check_url_alive(offer.url)  # ch·ªâ check link g·ªëc ƒë·ªÉ tr√°nh click ·∫£o
    return {
        "id": offer.id,
        "title": offer.title,
        "url": offer.url,
        "affiliate_url": offer.affiliate_url,
        "alive": alive,
        "checked_at": datetime.utcnow().isoformat() + "Z"
    }

@app.delete(
    "/offers",
    tags=["Offers üõí"],
    summary="Xo√° to√†n b·ªô s·∫£n ph·∫©m",
    description="**C·∫£nh b√°o:** Xo√° t·∫•t c·∫£ s·∫£n ph·∫©m trong DB."
)
def delete_all_offers_api(db: Session = Depends(get_db)):
    count = crud.delete_all_offers(db)
    return {"ok": True, "deleted": count}

# --- Import s·∫£n ph·∫©m t·ª´ Excel ---
import pandas as pd
@app.post(
    "/offers/import-excel",
    tags=["Offers üõí"],
    summary="Import s·∫£n ph·∫©m t·ª´ Excel",
    description="Upload file Excel (.xlsx) ch·ª©a danh s√°ch s·∫£n ph·∫©m ƒë·ªÉ import v√†o DB."
)
async def import_offers_excel(file: UploadFile = File(...), db: Session = Depends(get_db)):
    if not file.filename.endswith(".xlsx"):
        raise HTTPException(status_code=400, detail="Ch·ªâ h·ªó tr·ª£ file .xlsx")

    try:
        df = pd.read_excel(file.file)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"L·ªói ƒë·ªçc file Excel: {e}")
    # Ch·ªâ import Excel m·ªõi √°p d·ª•ng policy; m·∫∑c ƒë·ªãnh False n·∫øu ch∆∞a set
    flags = crud.get_policy_flags(db)
    only_with_commission = bool(flags.get("only_with_commission"))
    check_urls_excel = bool(flags.get("check_urls"))
    from accesstrade_service import _check_url_alive

    imported = 0
    for _, row in df.iterrows():
        base = {
            "source": "excel",
            "source_id": str(row.get("source_id") or row.get("id") or ""),
            "merchant": str(row.get("merchant") or "").lower(),
            "title": str(row.get("title") or ""),
            "url": str(row.get("url") or ""),
            "affiliate_url": row.get("affiliate_url"),
            "image_url": row.get("image_url"),
            "price": float(row.get("price")) if row.get("price") else None,
            "currency": row.get("currency") or "VND",
        }

        # Ghi campaign_id n·∫øu c√≥ trong file Excel
        campaign_id = row.get("campaign_id")
        if pd.notna(campaign_id):
            base["campaign_id"] = str(campaign_id).strip()

        # Gom promotion
        promotion = {
            "name": row.get("promotion_name"),
            "content": row.get("promotion_content"),
            "start_time": row.get("promotion_start_time"),
            "end_time": row.get("promotion_end_time"),
            "coupon": row.get("promotion_coupon"),
            "link": row.get("promotion_link"),
        }
        promotion = {k: v for k, v in promotion.items() if pd.notna(v)}

        # Gom commission (n·∫øu file c√≥ c√°c c·ªôt n√†y)
        commission = {
            "sales_ratio": row.get("commission_sales_ratio"),
            "sales_price": row.get("commission_sales_price"),
            "reward_type": row.get("commission_reward_type"),
            "target_month": row.get("commission_target_month"),
        }
        commission = {k: v for k, v in commission.items() if pd.notna(v)}

        # G·ªôp v√†o extra
        extra = {}
        if promotion:
            extra["promotion"] = promotion
        if commission:
            extra["commission"] = commission

        base["extra"] = json.dumps(extra, ensure_ascii=False)
        
        if only_with_commission:
            # X√°c ƒë·ªãnh ƒë·ªß ƒëi·ªÅu ki·ªán: c√≥ c·ªôt eligible_commission=True ho·∫∑c c√≥ √≠t nh·∫•t m·ªôt tr∆∞·ªùng commission h·ª£p l·ªá
            eligible_flag = False
            try:
                eligible_flag = bool(str(row.get("eligible_commission") or "").strip().lower() in ("true","1","yes"))
            except Exception:
                eligible_flag = False

            has_comm = False
            try:
                _comm = commission if isinstance(commission, dict) else {}
                for _k in ("sales_ratio","sales_price","reward_type","target_month"):
                    v = _comm.get(_k)
                    if v not in (None, "", float("nan")):
                        has_comm = True
                        break
            except Exception:
                has_comm = False

            if not (eligible_flag or has_comm):
                continue

        data = schemas.ProductOfferCreate(**base)

        if not data.url or not data.source_id:
            continue

        # N·∫øu b·∫≠t check link cho Excel th√¨ ch·ªâ ghi khi url s·ªëng
        if check_urls_excel:
            try:
                if not await _check_url_alive(data.url or ""):
                    continue
            except Exception:
                continue

        crud.upsert_offer_by_source(db, data)
        imported += 1

    return {"ok": True, "imported": imported}

# --- Export s·∫£n ph·∫©m t·ª´ DB ra file Excel ---
@app.get(
    "/offers/export-excel",
    tags=["Offers üõí"],
    summary="Xu·∫•t s·∫£n ph·∫©m ra Excel",
    description="Xu·∫•t s·∫£n ph·∫©m trong DB ra file Excel. C√≥ th·ªÉ l·ªçc theo merchant, title (t∆∞∆°ng ƒë·ªëi), skip, limit."
)
def export_offers_excel(
    merchant: str | None = None,
    title: str | None = None,
    skip: int = 0,
    limit: int = 0,  # n·∫øu =0 th√¨ xu·∫•t to√†n b·ªô
    db: Session = Depends(get_db)
):
    # L·∫•y query g·ªëc
    query = db.query(models.ProductOffer)

    # L·ªçc theo merchant n·∫øu c√≥
    if merchant:
        query = query.filter(models.ProductOffer.merchant == merchant.lower())

    # L·ªçc theo title t∆∞∆°ng ƒë·ªëi (LIKE) n·∫øu c√≥
    if title:
        like_pattern = f"%{title.lower()}%"
        query = query.filter(models.ProductOffer.title.ilike(like_pattern))

    # Skip + limit
    if skip:
        query = query.offset(skip)
    if limit:
        query = query.limit(limit)

    offers = query.all()
    # Prefetch map/group t·ª´ c√°c b·∫£ng chu·∫©n ho√° ƒë·ªÉ join nhanh theo campaign_id
    from collections import defaultdict
    campaign_map = {c.campaign_id: c for c in db.query(models.Campaign).all()}

    commissions_by_cid = defaultdict(list)
    for cp in db.query(models.CommissionPolicy).all():
        commissions_by_cid[cp.campaign_id].append(cp)

    promotions_by_cid = defaultdict(list)
    for pr in db.query(models.Promotion).all():
        promotions_by_cid[pr.campaign_id].append(pr)

    # === JSONL: ƒë·ªçc log API ƒë·ªÉ g√°n API_EMPTY / API_MISSING ===
    import os, json
    LOG_DIR = os.getenv("API_LOG_DIR", "./logs")

    def _read_jsonl(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        yield json.loads(line)
                    except Exception:
                        pass
        except FileNotFoundError:
            return

    # Commissions theo campaign_id
    COMM_POLLED, COMM_EMPTY = set(), set()
    for rec in _read_jsonl(os.path.join(LOG_DIR, "commission_policies.jsonl")) or []:
        cid = str(rec.get("campaign_id") or "")
        if not cid:
            continue
        COMM_POLLED.add(cid)
        if int(rec.get("items_count") or 0) == 0:
            COMM_EMPTY.add(cid)

    # Promotions theo merchant (vi·∫øt th∆∞·ªùng)
    PROMO_POLLED, PROMO_EMPTY = set(), set()
    for rec in _read_jsonl(os.path.join(LOG_DIR, "promotions.jsonl")) or []:
        m = (rec.get("merchant") or "").lower()
        if not m:
            continue
        PROMO_POLLED.add(m)
        if int(rec.get("items_count") or 0) == 0:
            PROMO_EMPTY.add(m)

    # Campaign detail: gi·ªØ b·∫£n ghi cu·ªëi theo campaign_id
    CAMP_LAST = {}
    for rec in _read_jsonl(os.path.join(LOG_DIR, "campaign_detail.jsonl")) or []:
        cid = str(rec.get("campaign_id") or "")
        if cid:
            CAMP_LAST[cid] = rec  # overwrite ƒë·ªÉ l·∫•y b·∫£n m·ªõi nh·∫•t

    def _campaign_field_from_log(cid: str, field_name: str):
        rec = CAMP_LAST.get(str(cid) if cid is not None else "")
        if not rec:
            return "API_MISSING"

        # 1) H·ªó tr·ª£ log r√∫t g·ªçn (boolean flags)
        if field_name == "end_time" and rec.get("has_end_time") is False:
            return "API_EMPTY"
        if field_name == "user_registration_status" and rec.get("has_user_status") is False:
            return "API_EMPTY"

        # 2) H·ªó tr·ª£ log d·∫°ng ƒë·∫ßy ƒë·ªß (raw JSON)
        if rec.get("empty") is True:
            return "API_EMPTY"

        raw = rec.get("raw")
        if isinstance(raw, dict):
            data = None
            d = raw.get("data")
            if isinstance(d, dict):
                data = d
            elif isinstance(d, list) and d:
                data = d[0]
            if isinstance(data, dict):
                if field_name == "user_registration_status":
                    for k in ("user_registration_status", "publisher_status", "user_status"):
                        v = data.get(k, None)
                        if v not in (None, "", []):
                            return v
                    return "API_EMPTY"
                v = data.get(field_name, None)
                return v if v not in (None, "", []) else "API_EMPTY"

        # 3) Kh√¥ng c√≥ raw v√† c≈©ng kh√¥ng c√≥ c·ªù ‚Üí coi nh∆∞ ch∆∞a ghi log ƒë√∫ng chu·∫©n
        return "API_MISSING"

    rows = []
    for o in offers:

        base = {
            "id": o.id,
            "source": o.source,
            "source_id": o.source_id,
            "merchant": o.merchant,
            "title": o.title,
            "url": o.url,
            "affiliate_url": o.affiliate_url,
            "image_url": o.image_url,
            "price": o.price,
            "currency": o.currency,
            "campaign_id": o.campaign_id,
            "updated_at": o.updated_at.isoformat() if o.updated_at else None,
        }
        # Parse extra n·∫øu c√≥
        extra = {}
        if o.extra:
            try:
                extra = json.loads(o.extra)
            except Exception:
                extra = {"extra_raw": o.extra}

        # NEW: Enrich theo campaign_id (n·∫øu c√≥) ‚Äî gi·ªØ Products g·ªçn,
        # kh√¥ng d√†n tr√†n campaign/commission/promotion v√†o base ·ªü ƒë√¢y.
        cid = str(o.campaign_id or "")
        # (C√°c sheet Campaigns/Commissions/Promotions s·∫Ω x·ª≠ l√Ω b√™n d∆∞·ªõi)

        # T√°ch th√™m c√°c tr∆∞·ªùng l·∫∑p t·ª´ extra (n·∫øu c√≥)
        base["desc"] = extra.get("desc")
        base["cate"] = extra.get("cate")
        base["shop_name"] = extra.get("shop_name")
        # ∆Øu ti√™n 'update_time_raw' (key chu·∫©n m·ªõi), fallback 'update_time' ƒë·ªÉ t∆∞∆°ng th√≠ch
        base["update_time_raw"] = extra.get("update_time_raw") or extra.get("update_time")

        # Lu√¥n gi·ªØ full extra raw ƒë·ªÉ kh√¥ng m·∫•t th√¥ng tin
        base["extra_raw"] = json.dumps(extra, ensure_ascii=False)

        rows.append(base)

    if not rows:
        raise HTTPException(status_code=404, detail="Kh√¥ng c√≥ s·∫£n ph·∫©m n√†o ph√π h·ª£p trong DB")

    # Xu·∫•t ra Excel
# ƒêO·∫†N M·ªöI (thay th·∫ø to√†n b·ªô kh·ªëi export 1 sheet th√†nh 4 sheet)

    # ---------------------------
    # T·∫†O 4 SHEET ƒê·ªíNG B·ªò TH·ª® T·ª∞
    # ---------------------------
    import pandas as pd

    df_products_rows = []
    df_campaigns_rows = []
    df_commissions_rows = []
    df_promotions_rows = []

    for base in rows:
        # base c√≥: id, source, source_id, merchant, title, url, affiliate_url, image_url,
        # price, currency, campaign_id, updated_at, desc, cate, shop_name, update_time_raw,
        # promotion_* (n·∫øu ƒë√£ map), extra_raw (full JSON)
        # -> Ta v·∫´n gi·ªØ Products g·ªçn: kh√¥ng d√†n tr√†n commission/promotion v√†o ƒë√¢y
        prod_row = {
            "id": base.get("id"),
            "source": base.get("source"),
            "source_id": base.get("source_id"),
            "merchant": base.get("merchant"),
            "title": base.get("title"),
            "url": base.get("url"),
            "affiliate_url": base.get("affiliate_url"),
            "image_url": base.get("image_url"),
            "price": base.get("price"),
            "currency": base.get("currency"),
            "campaign_id": base.get("campaign_id"),
            "updated_at": base.get("updated_at"),
            # M·ªôt s·ªë tr∆∞·ªùng extra ti·ªán tra c·ª©u
            "desc": base.get("desc"),
            "cate": base.get("cate"),
            "shop_name": base.get("shop_name"),
            "update_time_raw": base.get("update_time_raw"),
            "extra_raw": base.get("extra_raw"),
        }
        df_products_rows.append(prod_row)

        # T√°ch extra ƒë·ªÉ ƒë·ªçc commission/promotion/campaign-info
        try:
            extra = json.loads(base.get("extra_raw", "{}")) if base.get("extra_raw") else {}
        except Exception:
            extra = {}


        # --- Campaigns sheet (join t·ª´ b·∫£ng Campaign)
        cid = str(base.get("campaign_id") or "") if base.get("campaign_id") is not None else ""
        c = campaign_map.get(cid)

        # N·∫øu DB c√≥ gi√° tr·ªã th√¨ d√πng; n·∫øu tr·ªëng ‚Üí tra log ƒë·ªÉ g√°n API_EMPTY / API_MISSING
        user_val = (c.user_registration_status if c else None)
        end_val = (c.end_time if c else None)
        if user_val in (None, "", []):
            user_val = _campaign_field_from_log(cid, "user_registration_status")
        if end_val in (None, "", []):
            end_val = _campaign_field_from_log(cid, "end_time")

        camp_row = {
            "product_id": base.get("id"),
            "merchant": base.get("merchant"),
            "campaign_id": cid,
            "campaign_name": (c.name if c else None),
            "approval_type": (c.approval if c else None),
            "user_status": user_val,  # NOT_REGISTERED/PENDING/APPROVED ho·∫∑c API_EMPTY/API_MISSING
            "status": (c.status if c else _campaign_field_from_log(cid, "status")),
            "start_time": (c.start_time if c else None),
            "end_time": end_val,      # yyyy-mm-dd ho·∫∑c API_EMPTY/API_MISSING
        }

        df_campaigns_rows.append(camp_row)

        # --- Commissions sheet (join t·ª´ b·∫£ng CommissionPolicy, gom nhi·ªÅu ch√≠nh s√°ch v·ªÅ 1 h√†ng)
        cid = str(base.get("campaign_id") or "") if base.get("campaign_id") is not None else ""
        pols = commissions_by_cid.get(cid, [])
        def _join(vals): 
            vals = [str(v) for v in vals if v not in (None, "")]
            return "; ".join(sorted(set(vals))) if vals else None

        if pols:
            df_commissions_rows.append({
                "product_id": base.get("id"),
                "sales_ratio": _join([p.sales_ratio for p in pols]),
                "sales_price": _join([p.sales_price for p in pols]),
                "reward_type": _join([p.reward_type for p in pols]),
                "target_month": _join([p.target_month for p in pols]),
            })
        else:
            # Kh√¥ng c√≥ policy trong DB ‚Üí tra log theo campaign_id ƒë·ªÉ g·∫Øn nh√£n
            tag = "API_EMPTY" if cid in COMM_EMPTY else ("API_MISSING" if (cid and cid not in COMM_POLLED) else "API_EMPTY")
            df_commissions_rows.append({
                "product_id": base.get("id"),
                "sales_ratio": None,
                "sales_price": None,
                "reward_type": tag,
                "target_month": None,
            })

        # --- Promotions sheet (join t·ª´ b·∫£ng Promotion, c√≥ th·ªÉ nhi·ªÅu khuy·∫øn m√£i -> g·ªôp)
        cid = str(base.get("campaign_id") or "") if base.get("campaign_id") is not None else ""
        pr_list = promotions_by_cid.get(cid, [])

        def _join(vals):
            vals = [str(v) for v in vals if v not in (None, "")]
            return "; ".join(sorted(set(vals))) if vals else None

        if pr_list:
            df_promotions_rows.append({
                "product_id": base.get("id"),
                "promotion_name": _join([p.name for p in pr_list]),
                "promotion_content": _join([p.content for p in pr_list]),
                "promotion_start_time": _join([p.start_time for p in pr_list]),
                "promotion_end_time": _join([p.end_time for p in pr_list]),
                "promotion_coupon": _join([p.coupon for p in pr_list]),
                "promotion_link": _join([p.link for p in pr_list]),
            })
        else:
            # Kh√¥ng c√≥ promotion trong DB ‚Üí tra log theo merchant ƒë·ªÉ g·∫Øn nh√£n
            mkey = (base.get("merchant") or "").lower()
            if not mkey and cid and cid in campaign_map:
                mkey = (getattr(campaign_map[cid], "merchant", "") or "").lower()
            tag = "API_EMPTY" if (mkey in PROMO_EMPTY) else ("API_MISSING" if (mkey and mkey not in PROMO_POLLED) else "API_EMPTY")
            df_promotions_rows.append({
                "product_id": base.get("id"),
                "promotion_name": tag,
                "promotion_content": None,
                "promotion_start_time": None,
                "promotion_end_time": None,
                "promotion_coupon": None,
                "promotion_link": None,
            })

    # DataFrames
    df_products = pd.DataFrame(df_products_rows)
    df_campaigns = pd.DataFrame(df_campaigns_rows)
    df_commissions = pd.DataFrame(df_commissions_rows)
    df_promotions = pd.DataFrame(df_promotions_rows)

    # H√†ng d·ªãch nghƒ©a (ti·∫øng Vi·ªát) cho t·ª´ng sheet
    trans_products = {
        "id": "M√£ ID", "source": "Ngu·ªìn", "source_id": "M√£ ngu·ªìn", "merchant": "Nh√† b√°n",
        "title": "T√™n s·∫£n ph·∫©m", "url": "Link g·ªëc", "affiliate_url": "Link ti·∫øp th·ªã",
        "image_url": "·∫¢nh s·∫£n ph·∫©m", "price": "Gi√°", "currency": "Ti·ªÅn t·ªá",
        "campaign_id": "Chi·∫øn d·ªãch", "updated_at": "Ng√†y c·∫≠p nh·∫≠t", "desc": "M√¥ t·∫£ chi ti·∫øt",
        "cate": "Danh m·ª•c", "shop_name": "T√™n c·ª≠a h√†ng", "update_time_raw": "Th·ªùi gian c·∫≠p nh·∫≠t t·ª´ ngu·ªìn",
        "extra_raw": "Extra g·ªëc",
    }
    trans_campaigns = {
        "product_id": "ID s·∫£n ph·∫©m", "merchant": "Nh√† b√°n",
        "campaign_name": "T√™n chi·∫øn d·ªãch", "approval_type": "Approval", "user_status": "Tr·∫°ng th√°i c·ªßa t√¥i",
        "status": "T√¨nh tr·∫°ng",  # NEW
        "start_time": "B·∫Øt ƒë·∫ßu", "end_time": "K·∫øt th√∫c",
    }
    trans_commissions = {
        "product_id": "ID s·∫£n ph·∫©m", "sales_ratio": "T·ª∑ l·ªá (%)",
        "sales_price": "Hoa h·ªìng c·ªë ƒë·ªãnh", "reward_type": "Ki·ªÉu th∆∞·ªüng", "target_month": "Th√°ng √°p d·ª•ng",
    }
    trans_promotions = {
        "product_id": "ID s·∫£n ph·∫©m", "promotion_name": "T√™n khuy·∫øn m√£i", "promotion_content": "N·ªôi dung",
        "promotion_start_time": "B·∫Øt ƒë·∫ßu KM", "promotion_end_time": "K·∫øt th√∫c KM",
        "promotion_coupon": "M√£ gi·∫£m", "promotion_link": "Link khuy·∫øn m√£i",
    }

    def _with_header(df, trans):
        if df.empty:
            return df
        header = {c: trans.get(c, c) for c in df.columns}
        return pd.concat([pd.DataFrame([header]), df], ignore_index=True)

    df_products = _with_header(df_products, trans_products)
    df_campaigns = _with_header(df_campaigns, trans_campaigns)
    df_commissions = _with_header(df_commissions, trans_commissions)
    df_promotions = _with_header(df_promotions, trans_promotions)

    # Ghi 4 sheet
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df_products.to_excel(writer, sheet_name="Products", index=False)
        df_campaigns.to_excel(writer, sheet_name="Campaigns", index=False)
        df_commissions.to_excel(writer, sheet_name="Commissions", index=False)
        df_promotions.to_excel(writer, sheet_name="Promotions", index=False)
    output.seek(0)

    filename = f"offers_export_{int(time.time())}.xlsx"
    headers = {"Content-Disposition": f"attachment; filename={filename}"}
    return StreamingResponse(
        output,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers=headers
    )
@app.get(
    "/alerts/campaigns-registration",
    tags=["Campaigns üì¢"],
    summary="C·∫£nh b√°o ƒëƒÉng k√Ω chi·∫øn d·ªãch",
    description="Li·ªát k√™ c√°c campaign ƒëang ch·∫°y v√† ƒë√£ c√≥ s·∫£n ph·∫©m trong DB, nh∆∞ng user ch∆∞a ·ªü tr·∫°ng th√°i APPROVED (ch∆∞a ƒëƒÉng k√Ω ho·∫∑c ƒëang ch·ªù duy·ªát)."
)
def campaigns_registration_alerts(db: Session = Depends(get_db)):
    return crud.campaigns_need_registration_alerts(db)
